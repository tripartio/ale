[{"path":"https://tripartio.github.io/ale/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2024 ale authors Permission hereby granted, free charge, person obtaining copy software associated documentation files (“Software”), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED “”, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":"https://tripartio.github.io/ale/articles/ale-intro.html","id":"diamonds-dataset","dir":"Articles","previous_headings":"","what":"diamonds dataset","title":"Introduction to the ale package","text":"introduction, use diamonds dataset, included ggplot2 graphics system. cleaned original version removing duplicates invalid entries length (x), width (y), depth (z) 0. description modified dataset. Interpretable machine learning (IML) techniques like ALE applied dataset used train model. explanation explanation trained model trained model intrinsically linked dataset trained. (dataset small feasibly split training test sets, ale package tools appropriately handle small datasets.","code":"# Clean up some invalid entries diamonds <- ggplot2::diamonds |>    filter(!(x == 0 | y == 0 | z == 0)) |>    # https://lorentzen.ch/index.php/2021/04/16/a-curious-fact-on-the-diamonds-dataset/   distinct(     price, carat, cut, color, clarity,     .keep_all = TRUE   ) |>    rename(     x_length = x,     y_width = y,     z_depth = z,     depth_pct = depth   )  # Optional: sample 1000 rows so that the code executes faster. set.seed(0) diamonds_sample <- ggplot2::diamonds[sample(nrow(ggplot2::diamonds), 1000), ]  summary(diamonds) #>      carat               cut        color       clarity       depth_pct     #>  Min.   :0.2000   Fair     : 1492   D:4658   SI1    :9857   Min.   :43.00   #>  1st Qu.:0.5200   Good     : 4173   E:6684   VS2    :8227   1st Qu.:61.00   #>  Median :0.8500   Very Good: 9714   F:6998   SI2    :7916   Median :61.80   #>  Mean   :0.9033   Premium  : 9657   G:7815   VS1    :6007   Mean   :61.74   #>  3rd Qu.:1.1500   Ideal    :14703   H:6443   VVS2   :3463   3rd Qu.:62.60   #>  Max.   :5.0100                     I:4556   VVS1   :2413   Max.   :79.00   #>                                     J:2585   (Other):1856                   #>      table           price          x_length         y_width       #>  Min.   :43.00   Min.   :  326   Min.   : 3.730   Min.   : 3.680   #>  1st Qu.:56.00   1st Qu.: 1410   1st Qu.: 5.160   1st Qu.: 5.170   #>  Median :57.00   Median : 3365   Median : 6.040   Median : 6.040   #>  Mean   :57.58   Mean   : 4686   Mean   : 6.009   Mean   : 6.012   #>  3rd Qu.:59.00   3rd Qu.: 6406   3rd Qu.: 6.730   3rd Qu.: 6.720   #>  Max.   :95.00   Max.   :18823   Max.   :10.740   Max.   :58.900   #>                                                                    #>     z_depth       #>  Min.   : 1.070   #>  1st Qu.: 3.190   #>  Median : 3.740   #>  Mean   : 3.711   #>  3rd Qu.: 4.150   #>  Max.   :31.800   #> str(diamonds) #> tibble [39,739 × 10] (S3: tbl_df/tbl/data.frame) #>  $ carat    : num [1:39739] 0.23 0.21 0.23 0.29 0.31 0.24 0.24 0.26 0.22 0.23 ... #>  $ cut      : Ord.factor w/ 5 levels \"Fair\"<\"Good\"<..: 5 4 2 4 2 3 3 3 1 3 ... #>  $ color    : Ord.factor w/ 7 levels \"D\"<\"E\"<\"F\"<\"G\"<..: 2 2 2 6 7 7 6 5 2 5 ... #>  $ clarity  : Ord.factor w/ 8 levels \"I1\"<\"SI2\"<\"SI1\"<..: 2 3 5 4 2 6 7 3 4 5 ... #>  $ depth_pct: num [1:39739] 61.5 59.8 56.9 62.4 63.3 62.8 62.3 61.9 65.1 59.4 ... #>  $ table    : num [1:39739] 55 61 65 58 58 57 57 55 61 61 ... #>  $ price    : int [1:39739] 326 326 327 334 335 336 336 337 337 338 ... #>  $ x_length : num [1:39739] 3.95 3.89 4.05 4.2 4.34 3.94 3.95 4.07 3.87 4 ... #>  $ y_width  : num [1:39739] 3.98 3.84 4.07 4.23 4.35 3.96 3.98 4.11 3.78 4.05 ... #>  $ z_depth  : num [1:39739] 2.43 2.31 2.31 2.63 2.75 2.48 2.47 2.53 2.49 2.39 ... summary(diamonds$price) #>    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.  #>     326    1410    3365    4686    6406   18823"},{"path":"https://tripartio.github.io/ale/articles/ale-intro.html","id":"modelling-with-generalized-additive-models-gam","dir":"Articles","previous_headings":"","what":"Modelling with generalized additive models (GAM)","title":"Introduction to the ale package","text":"ALE model-agnostic IML approach, , works kind machine learning model. , ale works R model condition can predict numeric outcomes (raw estimates regression probabilities odds ratios classification). demonstration, use generalized additive models (GAM), relatively fast algorithm models data flexibly ordinary least squares regression. beyond scope explain GAM works (can learn Noam Ross’s excellent tutorial), examples work statistical machine learning algorithm. train GAM model predict diamond prices:","code":"# Create a GAM model with flexible curves to predict diamond prices. # Smooth all numeric variables and include all other variables. gam_diamonds <- mgcv::gam(   price ~ s(carat) + s(depth_pct) + s(table) + s(x_length) + s(y_width) + s(z_depth) +     cut + color + clarity,   data = diamonds   ) summary(gam_diamonds) #>  #> Family: gaussian  #> Link function: identity  #>  #> Formula: #> price ~ s(carat) + s(depth_pct) + s(table) + s(x_length) + s(y_width) +  #>     s(z_depth) + cut + color + clarity #>  #> Parametric coefficients: #>              Estimate Std. Error  t value Pr(>|t|)     #> (Intercept)  4436.199     13.315  333.165  < 2e-16 *** #> cut.L         263.124     39.117    6.727 1.76e-11 *** #> cut.Q           1.792     27.558    0.065 0.948151     #> cut.C          74.074     20.169    3.673 0.000240 *** #> cut^4          27.694     14.373    1.927 0.054004 .   #> color.L     -2152.488     18.996 -113.313  < 2e-16 *** #> color.Q      -704.604     17.385  -40.528  < 2e-16 *** #> color.C       -66.839     16.366   -4.084 4.43e-05 *** #> color^4        80.376     15.289    5.257 1.47e-07 *** #> color^5      -110.164     14.484   -7.606 2.89e-14 *** #> color^6       -49.565     13.464   -3.681 0.000232 *** #> clarity.L    4111.691     33.499  122.742  < 2e-16 *** #> clarity.Q   -1539.959     31.211  -49.341  < 2e-16 *** #> clarity.C     762.680     27.013   28.234  < 2e-16 *** #> clarity^4    -232.214     21.977  -10.566  < 2e-16 *** #> clarity^5     193.854     18.324   10.579  < 2e-16 *** #> clarity^6      46.812     16.172    2.895 0.003799 **  #> clarity^7     132.621     14.274    9.291  < 2e-16 *** #> --- #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 #>  #> Approximate significance of smooth terms: #>                edf Ref.df       F  p-value     #> s(carat)     8.695  8.949  37.027  < 2e-16 *** #> s(depth_pct) 7.606  8.429   6.758  < 2e-16 *** #> s(table)     5.759  6.856   3.682 0.000736 *** #> s(x_length)  8.078  8.527  60.936  < 2e-16 *** #> s(y_width)   7.477  8.144 211.202  < 2e-16 *** #> s(z_depth)   9.000  9.000  16.266  < 2e-16 *** #> --- #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 #>  #> R-sq.(adj) =  0.929   Deviance explained = 92.9% #> GCV = 1.2602e+06  Scale est. = 1.2581e+06  n = 39739"},{"path":"https://tripartio.github.io/ale/articles/ale-intro.html","id":"ale-object-for-ale-data","dir":"Articles","previous_headings":"","what":"ALE object for ALE data","title":"Introduction to the ale package","text":"core object ale package S7 ALE object. effect stores ALE data , optionally, ALE statistics bootstrap data one categories. first argument ALE() constructor model object–R model object can generate numeric predictions acceptable. default, generates 1D (“first order”) ALE variables dataset used train model, dataset included model object. , dataset can specified data argument. can optionally create ALE specified variables interactions using x_cols argument. change options (e.g., calculate ALE subset variables; output data use custom, non-standard predict function model), see details help file object: help(ALE). introduction, demonstrate basics retrieving plotting ALE data. details ALE statistics see dedicated vignette topic. default, core functions ale package use parallel processing. computer problems , can disable parallelization argument parallel = 0. access plot specific variable, must first create ALEPlots object calling plot() method ALE object internally generates ggplot objects full flexibility {ggplot2}: retrieve specific variable plot, can use get() method ALEPlots object. example, access print carat ALE plot, can simply refer get(diamonds_plots, 'carat'):  display ALE plots ALEPlots object, can simply call print() plot() methods. Behind scenes, use patchwork package arrange multiple plots common plot grid using patchwork::wrap_plots(), can pass arguments function. example, can specify want two plots per row ncol argument:","code":"# Simple ALE without bootstrapping ale_gam_diamonds <- ALE(gam_diamonds) # Print a plot by entering its reference diamonds_plots <- plot(ale_gam_diamonds) # Print a plot by entering its reference get(diamonds_plots, 'carat') # Print all plots plot(diamonds_plots, ncol = 2)"},{"path":"https://tripartio.github.io/ale/articles/ale-intro.html","id":"bootstrapped-ale","dir":"Articles","previous_headings":"","what":"Bootstrapped ALE","title":"Introduction to the ale package","text":"One key features ALE package bootstrapping ALE results ensure results reliable, , generalizable data beyond sample model trained. mentioned , assumes IML analysis carried model whose hyperparameters determined cross-validation. samples small cross-validation, provide different approach bootstrapping entire model ModelBoot object, explained vignette small datasets. Although ALE faster IML techniques global explanation partial dependence plots (PDP) SHAP, still requires time run. Bootstrapping multiplies time number bootstrap iterations. Since vignette just demonstration package functionality rather real analysis, demonstrate bootstrapping small subset test data. run much faster speed ALE algorithm depends size dataset. , let us take random sample 200 rows. Now create bootstrapped ALE data plots using boot_it argument. ALE relatively stable IML algorithm (compared others like PDP), 100 bootstrap samples sufficient relatively stable results, especially model development. Final results confirmed 1000 bootstrap samples , much difference results beyond 100 iterations. However, introduction runs faster, demonstrate 10 iterations.  case, bootstrapped results mostly similar single (non-bootstrapped) ALE results. principle, always bootstrap results trust bootstrapped results. unusual result values x_length (length diamond) 6.2 mm higher associated lower diamond prices. compare y_width value (width diamond), suspect length width (, size) diamond become increasingly large, price increases much rapidly width length width inordinately high effect tempered decreased effect length high values. worth exploration real analysis, just introducing key features package.","code":"# Bootstraping is rather slow, so create a smaller subset of new data for demonstration set.seed(0) new_rows <- sample(nrow(diamonds), 200, replace = FALSE) diamonds_small_test <- diamonds[new_rows, ] ale_gam_diamonds_boot <- ALE(   model = gam_diamonds,    data = diamonds_small_test,    # Normally boot_it should be set to at least 100, but just 10 here for a faster demonstration   boot_it = 10 )  # Bootstrapping produces confidence intervals plot(ale_gam_diamonds_boot) |>    print(ncol = 2)"},{"path":"https://tripartio.github.io/ale/articles/ale-intro.html","id":"ale-interactions","dir":"Articles","previous_headings":"","what":"ALE interactions","title":"Introduction to the ale package","text":"Another advantage ALE provides data 2D interactions variables. also implemented ALE() constructor. d2 element x_cols list argument set TRUE, ALE() generates ALE data possible 2D interactions input dataset. change default options (e.g., calculate interactions certain pairs variables), see details help file object: help(ALE). plot() method similarly creates 2D ALE plots ALE object. subset() method ALEPlots extracts new ALEPlots object selected variables interaction terms:  printing plots together, might appear vertically distorted plot forced height. fine-tuned presentation, need refer specific plot. ale package supports standard R formula notation specifying variables. example, can print interaction plot carat depth referring thus: get(diamonds_2D_plots, ~ carat:clarity).  best dataset use illustrate ALE interactions none . expressed graphs ALE y values grey, middle range data. plots, darker squares indicate relative percentage actual data interaction intersection. , little actual data 0.2 carats; much higher carat ranges. Note ALE interactions particular: ALE interaction means two variables composite effect separate independent effects. , course x_length y_width effects price, one-way ALE plots show, interaction additional composite effect. see ALE interaction plots look like presence interactions, see ALEPlot comparison vignette, explains interaction plots detail.","code":"# ALE two-way interactions ale_2D_gam_diamonds <- ALE(   gam_diamonds,   x_cols = list(d2 = TRUE) ) diamonds_2D_plots <- plot(ale_2D_gam_diamonds)  diamonds_2D_plots |>   # Select all 2D interactions that involve 'carat'   subset(list(d2_all = 'carat')) |>    print(ncol = 2) get(diamonds_2D_plots, ~ carat:clarity)"},{"path":"https://tripartio.github.io/ale/articles/ale-small-datasets.html","id":"what-is-a-small-dataset","dir":"Articles","previous_headings":"","what":"What is a “small” dataset?","title":"Analyzing small datasets (fewer than 2000 rows) with ALE","text":"obvious question , “small ‘small’?” complex question way beyond scope vignette try answer rigorously. can simply say key issue stake applying training-test split common machine learning crucial technique increasing generalizability data analysis. , question becomes focused , “small small training-test split machine learning analysis?” rule thumb familiar machine learning requires least 200 rows data predictor variable. , example, five input variables, need least 1000 rows data. note refer size entire dataset minimum size training subset. , carry 80-20 split full dataset (, 80% training set), need least 1000 rows training set another 250 rows test set, minimum 1250 rows. (carry hyperparameter tuning cross validation training set, need even data.) see headed, might quickly realize datasets less 2000 rows probably “small”. can see even many datasets 2000 rows nonetheless “small”, probably need techniques mentioned vignette. begin loading necessary libraries.","code":"library(ale) #>  #> Attaching package: 'ale' #> The following object is masked from 'package:base': #>  #>     get"},{"path":"https://tripartio.github.io/ale/articles/ale-small-datasets.html","id":"attitude-dataset","dir":"Articles","previous_headings":"","what":"attitude dataset","title":"Analyzing small datasets (fewer than 2000 rows) with ALE","text":"analysis, use attitude dataset, built-R: “survey clerical employees large financial organization, data aggregated questionnaires approximately 35 employees 30 (randomly selected) departments.” numbers give percent proportion favourable responses seven questions department. Since ’re talking “small” datasets, figure might well demonstrate principles extremely small examples.","code":""},{"path":"https://tripartio.github.io/ale/articles/ale-small-datasets.html","id":"format","dir":"Articles","previous_headings":"attitude dataset","what":"Format","title":"Analyzing small datasets (fewer than 2000 rows) with ALE","text":"data frame 30 observations 7 variables. first column short names reference, second one variable names data frame:","code":""},{"path":"https://tripartio.github.io/ale/articles/ale-small-datasets.html","id":"source","dir":"Articles","previous_headings":"attitude dataset","what":"Source","title":"Analyzing small datasets (fewer than 2000 rows) with ALE","text":"Chatterjee, S. Price, B. (1977) Regression Analysis Example. New York: Wiley. (Section 3.7, p.68ff 2nd ed.(1991).) first run ALE analysis dataset valid regular dataset, even though small proper training-test split. small-scale demonstration mainly demonstrate ale package valid analyzing even small datasets, just large datasets typically used machine learning.","code":"str(attitude) #> 'data.frame':    30 obs. of  7 variables: #>  $ rating    : num  43 63 71 61 81 43 58 71 72 67 ... #>  $ complaints: num  51 64 70 63 78 55 67 75 82 61 ... #>  $ privileges: num  30 51 68 45 56 49 42 50 72 45 ... #>  $ learning  : num  39 54 69 47 66 44 56 55 67 47 ... #>  $ raises    : num  61 63 76 54 71 54 66 70 71 62 ... #>  $ critical  : num  92 73 86 84 83 49 68 66 83 80 ... #>  $ advance   : num  45 47 48 35 47 34 35 41 31 41 ... summary(attitude) #>      rating        complaints     privileges       learning         raises      #>  Min.   :40.00   Min.   :37.0   Min.   :30.00   Min.   :34.00   Min.   :43.00   #>  1st Qu.:58.75   1st Qu.:58.5   1st Qu.:45.00   1st Qu.:47.00   1st Qu.:58.25   #>  Median :65.50   Median :65.0   Median :51.50   Median :56.50   Median :63.50   #>  Mean   :64.63   Mean   :66.6   Mean   :53.13   Mean   :56.37   Mean   :64.63   #>  3rd Qu.:71.75   3rd Qu.:77.0   3rd Qu.:62.50   3rd Qu.:66.75   3rd Qu.:71.00   #>  Max.   :85.00   Max.   :90.0   Max.   :83.00   Max.   :75.00   Max.   :88.00   #>     critical        advance      #>  Min.   :49.00   Min.   :25.00   #>  1st Qu.:69.25   1st Qu.:35.00   #>  Median :77.50   Median :41.00   #>  Mean   :74.77   Mean   :42.93   #>  3rd Qu.:80.00   3rd Qu.:47.75   #>  Max.   :92.00   Max.   :72.00"},{"path":"https://tripartio.github.io/ale/articles/ale-small-datasets.html","id":"ale-for-ordinary-least-squares-regression-multiple-linear-regression","dir":"Articles","previous_headings":"","what":"ALE for ordinary least squares regression (multiple linear regression)","title":"Analyzing small datasets (fewer than 2000 rows) with ALE","text":"Ordinary least squares (OLS) regression generic multivariate statistical technique. Thus, use baseline illustration help motivate value ALE interpreting analysis small data samples. train OLS model predict average rating: least, ale package useful visualizing effects model variables. Note now, run ALE() bootstrapping (default) small samples require special bootstrap approach, explained . now, using ALE accurately visualize model estimates.  visualization confirms see model coefficients : complaints strong positive effect ratings learning moderate effect. However, ALE indicates stronger effect advance regression coefficients suggest. variables relatively little effect ratings. see shortly proper bootstrapping model can shed light discrepancies.","code":"lm_attitude <- lm(rating ~ ., data = attitude)  summary(lm_attitude) #>  #> Call: #> lm(formula = rating ~ ., data = attitude) #>  #> Residuals: #>      Min       1Q   Median       3Q      Max  #> -10.9418  -4.3555   0.3158   5.5425  11.5990  #>  #> Coefficients: #>             Estimate Std. Error t value Pr(>|t|)     #> (Intercept) 10.78708   11.58926   0.931 0.361634     #> complaints   0.61319    0.16098   3.809 0.000903 *** #> privileges  -0.07305    0.13572  -0.538 0.595594     #> learning     0.32033    0.16852   1.901 0.069925 .   #> raises       0.08173    0.22148   0.369 0.715480     #> critical     0.03838    0.14700   0.261 0.796334     #> advance     -0.21706    0.17821  -1.218 0.235577     #> --- #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 #>  #> Residual standard error: 7.068 on 23 degrees of freedom #> Multiple R-squared:  0.7326, Adjusted R-squared:  0.6628  #> F-statistic:  10.5 on 6 and 23 DF,  p-value: 1.24e-05 ale_lm_attitude_simple <- ALE(lm_attitude)  # Print all plots plot(ale_lm_attitude_simple) |>    print(ncol = 2)"},{"path":"https://tripartio.github.io/ale/articles/ale-small-datasets.html","id":"full-model-bootstrapping","dir":"Articles","previous_headings":"","what":"Full model bootstrapping","title":"Analyzing small datasets (fewer than 2000 rows) with ALE","text":"referred frequently importance bootstrapping. None model results, without ALE, considered reliable without bootstrapped. large datasets whose models properly trained evaluated separate subsets ALE analysis, ALE object can bootstrap ALE results model trained full dataset. However, dataset small subdivided training test sets, entire model bootstrapped, just ALE data single trained model. , multiple models trained, one bootstrap sample. reliable results average results bootstrap models, however many . ModelBoot object automatically carries full-model bootstrapping suitable relatively smaller datasets. Specifically, : Creates multiple bootstrap samples (default 100; user can specify number); Creates model bootstrap sample; Calculates model overall statistics, variable coefficients, ALE values model bootstrap sample; Calculates mean, median, lower upper confidence intervals values across bootstrap samples. constructor S7 ModelBoot object requires model object first argument–R model object can generate numeric predictions. second argument dataset. objects follow standard R modelling conventions, ModelBoot() able automatically recognize parse model object, data object often optional. , creation ModelBoot object: default, ModelBoot object creates 100 bootstrap samples provided dataset creates 100 + 1 models data (one bootstrap sample original dataset). (However, illustration runs faster, demonstrate 10 iterations.) Beyond ALE data, also provides bootstrapped overall model statistics (provided broom::glance()) bootstrapped model coefficients (provided broom::tidy()). default options broom::glance(), broom::tidy(), ALE() can customized, along defaults ModelBoot constructor, number bootstrap iterations. can consult help file details help(ModelBoot). ModelBoot following properties (depending values requested output argument: model_stats: bootstrapped results broom::glance() model_coefs: bootstrapped results broom::tidy() ale: bootstrapped ALE data plots boot_data: full bootstrap data (returned default) bootstrapped overall model statistics: bootstrapped model coefficients: can visualize results ALE plots.  draw formal conclusions analysis, need formal statistical framework based ALE, describe vignette ALE-based statistics statistical inference. However, can generally infer : Complaints handled around 55% led -average overall ratings; complaints handled around 72% associated -average overall ratings. 95% bootstrapped confidence intervals every variable fully overlap almost entirety median. Thus, despite general trends data (particular learning’s positive trend advance’s negative trend), data seem support claims factor convincingly meaningful effect ratings. Although basic demonstration, readily shows crucial proper bootstrapping make meaningful inferences data analysis.","code":"mb_lm <- ModelBoot(   lm_attitude,   boot_it = 10  # 100 by default but reduced here for a faster demonstration ) mb_lm@model_stats #> # A tibble: 12 × 7 #>    name          boot_valid conf.low       median       mean  conf.high       sd #>    <chr>              <dbl>    <dbl>        <dbl>      <dbl>      <dbl>    <dbl> #>  1 r.squared         NA      6.78e-1  0.822        0.793      0.874      7.58e-2 #>  2 adj.r.squared     NA      5.94e-1  0.775        0.739      0.841      9.56e-2 #>  3 sigma             NA      4.62e+0  5.91         6.03       7.65       1.05e+0 #>  4 statistic         NA      8.07e+0 17.7         16.9       26.7        6.86e+0 #>  5 p.value           NA      3.53e-9  0.000000159  0.0000203  0.0000922  3.62e-5 #>  6 df                NA      6   e+0  6            6          6          0       #>  7 df.residual       NA      2.3 e+1 23           23         23          0       #>  8 nobs              NA      3   e+1 30           30         30          0       #>  9 mae                7.08   5.70e+0 NA           NA         10.2        1.62e+0 #> 10 sa_mae             0.597  3.82e-1 NA           NA          0.709      1.21e-1 #> 11 rmse               8.34   6.47e+0 NA           NA         11.9        1.85e+0 #> 12 sa_rmse            0.638  4.59e-1 NA           NA          0.748      9.47e-2 mb_lm@model_coefs #> # A tibble: 7 × 6 #>   term        conf.low  median    mean conf.high std.error #>   <chr>          <dbl>   <dbl>   <dbl>     <dbl>     <dbl> #> 1 (Intercept) -15.4     6.57    8.40      37.1      19.9   #> 2 complaints    0.370   0.556   0.561      0.772     0.144 #> 3 privileges   -0.325   0.0323 -0.0575     0.187     0.199 #> 4 learning      0.0385  0.233   0.227      0.434     0.131 #> 5 raises       -0.0105  0.169   0.215      0.472     0.179 #> 6 critical     -0.303   0.120   0.0300     0.302     0.235 #> 7 advance      -0.509  -0.0816 -0.173      0.133     0.239 plot(mb_lm) |>    print(ncol = 2)"},{"path":"https://tripartio.github.io/ale/articles/ale-small-datasets.html","id":"ale-for-generalized-additive-models-gam","dir":"Articles","previous_headings":"","what":"ALE for generalized additive models (GAM)","title":"Analyzing small datasets (fewer than 2000 rows) with ALE","text":"major limitation OLS regression models relationships x variables y straight lines. unlikely relationships truly linear. OLS accurately capture non-linear relationships. samples relatively small, use generalized additive models (GAM) modelling. grossly oversimplify things, GAM extension statistical regression analysis lets model fit flexible patterns data instead restricted best-fitting straight line. ideal approach samples small machine learning provides flexible curves unlike ordinary least squares regression yet overfit excessively machine learning techniques working small samples. GAM, variables want become flexible need wrapped s (smooth) function, e.g., s(complaints). example, smooth numerical input variables: comparing adjusted R2 OLS model (0.663) GAM model (0.776), can readily see GAM model provides superior fit data. understand variables responsible relationship, results smooth terms GAM readily interpretable. need visualized effective interpretation—ALE perfect purposes.  Compared OLS results , GAM results provide quite surprise concerning shape effect employees’ perceptions department critical–seems low criticism high criticism negatively affect ratings. However, trying interpret results, must remember results bootstrapped simply reliable. , let us see bootstrapping give us.  bootstrapped GAM results tell rather different story OLS results. case, bootstrap confidence bands variables (even complaints) fully overlap median. Even average slopes vanished variables except complaint, remains positive, yet insignificant wide confidence interval. , conclude? First, tempting retain OLS results tell interesting story. consider irresponsible since GAM model clearly superior terms adjusted R2: model far reliably tells us really going . tell us? seems positive effect handled complaints ratings (higher percentage complaints handled, higher average rating), data allow us sufficiently certain generalize results. insufficient evidence variables effect . doubt, inconclusive results dataset small (30 rows). dataset even double size might show significant effects least complaints, variables.","code":"gam_attitude <- mgcv::gam(   rating ~ complaints + privileges + s(learning) +     raises + s(critical) + advance,   data = attitude) summary(gam_attitude) #>  #> Family: gaussian  #> Link function: identity  #>  #> Formula: #> rating ~ complaints + privileges + s(learning) + raises + s(critical) +  #>     advance #>  #> Parametric coefficients: #>             Estimate Std. Error t value Pr(>|t|)     #> (Intercept) 36.97245   11.60967   3.185 0.004501 **  #> complaints   0.60933    0.13297   4.582 0.000165 *** #> privileges  -0.12662    0.11432  -1.108 0.280715     #> raises       0.06222    0.18900   0.329 0.745314     #> advance     -0.23790    0.14807  -1.607 0.123198     #> --- #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 #>  #> Approximate significance of smooth terms: #>               edf Ref.df     F p-value   #> s(learning) 1.923  2.369 3.761  0.0312 * #> s(critical) 2.296  2.862 3.272  0.0565 . #> --- #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 #>  #> R-sq.(adj) =  0.776   Deviance explained = 83.9% #> GCV = 47.947  Scale est. = 33.213    n = 30 ale_gam_attitude_simple <- ALE(gam_attitude)  plot(ale_gam_attitude_simple) |>    print(ncol = 2) mb_gam <- ModelBoot(   gam_attitude,    boot_it = 10,  # 100 by default but reduced here for a faster demonstration   pred_type = 'response'   ) mb_gam@model_stats #> # A tibble: 9 × 7 #>   name          boot_valid conf.low median   mean conf.high      sd #>   <chr>              <dbl>    <dbl>  <dbl>  <dbl>     <dbl>   <dbl> #> 1 df                NA        8.18  14.5   14.4      20.6    4.62   #> 2 df.residual       NA        9.45  15.5   15.6      21.8    4.62   #> 3 nobs              NA       30     30     30        30      0      #> 4 adj.r.squared     NA        0.851  0.981  0.943     1.000  0.0675 #> 5 npar              NA       23     23     23        23      0      #> 6 mae               12.1      6.20  NA     NA        53.0   16.6    #> 7 sa_mae             0.364   -1.25  NA     NA         0.681  0.653  #> 8 rmse              15.1      7.49  NA     NA        68.8   22.1    #> 9 sa_rmse            0.383   -1.41  NA     NA         0.699  0.730 mb_gam@model_coefs #> # A tibble: 2 × 6 #>   term        conf.low median  mean conf.high std.error #>   <chr>          <dbl>  <dbl> <dbl>     <dbl>     <dbl> #> 1 s(learning)     1.20   4.55  4.92      8.98      3.34 #> 2 s(critical)     1.97   4.56  4.49      7.12      2.19 plot(mb_gam) |>    print(ncol = 2)"},{"path":"https://tripartio.github.io/ale/articles/ale-small-datasets.html","id":"model_call_string-argument-for-non-standard-models","dir":"Articles","previous_headings":"","what":"model_call_string argument for non-standard models","title":"Analyzing small datasets (fewer than 2000 rows) with ALE","text":"ModelBoot() constructor accesses model object internally modifies retrain model bootstrapped datasets. able automatically manipulate R model objects used statistical analysis. However, object follow standard conventions R model objects, ModelBoot() might able manipulate . , function fail early appropriate error message. case, user must specify model_call_string argument character string full call model boot_data data argument call. (boot_data placeholder bootstrap datasets ModelBoot() constructor internally work .) show works, let’s pretend mgcv::gam object needs special treatment. construct, model_call_string, must first execute model make sure works. earlier repeat demonstration ’re sure model call works, model_call_string constructed three simple steps: Wrap entire call (everything right assignment operator <-) quotes. Replace dataset data argument boot_data. Pass quoted string ModelBoot() model_call_string argument (argument must explicitly named). , form constructing ModelBoot non-standard model object type: Everything else works usual.","code":"gam_attitude_again <- mgcv::gam(   rating ~ complaints + privileges + s(learning) +     raises + s(critical) + advance,   data = attitude) summary(gam_attitude_again) #>  #> Family: gaussian  #> Link function: identity  #>  #> Formula: #> rating ~ complaints + privileges + s(learning) + raises + s(critical) +  #>     advance #>  #> Parametric coefficients: #>             Estimate Std. Error t value Pr(>|t|)     #> (Intercept) 36.97245   11.60967   3.185 0.004501 **  #> complaints   0.60933    0.13297   4.582 0.000165 *** #> privileges  -0.12662    0.11432  -1.108 0.280715     #> raises       0.06222    0.18900   0.329 0.745314     #> advance     -0.23790    0.14807  -1.607 0.123198     #> --- #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 #>  #> Approximate significance of smooth terms: #>               edf Ref.df     F p-value   #> s(learning) 1.923  2.369 3.761  0.0312 * #> s(critical) 2.296  2.862 3.272  0.0565 . #> --- #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 #>  #> R-sq.(adj) =  0.776   Deviance explained = 83.9% #> GCV = 47.947  Scale est. = 33.213    n = 30 mb_gam_non_standard <- ModelBoot(   gam_attitude_again,   model_call_string = 'mgcv::gam(     rating ~ complaints + privileges + s(learning) +       raises + s(critical) + advance,     data = boot_data)',    boot_it = 10  # 100 by default but reduced here for a faster demonstration ) mb_gam_non_standard@model_stats #> # A tibble: 9 × 7 #>   name          boot_valid conf.low median   mean conf.high      sd #>   <chr>              <dbl>    <dbl>  <dbl>  <dbl>     <dbl>   <dbl> #> 1 df                NA        8.18  14.5   14.4      20.6    4.62   #> 2 df.residual       NA        9.45  15.5   15.6      21.8    4.62   #> 3 nobs              NA       30     30     30        30      0      #> 4 adj.r.squared     NA        0.851  0.981  0.943     1.000  0.0675 #> 5 npar              NA       23     23     23        23      0      #> 6 mae               12.1      6.20  NA     NA        53.0   16.6    #> 7 sa_mae             0.364   -1.25  NA     NA         0.681  0.653  #> 8 rmse              15.1      7.49  NA     NA        68.8   22.1    #> 9 sa_rmse            0.383   -1.41  NA     NA         0.699  0.730"},{"path":"https://tripartio.github.io/ale/articles/ale-statistics.html","id":"example-dataset","dir":"Articles","previous_headings":"","what":"Example dataset","title":"ALE-based statistics for statistical inference and effect sizes","text":"demonstrate ALE statistics using dataset composed transformed mgcv package. package required create generalized additive model (GAM) use demonstration. (Strictly speaking, source datasets nlme package, loaded automatically load mgcv package.) code generate data work : structure 160 rows, refers school whose students taken mathematics achievement test. describe data based documentation nlme package details quite clear: particular note variable rand_norm. added completely random variable (normal distribution) demonstrate randomness looks like analysis. (However, selected specific random seed 6 highlights particularly interesting points.) outcome variable focus analysis math_avg, average mathematics achievement scores students school. descriptive statistics:","code":"# Create and prepare the data  # Specific seed chosen to illustrate the spuriousness of the random variable set.seed(6)    math <-    # Start with math achievement scores per student   MathAchieve |>    as_tibble() |>    mutate(     school = School |> as.character() |>  as.integer(),     minority = Minority == 'Yes',     female = Sex == 'Female'   ) |>    # summarize the scores to give per-school values   summarize(     .by = school,     minority_ratio = mean(minority),     female_ratio = mean(female),     math_avg = mean(MathAch),   ) |>    # merge the summarized student data with the school data   inner_join(     MathAchSchool |>        mutate(school = School |> as.character() |>  as.integer()),     by = c('school' = 'school')   ) |>    mutate(     public = Sector == 'Public',     high_minority = HIMINTY == 1,   ) |>    select(-School, -Sector, -HIMINTY) |>    rename(     size = Size,     academic_ratio = PRACAD,     discrim = DISCLIM,     mean_ses = MEANSES,   ) |>    # Remove ID column for analysis   select(-school) |>    select(     math_avg, size, public, academic_ratio,     female_ratio, mean_ses, minority_ratio, high_minority, discrim,     everything()   ) |>    mutate(     rand_norm = rnorm(nrow(MathAchSchool))    )  glimpse(math) #> Rows: 160 #> Columns: 10 #> $ math_avg       <dbl> 9.715447, 13.510800, 7.635958, 16.255500, 13.177687, 11… #> $ size           <dbl> 842, 1855, 1719, 716, 455, 1430, 2400, 899, 185, 1672, … #> $ public         <lgl> TRUE, TRUE, TRUE, FALSE, FALSE, TRUE, TRUE, FALSE, FALS… #> $ academic_ratio <dbl> 0.35, 0.27, 0.32, 0.96, 0.95, 0.25, 0.50, 0.96, 1.00, 0… #> $ female_ratio   <dbl> 0.5957447, 0.4400000, 0.6458333, 0.0000000, 1.0000000, … #> $ mean_ses       <dbl> -0.428, 0.128, -0.420, 0.534, 0.351, -0.014, -0.007, 0.… #> $ minority_ratio <dbl> 0.08510638, 0.12000000, 0.97916667, 0.40000000, 0.72916… #> $ high_minority  <lgl> FALSE, FALSE, TRUE, FALSE, TRUE, FALSE, FALSE, FALSE, F… #> $ discrim        <dbl> 1.597, 0.174, -0.137, -0.622, -1.694, 1.535, 2.016, -0.… #> $ rand_norm      <dbl> 0.26960598, -0.62998541, 0.86865983, 1.72719552, 0.0241… summary(math$math_avg) #>    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.  #>    4.24   10.47   12.90   12.62   14.65   19.72"},{"path":"https://tripartio.github.io/ale/articles/ale-statistics.html","id":"full-model-bootstrap","dir":"Articles","previous_headings":"","what":"Full model bootstrap","title":"ALE-based statistics for statistical inference and effect sizes","text":"Now create model compute statistics . relatively small dataset, carry full model bootstrapping ModelBoot object. First, create generalized additive model (GAM) can capture non-linear relationships data.","code":"gam_math <- gam(      math_avg ~ public + high_minority +      s(size) + s(academic_ratio) + s(female_ratio) + s(mean_ses) +       s(minority_ratio) + s(discrim) + s(rand_norm),      data = math    )  gam_math #>  #> Family: gaussian  #> Link function: identity  #>  #> Formula: #> math_avg ~ public + high_minority + s(size) + s(academic_ratio) +  #>     s(female_ratio) + s(mean_ses) + s(minority_ratio) + s(discrim) +  #>     s(rand_norm) #>  #> Estimated degrees of freedom: #> 1.00 6.34 2.74 8.66 5.27 1.00 1.38  #>  total = 29.39  #>  #> GCV score: 2.158011"},{"path":"https://tripartio.github.io/ale/articles/ale-statistics.html","id":"create-p-value-distribution-objects","dir":"Articles","previous_headings":"Full model bootstrap","what":"Create p-value distribution objects","title":"ALE-based statistics for statistical inference and effect sizes","text":"bootstrap model create ALE data, important preliminary step goal analyze ALE statistics. statistics calculated dataset, randomness statistic values procedure give us. quantify randomness, want obtain p-values statistics. P-values standard statistics based assumption statistics fit distribution another (e.g., Student’s t, χ2\\chi^2, etc.). distributional assumptions, p-values can calculated quickly. However, key characteristic ALE distributional assumptions: ALE data description model’s characterization data given . Accordingly, ALE statistics assume distribution, either. implication p-values distribution data must discovered simulation rather calculated based distributional assumptions. procedure calculating p-values following: random variable added dataset. model retrained variables including new random variable. ALE statistics calculated random variable. procedure repeated 1,000 times get 1,000 ALE statistic values 1,000 random variables. p-values calculated based frequency times random variables obtain specific statistic values. can imagine, procedure slow: involves retraining entire model full dataset 1,000 times. ale package speeds process significantly parallel processing (implemented default), still involves speed retraining model hundreds times. avoid repeat procedure several times (case exploratory analyses), can create ALEpDist object can run given model-dataset pair. ALEpDist object used generate p-values based statistics variable model-dataset pair. generates p-values passed ALE() ModelBoot() constructors. large datasets, process generating ALEpDist object sped using subset data running fewer 1,000 random iterations setting rand_it argument. However, ALEpDist() constructor allow fewer 100 iterations, otherwise p-values thus generated meaningless.) now demonstrate create ALEpDist object case. can now proceed bootstrap model ALE analysis.","code":"# # To generate the code, uncomment the following lines. # # But it is slow because it retrains the model 1000 times, so this vignette loads a pre-created ALEpDist object. # # For standard models like mgcv::gam that store their data, # # there is no need to specify the data argument. # gam_math_p_dist <- ALEpDist(gam_math) # saveRDS(gam_math_p_dist, file.choose()) gam_math_p_dist <- url('https://github.com/tripartio/ale/raw/main/download/gam_math_p_dist.0.5.0.rds') |>    readRDS()"},{"path":"https://tripartio.github.io/ale/articles/ale-statistics.html","id":"bootstrap-the-model-with-p-values","dir":"Articles","previous_headings":"Full model bootstrap","what":"Bootstrap the model with p-values","title":"ALE-based statistics for statistical inference and effect sizes","text":"default, ModelBoot object runs 100 bootstrap iterations; can controlled boot_it argument. Bootstrapping usually rather slow, even small datasets, since entire process repeated many times. ModelBoot() constructor speeds process significantly parallel processing (implemented default), still involves retraining entire model dozens times. default 100 sufficiently stable model building, want run bootstrapped algorithm several times want slow time. definitive conclusions, run 1,000 bootstraps confirm results 100 bootstraps. can see bootstrapped values various overall model statistics printing model_stats property model bootstrap object: names columns follow broom package conventions: name specific overall model statistic described row. boot_valid bootstrap-validated value performance metric specified name column. available machine-learning–style performance metrics like MAE AUC; validated (bootstrap validation .632 correction)[https://www.jstor.org/stable/2288636]. conf.low conf.high lower upper confidence intervals respectively. ModelBoot defaults 95% confidence interval; can changed setting boot_alpha argument constructor (default 0.05 95% confidence interval). median mean average bootstrapped estimates statistic. relevant bootstrap-validated metrics values calculated .632 correction. sd standard deviation bootstrapped estimate. focus, however, vignette effects individual variables. available model_coefs element model bootstrap object: vignette, go details GAM models work (can learn Noam Ross’s excellent tutorial). However, model illustration , estimates parametric variables (non-numeric ones model) interpreted regular statistical regression coefficients whereas estimates non-parametric smoothed variables (whose variable names encapsulated smooth s() function) actually estimates expected degrees freedom (EDF GAM). smooth function s() lets GAM model numeric variables flexible curves might fit data better straight line. estimate values smooth variables straightforward interpret, suffice say completely different regular regression coefficients. ale package uses bootstrap-based confidence intervals, p-values assume predetermined distributions, determine statistical significance. Although quite simple interpret counting number stars next p-value, complicated, either. Based default 95% confidence intervals, coefficient statistically significant conf.low conf.high positive negative. can filter results criterion: statistical significance estimate (EDF) smooth terms meaningless EDF go 1.0. Thus, even random term s(rand_norm) appears “statistically significant”. values non-smooth (parametric terms) public high_minority considered . , find neither coefficient estimates public high_minority effect statistically significantly different zero. (intercept conceptually meaningful ; statistical artifact.) initial analysis highlights two limitations classical hypothesis-testing analysis. First, might work suitably well use models traditional linear regression coefficients. use advanced models like GAM flexibly fit data, interpret coefficients meaningfully clear reach inferential conclusions. Second, basic challenge models based general linear model (including GAM almost statistical analyses) coefficient significance compares estimates null hypothesis effect. However, even effect, might practically meaningful. see, ALE-based statistics explicitly tailored emphasize practical implications beyond notion mere “statistical significance”.","code":"# # To generate the code, uncomment the following lines. # # But bootstrapping is slow because it retrains the model, so this vignette loads a pre-created ale_boot object. # mb_gam_math <- ModelBoot( #   gam_math, #   # Pass the ALEpDist object so that p-values will be generated #   ale_p = gam_math_p_dist, #   # For the GAM model coefficients, show details of all variables, parametric or not #   tidy_options = list(parametric = TRUE), #   # tidy_options = list(parametric = NULL), #   boot_it = 100  # default # ) # saveRDS(mb_gam_math, file.choose()) mb_gam_math <- url('https://github.com/tripartio/ale/raw/main/download/mb_gam_math_stats_vignette.0.5.0.rds') |>    readRDS() mb_gam_math@model_stats #> # A tibble: 9 × 7 #>   name          boot_valid conf.low  median    mean conf.high     sd #>   <chr>              <dbl>    <dbl>   <dbl>   <dbl>     <dbl>  <dbl> #> 1 df                NA       29.5    42.3    42.6      58.0   7.78   #> 2 df.residual       NA      102.    118.    117.      131.    7.78   #> 3 nobs              NA      160     160     160       160     0      #> 4 adj.r.squared     NA        0.844   0.896   0.895     0.938 0.0249 #> 5 npar              NA       66      66      66        66     0      #> 6 mae                1.35     1.25   NA      NA         2.13  0.211  #> 7 sa_mae             0.726    0.541  NA      NA         0.754 0.0512 #> 8 rmse               1.71     1.58   NA      NA         2.77  0.294  #> 9 sa_rmse            0.724    0.574  NA      NA         0.748 0.0528 mb_gam_math@model_coefs #> # A tibble: 3 × 6 #>   term              conf.low median   mean conf.high std.error #>   <chr>                <dbl>  <dbl>  <dbl>     <dbl>     <dbl> #> 1 (Intercept)         11.7   12.7   12.7      13.6       0.484 #> 2 publicTRUE          -2.02  -0.652 -0.689     0.415     0.637 #> 3 high_minorityTRUE   -0.318  1.05   1.03      2.32      0.676 mb_gam_math@model_coefs |>    # filter is TRUE if conf.low and conf.high are both positive or both negative because   # multiplying two numbers of the same sign results in a positive number.   filter((conf.low * conf.high) > 0) #> # A tibble: 1 × 6 #>   term        conf.low median  mean conf.high std.error #>   <chr>          <dbl>  <dbl> <dbl>     <dbl>     <dbl> #> 1 (Intercept)     11.7   12.7  12.7      13.6     0.484"},{"path":"https://tripartio.github.io/ale/articles/ale-statistics.html","id":"ale-effect-size-measures","dir":"Articles","previous_headings":"","what":"ALE effect size measures","title":"ALE-based statistics for statistical inference and effect sizes","text":"ALE developed graphically display relationship predictor variables model outcome regardless nature model. Thus, proceed describe extension effect size measures based ALE, let us first briefly examine ALE plots variable.","code":""},{"path":"https://tripartio.github.io/ale/articles/ale-statistics.html","id":"ale-plots-with-p-values","dir":"Articles","previous_headings":"ALE effect size measures","what":"ALE plots with p-values","title":"ALE-based statistics for statistical inference and effect sizes","text":"can see variables seem sort mean effect across various values. However, statistical inference, focus must bootstrap intervals. Crucial interpretation middle grey band indicates median ± 5% random values. , explain exactly ALE range (ALER) means, now, can say : approximate middle grey band median y outcome variables dataset (math_avg, case). middle tick right y-axis indicates exact median. (prefer, plot() function lets centre data mean zero ale_centre argument.) call grey band “ALER band”. 95% random variables ALE values fully lay within ALER band. dashed lines ALER band expand boundaries 99% random variables constrained. boundaries considered demarcating extended outer ALER band. idea ALE values predictor variable falls fully within ALER band, greater effect 95% purely random variables. Moreover, consider effect ALE plot statistically significant (, non-random), overlap bootstrapped confidence regions predictor variable ALER band. (threshold p-values, use conventional defaults 0.05 95% confidence 0.01 99% confidence, value can changed aler_alpha argument.) categorical variables (public high_minority ), confidence interval bars categories overlap ALER band. confidence interval bars indicate two useful pieces information us. compare ALER band, overlap lack thereof tells us practical significance category. compare confidence bars one category others, allows us assess category statistically significant effect different categories; equivalent regular interpretation coefficients GAM GLM models. cases, confidence interval bars TRUE FALSE categories overlap , indicating statistically significant difference categories. addition, confidence interval band overlaps ALER band, indicating none effects meaningfully different random results, either. numeric variables, confidence regions overlap ALER band domains predictor variables except regions examine . extreme points variable (except discrim female_ratio) usually either slightly slightly ALER band, indicating extreme values extreme effects: math achievement increases increasing school size, academic track ratio, mean socioeconomic status, whereas decreases increasing minority ratio. ratio females discrimination climate overlap ALER band entirety domains, data support apparent trends. particular interest random variable rand_norm, whose average ALE appears show sort pattern. However, note 95% confidence intervals use mean retry analysis 100 different random seeds, expect around five random variables partially escape bounds ALER band. return implications random variables ALE analysis.","code":"mb_gam_plots <- plot(mb_gam_math) print(mb_gam_plots, ncol = 2)"},{"path":"https://tripartio.github.io/ale/articles/ale-statistics.html","id":"ale-plots-without-p-values","dir":"Articles","previous_headings":"ALE effect size measures","what":"ALE plots without p-values","title":"ALE-based statistics for statistical inference and effect sizes","text":"continue, let us take brief detour see get create ModelBoot object without giving ALEpDist object. might forget , want see quick results without slow process first generating ALEpDist object. Let us create another ModelBoot object, time, one without p-values.  absence p-values, ale packages uses simpler visualizations offer meaningful results. ALER band; simply reference lines indicate interquartile range outcome values, , 25th 75th percentiles, median . references give us precise measure strength effects, give general, intuitive indication. rest article, analyze results ALER bands generated p-values, though briefly revisit ALE plots without p-values.","code":"# # To generate the code, uncomment the following lines. # # But bootstrapping is slow because it retrains the model, so this vignette loads a pre-created ale_boot object. # mb_gam_no_p <- ModelBoot( #   gam_math, #   ale_p = NULL,  # disable ALE p-values #   # For the GAM model coefficients, show details of all variables, parametric or not #   tidy_options = list(parametric = TRUE), #   # tidy_options = list(parametric = NULL), #   boot_it = 40  # 100 by default but reduced here for a faster demonstration # ) # saveRDS(mb_gam_no_p, file.choose()) mb_gam_no_p <- url('https://github.com/tripartio/ale/raw/main/download/mb_gam_no_p_stats_vignette.0.5.0.rds') |>    readRDS()  plot(mb_gam_no_p) |>    print(ncol = 2)"},{"path":"https://tripartio.github.io/ale/articles/ale-statistics.html","id":"ale-effect-size-measures-on-the-scale-of-the-y-outcome-variable","dir":"Articles","previous_headings":"ALE effect size measures","what":"ALE effect size measures on the scale of the y outcome variable","title":"ALE-based statistics for statistical inference and effect sizes","text":"Although ALE plots allow rapid intuitive conclusions statistical inference, often helpful summary numbers quantify average strengths effects variable. Thus, developed collection effect size measures based ALE tailored intuitive interpretation. understand intuition underlying various ALE effect size measures, useful first examine ALE effects plot, graphically summarizes effect sizes variables ALE analysis. generated get() method ALEPlots object type = 'effect':  plot unusual, requires explanation: y- (vertical) axis displays x variables, rather x-axis. consistent effect size plots list full names variables. readable list labels y-axis way around. x- (horizontal) axis thus displays y (outcome) variable. two representations axis, one bottom one top. bottom typical axis outcome variable, case, math_avg. scaled expected. case, axis breaks default four six units 5 20, evenly spaced. top, outcome variable expressed percentiles ranging -50‰ median (minimum outcome value dataset) +50‰ median (maximum). divided 10 deciles 10‰ . percentiles usually evenly distributed dataset, decile breaks evenly spaced. Thus, plot two x-axes, lower one units outcome variable upper one percentiles outcome variable. reduce confusion, major vertical gridlines slightly darker align units outcome (lower axis) minor vertical gridlines slightly lighter align percentiles (upper axis). vertical grey band middle NALED band. width 0.05 p-value NALED (explained ). , 95% random variables NALED equal smaller width. variables horizontal axis sorted decreasing ALED NALED value (explained ). Although somewhat confusing two axes, percentiles direct transformation raw outcome values. first two base ALE effect size measures units outcome variable normalized versions percentiles outcome. Thus, plot can display two kinds measures simultaneously. Referring plot can help understand measures, proceed explain detail. explain measures detail, must reiterate timeless reminder correlation causation. , none scores necessarily means x variable “predictor” causes certain effect y outcome; can say ALE effect size measures indicate associated related variations two variables.","code":"get(mb_gam_plots, type = 'effect')"},{"path":"https://tripartio.github.io/ale/articles/ale-statistics.html","id":"ale-range-aler","dir":"Articles","previous_headings":"ALE effect size measures > ALE effect size measures on the scale of the y outcome variable","what":"ALE range (ALER)","title":"ALE-based statistics for statistical inference and effect sizes","text":"easiest ALE statistic understand ALE range (ALER), begin . simply range minimum maximum ale_y value variable. Mathematically, ALER(ale_y)={min(ale_y),max(ale_y)}\\mathrm{ALER}(\\mathrm{ale\\_y}) = \\{ \\min(\\mathrm{ale\\_y}), \\max(\\mathrm{ale\\_y}) \\} ale_y\\mathrm{ale\\_y} vector ALE y values variable. ALE effect size measures centred zero consistent regardless user chooses centre plots zero, median, mean. Specifically, aler_min: minimum ale_y value variable. aler_max: maximum ale_y value variable. ALER shows extreme values variable’s effect outcome. effects plot , indicated extreme ends horizontal bars variable. can access ALE effect size measures ale$stats element bootstrap result object, multiple views. focus measures specific variable, can access ale$stats$by_term element. Let’s focus public. ALE plot:  effect size measures categorical public: see public ALER [-0.34, 0.42]. consider median math score dataset 12.9, ALER indicates minimum ALE y value public (public == TRUE) -0.34 median. shown 12.6 mark plot . maximum (public == FALSE) 0.42 median, shown 13.3 point . unit ALER unit outcome variable; case, math_avg ranging 2 20. matter average ALE values might , ALER quickly shows minimum maximum effects value x variable y variable. contrast, let us look numeric variable, academic_ratio:  ALE effect size measures: ALER academic_ratio considerably broader -4.09 2.09 median.","code":"get(mb_gam_plots, 'public') get(mb_gam_math, 'public', stats = 'all') #> # A tibble: 6 × 7 #>   term   statistic estimate conf.low median   mean conf.high #>   <fct>  <fct>        <dbl>    <dbl>  <dbl>  <dbl>     <dbl> #> 1 public aled         0.375   0.0184  0.332  0.375    0.968  #> 2 public aler_min    -0.344  -0.846  -0.320 -0.344   -0.0201 #> 3 public aler_max     0.421   0.0174  0.369  0.421    1.20   #> 4 public naled        5.03    0       4.72   5.03    11.7    #> 5 public naler_min   -4.26  -11.2    -3.41  -4.26     0      #> 6 public naler_max    6.07    0       5.62   6.07    17.8 get(mb_gam_plots, 'academic_ratio') get(mb_gam_math, 'academic_ratio', stats = 'all') #> # A tibble: 6 × 7 #>   term           statistic estimate conf.low  median    mean conf.high #>   <fct>          <fct>        <dbl>    <dbl>   <dbl>   <dbl>     <dbl> #> 1 academic_ratio aled         0.810    0.408   0.795   0.810     1.29  #> 2 academic_ratio aler_min    -4.09    -7.78   -4.41   -4.09     -0.568 #> 3 academic_ratio aler_max     2.09     0.895   2.08    2.09      3.43  #> 4 academic_ratio naled       10.2      4.39   10.2    10.2      15.9   #> 5 academic_ratio naler_min  -33.3    -48.1   -38.8   -33.3      -5.23  #> 6 academic_ratio naler_max   28.1     11.7    27.7    28.1      42.3"},{"path":"https://tripartio.github.io/ale/articles/ale-statistics.html","id":"ale-deviation-aled","dir":"Articles","previous_headings":"ALE effect size measures > ALE effect size measures on the scale of the y outcome variable","what":"ALE deviation (ALED)","title":"ALE-based statistics for statistical inference and effect sizes","text":"ALE range shows extreme effects variable might outcome, ALE deviation indicates average effect full domain values. Based zero-centred ALE values, ALED conceptually similar weighted mean absolute error (MAE) ALE y values. Mathematically, ALED(ale_y,ale_n)=∑=1k|ale_yi×ale_ni|∑=1kale_ni \\mathrm{ALED}(\\mathrm{ale\\_y}, \\mathrm{ale\\_n}) = \\frac{\\sum_{=1}^{k} \\left| \\mathrm{ale\\_y}_i \\times \\mathrm{ale\\_n}_i \\right|}{\\sum_{=1}^{k} \\mathrm{ale\\_n}_i} ii index kk ALE x intervals variable (categorical variable, number distinct categories), ale_yi\\mathrm{ale\\_y}_i ALE y value iith ALE x interval, ale_ni\\mathrm{ale\\_n}_i number rows iith ALE x interval. However, whereas equation describes ALED non-numeric values ALE x interval distinct x value corresponding ALE y value, requires adjustment numeric x values .ceil represents upper bound bin. Thus, numeric values, two adjustments needed. First, convert .ceil boundaries proper discrete bins, number rows (.n) first element (representing minimum) added second element. Second, rather .y values bin boundaries, .y bin recalculated midpoint consecutive .ceil boundaries. adjusted ALED formula numeric x variables given following equation: ALED(ale_y,ale_n)=∑=1k−1|12(ale_yi+ale_yi+1)×ale_ni′|∑=1k−1ale_ni′ \\mathrm{ALED}(\\mathrm{ale\\_y}, \\mathrm{ale\\_n}) = \\frac{\\sum_{=1}^{k-1} \\left|  \\frac{1}{2} \\left( \\mathrm{ale\\_y}_i + \\mathrm{ale\\_y}_{+1} \\right) \\times \\mathrm{ale\\_n}_i' \\right|}{\\sum_{=1}^{k-1} \\mathrm{ale\\_n}_i'}  : ale_ni′{ale\\_n}_i' adjusted number rows iith interval, first element adjusted include number rows minimum interval. ale_ni′={ale_ni+ale_ni+1if =1ale_niotherwise \\mathrm{ale\\_n}_i' =  \\begin{cases} \\mathrm{ale\\_n}_i + \\mathrm{ale\\_n}_{+1} & \\text{} = 1 \\\\ \\mathrm{ale\\_n}_i & \\text{otherwise} \\end{cases} 12(ale_yi+ale_yi+1)\\frac{1}{2} \\left( \\mathrm{ale\\_y}_i + \\mathrm{ale\\_y}_{+1} \\right) represents recalculated ALE yy value bin, taken midpoint consecutive ale_yale\\_y values. Based ALED, can say average effect math scores whether school public Catholic sector 0.38 (, range 2 20). effects plot , ALED indicated white box bounded parentheses ( ). centred median, can readily see average effect school sector barely exceeds limits ALER band, indicating barely exceeds threshold practical relevance. average effect ratio academic track students slightly higher 0.81. can see plot slightly exceeds ALER band sides, indicating slightly stronger effect. comment values variables discuss normalized versions scores, proceed next.","code":""},{"path":"https://tripartio.github.io/ale/articles/ale-statistics.html","id":"normalized-ale-effect-size-measures","dir":"Articles","previous_headings":"ALE effect size measures","what":"Normalized ALE effect size measures","title":"ALE-based statistics for statistical inference and effect sizes","text":"Since ALER ALED scores scaled range y given dataset, scores compared across datasets. Thus, present normalized versions intuitive, comparable values. intuitive interpretation, normalize scores minimum, median, maximum dataset. principle, divide zero-centred y values dataset two halves: lower half 0th 50th percentile (median) upper half 50th 100th percentile. (Note median included halves). zero-centred ALE y values, negative zero values converted percentile score relative lower half original y values positive ALE y values converted percentile score relative upper half. (Technically, percentile assignment called empirical cumulative distribution function (ECDF) half.) half divided two scale 0 50 together can represent 100 percentiles. (Note: centred ALE y value exactly 0 occurs, choose include score zero ALE y lower half analogous 50th percentile values, intuitively belongs lower half 100 percentiles.) transformed maximum ALE y scaled percentile 0 100%. notable complication. normalization smoothly distributes ALE y values many distinct values, distinct ALE y values, even minimal ALE y deviation can relatively large percentile difference. ALE y value less difference median data value either immediately median, consider virtually effect. Thus, normalization sets minimal ALE y values zero. formula : norm_ale_y=100×{0if max(centred_y<0)≤ale_y≤min(centred_y>0),−ECDFy≤0(ale_y)2if ale_y<0ECDFy≥0(ale_y)2if ale_y>0 norm\\_ale\\_y = 100 \\times \\begin{cases}  0 & \\text{} \\max(centred\\_y < 0) \\leq ale\\_y \\leq \\min(centred\\_y > 0), \\\\ \\frac{-ECDF_{y_{\\leq 0}}(ale\\_y)}{2} & \\text{}ale\\_y < 0 \\\\ \\frac{ECDF_{y_{\\geq 0}}(ale\\_y)}{2} & \\text{}ale\\_y > 0 \\\\ \\end{cases}   - centred_ycentred\\_y vector y values centred median (, median subtracted values). - ECDFy≥0ECDF_{y_{\\geq 0}} ECDF non-negative values y. - −ECDFy≤0-ECDF_{y_{\\leq 0}} ECDF negative values y inverted (multiplied -1). course, formula simplified multiplying 50 instead 100 dividing ECDFs two . prefer form given explicit ECDF represents half percentile range result scored 100 percentiles.","code":""},{"path":"https://tripartio.github.io/ale/articles/ale-statistics.html","id":"normalized-aler-naler","dir":"Articles","previous_headings":"ALE effect size measures > Normalized ALE effect size measures","what":"Normalized ALER (NALER)","title":"ALE-based statistics for statistical inference and effect sizes","text":"Based normalization, first normalized ALER (NALER), scales minimum maximum ALE y values -50% +50%, centred 0%, represents median: NALER(y,ale_y)={min(norm_ale_y)+50,max(norm_ale_y)+50} \\mathrm{NALER}(\\mathrm{y, ale\\_y}) =  \\{\\min(\\mathrm{norm\\_ale\\_y}) + 50,  \\max(\\mathrm{norm\\_ale\\_y}) + 50 \\} yy full vector y values original dataset, required calculate norm_ale_y\\mathrm{norm\\_ale\\_y}. ALER shows extreme values variable’s effect outcome. effects plot , indicated extreme ends horizontal bars variable. see public ALER -0.34, 0.42. consider median math score dataset 12.9, ALER indicates minimum ALE y value public (public == TRUE) -0.34 median. shown 12.6 mark plot . maximum (public == FALSE) 0.42 median, shown 13.3 point . ALER academic_ratio considerably broader -4.09 2.09 median. result transformation NALER values can interpreted percentile effects y median, centred 0%. numbers represent limits effect x variable units percentile scores y. effects plot , percentile scale top corresponds exactly raw scale , NALER limits represented exactly points ALER limits; scale changes. scale ALER ALED lower scale raw outcomes; scale NALER NALED upper scale percentiles. , NALER -4.26, 6.07, minimum ALE value public (public == TRUE) shifts math scores -4 percentile y points whereas maximum (public == FALSE) shifts math scores 6 percentile points. Academic track ratio NALER -33.32, 28.08, ranging -33 28 percentile points math scores.","code":""},{"path":"https://tripartio.github.io/ale/articles/ale-statistics.html","id":"normalized-aled-naled","dir":"Articles","previous_headings":"ALE effect size measures > Normalized ALE effect size measures","what":"Normalized ALED (NALED)","title":"ALE-based statistics for statistical inference and effect sizes","text":"normalization ALED scores applies ALED formula normalized ALE values instead original ALE y values: NALED(y,ale_y,ale_n)=ALED(norm_ale_y,ale_n) \\mathrm{NALED}(y, \\mathrm{ale\\_y}, \\mathrm{ale\\_n}) = \\mathrm{ALED}(\\mathrm{norm\\_ale\\_y}, \\mathrm{ale\\_n}) NALED produces score ranges 0 100%. essentially ALED expressed percentiles, , average effect variable full domain values. , NALED public school status 5 indicates average effect math scores spans middle 5 percent scores. Academic ratio average effect expressed NALED 10.2% scores.","code":""},{"path":"https://tripartio.github.io/ale/articles/ale-statistics.html","id":"the-aler-band-and-random-variables","dir":"Articles","previous_headings":"ALE effect size measures","what":"The ALER band and random variables","title":"ALE-based statistics for statistical inference and effect sizes","text":"particularly striking note ALE effect size measures random rand_norm:  rand_norm NALED 4. might surprising purely random value “effect size” speak statistically, must numeric value . informal tests several different random seeds, random variables dataset exceed threshold 5%. , p-values, NALED particularly helpful comparing practical relevance variables. rule thumb, suggest variable needs shift outcome average least 5% median values considered meaningful. threshold scale NALED. , can tell public school status NALED 5 just barely crosses threshold.","code":"get(mb_gam_plots, 'rand_norm') get(mb_gam_math, 'rand_norm', stats = 'all') #> # A tibble: 6 × 7 #>   term      statistic estimate conf.low  median    mean conf.high #>   <fct>     <fct>        <dbl>    <dbl>   <dbl>   <dbl>     <dbl> #> 1 rand_norm aled         0.295    0.107   0.282   0.295     0.631 #> 2 rand_norm aler_min    -1.26    -3.98   -1.01   -1.26     -0.180 #> 3 rand_norm aler_max     0.978    0.287   0.788   0.978     2.63  #> 4 rand_norm naled        4.00     1.31    3.65    4.00      7.93  #> 5 rand_norm naler_min  -13.7    -37.5   -11.2   -13.7      -3.75  #> 6 rand_norm naler_max   13.4      2.5    11.2    13.4      35.5"},{"path":"https://tripartio.github.io/ale/articles/ale-statistics.html","id":"interpretation-of-normalized-ale-effect-sizes","dir":"Articles","previous_headings":"ALE effect size measures","what":"Interpretation of normalized ALE effect sizes","title":"ALE-based statistics for statistical inference and effect sizes","text":"summarize general principles interpreting normalized ALE effect sizes. 0% means effect . 100% means maximum possible effect variable : binary variable, one value (50% data) sets outcome minimum value value (50% data) sets outcome maximum value. Larger NALED means stronger effects. NALER minimum ranges –50% 0%; NALER maximum ranges 0% +50%: 0% means effect . indicates effect input variable keep outcome median range values. NALER minimum n means , regardless effect size NALED, minimum effect input value shifts outcome n percentile points outcome range. Lower values (closer –50%) mean stronger extreme effect. NALER maximum x means , regardless effect size NALED, maximum effect input value shifts outcome x percentile points outcome range. Greater values (closer +50%) mean stronger extreme effect. However, NALER values normalized even actual effect variable exceeds ±50%, normalized value capped ±50%. general, regardless values ALE statistics, visually inspect ALE plots identify interpret patterns relationships inputs outcome. However, NALER values quite low (< ±5%), probably much see plot. common question interpreting effect sizes , “strong effect need considered ‘strong’ ‘weak’?” one hand, decline offer general guidelines “strong” “strong”. simple answer depends entirely applied context. meaningful try propose numerical values statistics supposed useful applied contexts. hand, consider important delineate threshold random effects non-random effects. always important distinguish weak real effect one just statistical artifact due random chance. , can offer general guidelines based whether p-values. p-values ALE statistics, boundaries ALER generally used determine acceptable risk considering statistic meaningful. Statistically significant ALE effects less 0.05 p-value ALER minimum random variable greater 0.05 p-value ALER maximum random variable. explained introducing ALER band, precisely ale package , especially plots highlight ALER band confidence region tables use specified ALER p-value threshold. absence p-values, suggest NALED can general guide non-random values. informal tests, find NALED values 5% average effect random variable. , average effect reliable; might random. However, regardless average effect indicated NALED, large NALER effects indicate ALE plot inspected interpret exceptional cases. caveat important; unlike GLM coefficients, ALE analysis sufficiently sensitive detect exceptions overall trend. precisely makes valuable detecting non-linear effects. general, NALED < 5%, NALER minimum > –5%, NALER maximum < +5%, input variable meaningful effect. cases worth inspecting ALE plots careful interpretation: - NALED > 5% means meaningful average effect. - NALER minimum < –5% means might least one input value significantly lowers outcome values. - NALER maximum > +5% means might least one input value significantly increases outcome values.","code":""},{"path":"https://tripartio.github.io/ale/articles/ale-statistics.html","id":"statistical-inference-with-ale","dir":"Articles","previous_headings":"","what":"Statistical inference with ALE","title":"ALE-based statistics for statistical inference and effect sizes","text":"Although effect sizes valuable summarizing global effects variable, mask much nuance since variable varies effect along domain values. Thus, ALE particularly powerful ability make fine-grained inferences variable’s effect depending specific value.","code":""},{"path":"https://tripartio.github.io/ale/articles/ale-statistics.html","id":"ale-data-structures-for-categorical-and-numeric-variables","dir":"Articles","previous_headings":"Statistical inference with ALE","what":"ALE data structures for categorical and numeric variables","title":"ALE-based statistics for statistical inference and effect sizes","text":"understand bootstrapped ALE can used statistical inference, must understand structure ALE data. Let’s begin simple binary variable just two categories, public: meaning column ale$data categorical variable: x.bin: different categories exist categorical variable. .n: number rows category dataset provided function. .y: ALE function value calculated category. bootstrapped ALE, .y_mean default .y_median boot_centre = 'median' argument specified. .y_lo .y_hi: lower upper confidence intervals bootstrapped .y value. ale package internally centres ALE values zero, outputs plots get() method centres displayed values median outcome variable; can changed mean- zero-centring ale_centre argument plot() get(). dataset, median schools’ average mathematics achievement scores 12.9. ALE centred median, weighted sum ALE y values (weighted .n) median approximately equal weighted sum median. , ALE plots , consider number instances indicated rug plots category percentages, average weighted ALE y approximately equals median. ALE data structure numeric variable, academic_ratio: columns categorical variable, instead x.bin, x.ceil since categories. calculate ALE numeric variables, range x values divided bins (default 10, customizable max_num_bins argument). numeric variables often multiple values bin, ALE data stores ceilings (upper bounds) bins. x values fewer 10 distinct values data, distinct value becomes bin record value ceiling bin. 10 distinct values, range divided 10 decile groups. first bin includes rows value exactly equal minimum value variable, thus often elements—sometimes one. columns mean thing categorical variables: .n number rows data bin .y calculated ALE bin whose ceiling .ceil.","code":"get(mb_gam_math, 'public') #> # A tibble: 2 × 7 #>   public.bin    .n    .y .y_lo .y_mean .y_median .y_hi #>   <ord>      <int> <dbl> <dbl>   <dbl>     <dbl> <dbl> #> 1 FALSE         70  13.3  12.7    13.3      13.3  14.1 #> 2 TRUE          90  12.6  12.1    12.6      12.6  13.1 get(mb_gam_math, 'academic_ratio') #> # A tibble: 10 × 7 #>    academic_ratio.ceil    .n    .y .y_lo .y_mean .y_median .y_hi #>                  <dbl> <int> <dbl> <dbl>   <dbl>     <dbl> <dbl> #>  1                0        1  7.79  5.08    7.79      7.83  11.4 #>  2                0.2     19 12.5  11.6    12.5      12.5   13.8 #>  3                0.28    16 12.5  11.8    12.5      12.5   13.6 #>  4                0.38    18 12.7  12.3    12.7      12.7   13.3 #>  5                0.45    18 12.7  11.9    12.7      12.7   13.3 #>  6                0.53    17 13.0  12.5    13.0      13.0   13.4 #>  7                0.6     18 13.3  12.7    13.3      13.2   13.9 #>  8                0.71    18 13.4  12.4    13.4      13.5   14.1 #>  9                0.9     18 13.9  12.8    13.9      13.7   15.0 #> 10                1       17 14.9  13.4    14.9      15.0   16.3"},{"path":"https://tripartio.github.io/ale/articles/ale-statistics.html","id":"bootstrap-based-inference-with-ale","dir":"Articles","previous_headings":"Statistical inference with ALE","what":"Bootstrap-based inference with ALE","title":"ALE-based statistics for statistical inference and effect sizes","text":"bootstrapped ALE plot, values within confidence intervals statistically significant; values outside ALER band can considered least somewhat meaningful. Thus, essence ALE-based inference variable least effects whose confidence intervals outside ALER band considered conceptually meaningful. can see , example, plot mean_ses:  might always easy tell plot regions relevant, results statistical significance summarized ale$conf_regions$by_term element, can accessed variable by_term element: numeric variables, confidence regions summary one row consecutive sequence x values status: values region ALER band, overlap band, band. summary components: start_x first end_x last x value sequence. start_y y value corresponds start_x end_y corresponds end_x. n number data elements (rows) sequence; pct percentage total data elements total number. x_span_pct percentage domain x sequence confidence status (aler_band). expressed percentage full domain x values may comparable across variables different units x. trend average slope point (start_x, start_y) (end_x, end_y). start end points used calculate trend, reflect ups downs might occur two points. Since various x values dataset different scales, scales x y values calculating trend normalized scale 100 trends variables directly comparable. positive trend means , average, y increases x; negative trend means , average, y decreases x; zero trend means y value start end points–always case one point indicated sequence. : higher limit confidence interval ALE y (.y_hi) lower limit ALER band. : lower limit confidence interval ALE y (.y_lo) higher limit ALER band. overlap: neither first two conditions holds; , confidence region .y_lo .y_hi least partially overlaps ALER band. results tell us , mean_ses, -1.19 -0.517, ALE ALER band 5.32 11.3. -0.335 0.831, ALE overlaps ALER band 12.3 15. Interestingly, text previous paragraph generated automatically internal (unexported function) ale:::summarize_conf_regions_1D_in_words. (Since function exported, must use ale::: three colons, just two, want access .) wording rather mechanical, nonetheless illustrates potential value able summarize inferentially relevant conclusions tabular form. Confidence region summary tables available numeric also categorical variables, see public. ALE plot :  confidence regions summary table: Since categories , start end position trend. instead x category single ALE y value, n pct respective category. aler_band indicate whether indicated category , overlaps , ALER band. help ale:::summarize_conf_regions_1D_in_words(), can summarize results public: FALSE, ALE 13.3 overlaps ALER band. TRUE, ALE 12.6 overlaps ALER band. , random variable rand_norm particularly interesting. ALE plot:  confidence regions summary table: Despite apparent pattern (even though deliberately selected random seed particularly erratic random variable), see -2.4 2.61, ALE overlaps ALER band 11.7 12.5.. , despite random highs lows bootstrap confidence interval, reason suppose random variable effect anywhere domain. can conveniently summarize confidence regions variables statistically significant meaningful accessing conf_regions$significant element: summary focuses x variables meaningful ALE regions anywhere domain. can also conveniently isolate variables meaningful region extracting unique values term column: especially useful analyses dozens variables; can thus quickly isolate focus meaningful ones.","code":"get(mb_gam_plots, 'mean_ses') get(mb_gam_math, 'mean_ses', stats = 'conf_regions') #> # A tibble: 2 × 10 #>   term     start_x  end_x x_span_pct     n   pct start_y end_y trend aler_band #>   <chr>      <dbl>  <dbl>      <dbl> <int> <dbl>   <dbl> <dbl> <dbl> <ord>     #> 1 mean_ses  -1.19  -0.517       33.2    18  11.2    5.32  11.3 1.20  below     #> 2 mean_ses  -0.335  0.831       57.8   142  88.8   12.3   15.0 0.314 overlap get(mb_gam_math, 'mean_ses', stats = 'conf_regions') |>    ale:::summarize_conf_regions_1D_in_words() #> [1] \"From -1.19 to -0.517, ALE is below the ALER band from 5.32 to 11.3. From -0.335 to 0.831, ALE overlaps the ALER band from 12.3 to 15.\" get(mb_gam_plots, 'public') get(mb_gam_math, 'public', stats = 'conf_regions') #> # A tibble: 2 × 6 #>   term   x         n   pct     y aler_band #>   <chr>  <chr> <int> <dbl> <dbl> <ord>     #> 1 public FALSE    70  43.8  13.3 overlap   #> 2 public TRUE     90  56.2  12.6 overlap get(mb_gam_plots, 'rand_norm') get(mb_gam_math, 'rand_norm', stats = 'conf_regions') #> # A tibble: 1 × 10 #>   term      start_x end_x x_span_pct     n   pct start_y end_y  trend aler_band #>   <chr>       <dbl> <dbl>      <dbl> <int> <dbl>   <dbl> <dbl>  <dbl> <ord>     #> 1 rand_norm   -2.40  2.61        100   160   100    11.7  12.5 0.0555 overlap get(mb_gam_math, stats = 'conf_sig') #> # A tibble: 5 × 12 #>   term   x     start_x   end_x x_span_pct     n   pct     y start_y end_y  trend #>   <chr>  <chr>   <dbl>   <dbl>      <dbl> <int> <dbl> <dbl>   <dbl> <dbl>  <dbl> #> 1 mean_… NA    -1.19   -0.517       33.2     18  11.2    NA    5.32 11.3   1.20  #> 2 mean_… NA    -0.335   0.831       57.8    142  88.8    NA   12.3  15.0   0.314 #> 3 minor… NA     0       0.0339       3.39    36  22.5    NA   14.5  14.2  -0.742 #> 4 minor… NA     0.0638  0.792       72.8    107  66.9    NA   13.8  11.8  -0.184 #> 5 minor… NA     1       1            0       17  10.6    NA    9.10  9.10  0     #> # ℹ 1 more variable: aler_band <ord> get(mb_gam_math, stats = 'conf_sig')$term |>    unique() #> [1] \"mean_ses\"       \"minority_ratio\""},{"path":"https://tripartio.github.io/ale/articles/ale-x-datatypes.html","id":"var_cars-modified-mtcars-dataset-motor-trend-car-road-tests","dir":"Articles","previous_headings":"","what":"var_cars: modified mtcars dataset (Motor Trend Car Road Tests)","title":"ale function handling of various datatypes for x","text":"demonstration, use modified version built-mtcars dataset binary (logical), categorical (factor, , non-ordered categories), ordinal (ordered factor), discrete interval (integer), continuous interval (numeric double) values. modified version, called var_cars, let us test different basic variations x variables. factor, adds country car manufacturer. data tibble 32 observations 12 variables:","code":"print(var_cars) #> # A tibble: 32 × 14 #>    model         mpg   cyl  disp    hp  drat    wt  qsec vs    am    gear   carb #>    <chr>       <dbl> <int> <dbl> <dbl> <dbl> <dbl> <dbl> <lgl> <lgl> <ord> <int> #>  1 Mazda RX4    21       6  160    110  3.9   2.62  16.5 FALSE TRUE  four      4 #>  2 Mazda RX4 …  21       6  160    110  3.9   2.88  17.0 FALSE TRUE  four      4 #>  3 Datsun 710   22.8     4  108     93  3.85  2.32  18.6 TRUE  TRUE  four      1 #>  4 Hornet 4 D…  21.4     6  258    110  3.08  3.22  19.4 TRUE  FALSE three     1 #>  5 Hornet Spo…  18.7     8  360    175  3.15  3.44  17.0 FALSE FALSE three     2 #>  6 Valiant      18.1     6  225    105  2.76  3.46  20.2 TRUE  FALSE three     1 #>  7 Duster 360   14.3     8  360    245  3.21  3.57  15.8 FALSE FALSE three     4 #>  8 Merc 240D    24.4     4  147.    62  3.69  3.19  20   TRUE  FALSE four      2 #>  9 Merc 230     22.8     4  141.    95  3.92  3.15  22.9 TRUE  FALSE four      2 #> 10 Merc 280     19.2     6  168.   123  3.92  3.44  18.3 TRUE  FALSE four      4 #> # ℹ 22 more rows #> # ℹ 2 more variables: country <fct>, continent <fct> summary(var_cars) #>     model                mpg             cyl             disp       #>  Length:32          Min.   :10.40   Min.   :4.000   Min.   : 71.1   #>  Class :character   1st Qu.:15.43   1st Qu.:4.000   1st Qu.:120.8   #>  Mode  :character   Median :19.20   Median :6.000   Median :196.3   #>                     Mean   :20.09   Mean   :6.188   Mean   :230.7   #>                     3rd Qu.:22.80   3rd Qu.:8.000   3rd Qu.:326.0   #>                     Max.   :33.90   Max.   :8.000   Max.   :472.0   #>        hp             drat             wt             qsec       #>  Min.   : 52.0   Min.   :2.760   Min.   :1.513   Min.   :14.50   #>  1st Qu.: 96.5   1st Qu.:3.080   1st Qu.:2.581   1st Qu.:16.89   #>  Median :123.0   Median :3.695   Median :3.325   Median :17.71   #>  Mean   :146.7   Mean   :3.597   Mean   :3.217   Mean   :17.85   #>  3rd Qu.:180.0   3rd Qu.:3.920   3rd Qu.:3.610   3rd Qu.:18.90   #>  Max.   :335.0   Max.   :4.930   Max.   :5.424   Max.   :22.90   #>      vs              am             gear         carb          country   #>  Mode :logical   Mode :logical   three:15   Min.   :1.000   Germany: 8   #>  FALSE:18        FALSE:19        four :12   1st Qu.:2.000   Italy  : 4   #>  TRUE :14        TRUE :13        five : 5   Median :2.000   Japan  : 6   #>                                             Mean   :2.812   Sweden : 1   #>                                             3rd Qu.:4.000   UK     : 1   #>                                             Max.   :8.000   USA    :12   #>          continent  #>  Asia         : 6   #>  Europe       :14   #>  North America:12   #>                     #>                     #>"},{"path":"https://tripartio.github.io/ale/articles/ale-x-datatypes.html","id":"modelling-with-ale-and-gam","dir":"Articles","previous_headings":"","what":"Modelling with ALE and GAM","title":"ale function handling of various datatypes for x","text":"GAM, numeric variables can smoothed, binary categorical ones. However, smoothing always help improve model since variables related outcome related actually simple linear relationship. keep demonstration simple, done earlier analysis (shown ) determines smoothing worthwhile modified var_cars dataset, numeric variables smoothed. goal demonstrate best modelling procedure rather demonstrate flexibility ale package. Now generate ALE data gam_cars GAM model plot .  can see ALE() trouble modelling datatypes sample (logical, factor, ordered, integer, double). plots line charts numeric predictors column charts everything else. numeric predictors rug plots indicate ranges x (predictor) y (mpg) values data actually exists dataset. helps us -interpret regions data sparse. Since column charts discrete scale, display rug plots. Instead, percentage data represented column displayed. can also generate plot ALE data two-way interactions.  interactions model point demonstration show ale package can handle 2D interactions just pair interaction types: numeric-numeric, ordinal-binary, categorical-ordinal, etc. Finally, explained vignette modelling small datasets, appropriate modelling workflow require bootstrapping entire model, just ALE data. , let’s now.  (default, ModelBoot object creates 100 bootstrap samples , illustration runs faster, demonstrate 10 iterations.) small dataset, bootstrap confidence interval always overlap median, indicating dataset support claims variables meaningful effect fuel efficiency (mpg). Considering average bootstrapped ALE values suggest various intriguing patterns, problem doubt dataset small–data collected analyzed, patterns probably confirmed.","code":"gam_cars <- mgcv::gam(   mpg ~ cyl + disp + hp + drat + wt + s(qsec) +     vs + am + gear + carb + country,   data = var_cars ) summary(gam_cars) #>  #> Family: gaussian  #> Link function: identity  #>  #> Formula: #> mpg ~ cyl + disp + hp + drat + wt + s(qsec) + vs + am + gear +  #>     carb + country #>  #> Parametric coefficients: #>               Estimate Std. Error t value Pr(>|t|)    #> (Intercept)   -7.84775   12.47080  -0.629  0.54628    #> cyl            1.66078    1.09449   1.517  0.16671    #> disp           0.06627    0.01861   3.561  0.00710 ** #> hp            -0.01241    0.02502  -0.496  0.63305    #> drat           4.54975    1.48971   3.054  0.01526 *  #> wt            -5.03737    1.53979  -3.271  0.01095 *  #> vsTRUE        12.45630    3.62342   3.438  0.00852 ** #> amTRUE         8.77813    2.67611   3.280  0.01080 *  #> gear.L         0.53111    3.03337   0.175  0.86525    #> gear.Q         0.57129    1.18201   0.483  0.64150    #> carb          -0.34479    0.78600  -0.439  0.67223    #> countryItaly  -0.08633    2.22316  -0.039  0.96995    #> countryJapan  -3.31948    2.22723  -1.490  0.17353    #> countrySweden -3.83437    2.74934  -1.395  0.19973    #> countryUK     -7.24222    3.81985  -1.896  0.09365 .  #> countryUSA    -7.69317    2.37998  -3.232  0.01162 *  #> --- #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 #>  #> Approximate significance of smooth terms: #>           edf Ref.df     F p-value   #> s(qsec) 7.797  8.641 5.975  0.0101 * #> --- #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 #>  #> R-sq.(adj) =  0.955   Deviance explained = 98.8% #> GCV = 6.4263  Scale est. = 1.6474    n = 32 ale_cars <- ALE(gam_cars)  # Print all plots plot(ale_cars) |>    print(ncol = 2) ale_cars_2D <- ALE(   gam_cars,   x_cols = list(d2 = TRUE) )  # Print plots plot(ale_cars_2D) |>    print(     ncol = 2,      # By default, at most 20 plots are printed. Set max_print to increase this limit     max_print = 100   ) mb <- ModelBoot(   gam_cars,   boot_it = 10,  # 100 by default but reduced here for a faster demonstration   seed = 2  # workaround to avoid random error on such a small dataset ) #> Warning in min(y): no non-missing arguments to min; returning Inf #> Warning in max(y): no non-missing arguments to max; returning -Inf #> Warning in min(norm_y): no non-missing arguments to min; returning Inf #> Warning in max(norm_y): no non-missing arguments to max; returning -Inf  plot(mb) |>    print(ncol = 2)"},{"path":"https://tripartio.github.io/ale/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Chitu Okoli. Author, maintainer.","code":""},{"path":"https://tripartio.github.io/ale/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Okoli C (2023). “Statistical inference using machine learning classical techniques based accumulated local effects (ALE).” arXiv, 1-30. doi:10.48550/arXiv.2310.09877, https://arxiv.org/abs/2310.09877. Okoli C (2024). “Reliable Inference Human-Centred Datasets Accumulated Local Effects.” Conference, https://submissions.mirasmart.com/InformsAnnual2024/Itinerary/PresentationDetail.aspx?evdid=6275. Okoli C (2024). “Model-Agnostic Interpretability: Effect Size Measures Accumulated Local Effects (ALE).” Conference, https://sites.google.com/view/data-science-2024/program. Okoli C (2025). ale: Interpretable Machine Learning Statistical Inference Accumulated Local Effects (ALE). R package version 0.5.1, https://CRAN.R-project.org/package=ale.","code":"@Article{alestatsarxiv,   title = {Statistical inference using machine learning and classical techniques based on accumulated local effects (ALE)},   author = {Chitu Okoli},   year = {2023},   journal = {arXiv},   doi = {10.48550/arXiv.2310.09877},   url = {https://arxiv.org/abs/2310.09877},   pages = {1-30}, } @Unpublished{aleinforms24,   note = {Conference},   author = {Chitu Okoli},   title = {Reliable Inference from Human-Centred Datasets with Accumulated Local Effects},   booktitle = {2024 INFORMS Annual Meeting},   year = {2024},   url = {https://submissions.mirasmart.com/InformsAnnual2024/Itinerary/PresentationDetail.aspx?evdid=6275}, } @Unpublished{alestatsinformsds,   note = {Conference},   author = {Chitu Okoli},   title = {Model-Agnostic Interpretability: Effect Size Measures from Accumulated Local Effects (ALE)},   booktitle = {INFORMS Workshop on Data Science 2024},   year = {2024},   url = {https://sites.google.com/view/data-science-2024/program}, } @Manual{,   title = {ale: Interpretable Machine Learning and Statistical Inference with Accumulated Local Effects (ALE)},   author = {Chitu Okoli},   year = {2025},   note = {R package version 0.5.1},   url = {https://CRAN.R-project.org/package=ale}, }"},{"path":"https://tripartio.github.io/ale/index.html","id":"ale-","dir":"","previous_headings":"","what":"Interpretable Machine Learning and Statistical Inference with Accumulated Local Effects (ALE)","title":"Interpretable Machine Learning and Statistical Inference with Accumulated Local Effects (ALE)","text":"Accumulated Local Effects (ALE) initially developed model-agnostic approach global explanations results black-box machine learning algorithms (Apley, Daniel W., Jingyu Zhu. ‘Visualizing effects predictor variables black box supervised learning models.’ Journal Royal Statistical Society Series B: Statistical Methodology 82.4 (2020): 1059-1086 doi:10.1111/rssb.12377). ALE two primary advantages approaches like partial dependency plots (PDP) SHapley Additive exPlanations (SHAP): values affected presence interactions among variables model computation relatively rapid. package reimplements algorithms calculating ALE data develops highly interpretable visualizations plotting ALE values. also extends original ALE concept add bootstrap-based confidence intervals ALE-based statistics can used statistical inference. details, see Okoli, Chitu. 2023. “Statistical Inference Using Machine Learning Classical Techniques Based Accumulated Local Effects (ALE).” arXiv. doi:10.48550/arXiv.2310.09877. ale package defines four main S7 classes: ALE: data 1D ALE (single variables) 2D ALE (two-way interactions). ALE values may bootstrapped ALE statistics calculated. ModelBoot: bootstrap results entire model, just ALE values. function returns bootstrapped model statistics coefficients well bootstrapped ALE values. appropriate approach models cross-validated. ALEPlots: store ALE plots generated either ALE ModelBoot convenient print(), plot(), get() methods. ALEpDist: distribution object calculating p-values ALE statistics ALE object.","code":""},{"path":"https://tripartio.github.io/ale/index.html","id":"documentation","dir":"","previous_headings":"","what":"Documentation","title":"Interpretable Machine Learning and Statistical Inference with Accumulated Local Effects (ALE)","text":"can obtain direct help package’s user-facing functions R help() function, e.g., help(ale). However, detailed documentation found website recent development version. can find several articles. particularly recommend: Introduction {ale} package ALE-based statistics statistical inference effect sizes","code":""},{"path":"https://tripartio.github.io/ale/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Interpretable Machine Learning and Statistical Inference with Accumulated Local Effects (ALE)","text":"can obtain official releases CRAN: CRAN releases extensively tested relatively bugs. However, package still beta stage. ale package, means occasionally new features changes function interface might break functionality earlier versions. Please excuse us move towards stable version flexibly meets needs broadest user base. get recent features, can install development version package GitHub : development version main branch GitHub always thoroughly checked. However, documentation might fully --date functionality.","code":"install.packages('ale') # install.packages('pak') pak::pak('tripartio/ale')"},{"path":"https://tripartio.github.io/ale/index.html","id":"usage","dir":"","previous_headings":"","what":"Usage","title":"Interpretable Machine Learning and Statistical Inference with Accumulated Local Effects (ALE)","text":"give two demonstrations use package: first, simple demonstration ALE plots, second, sophisticated demonstration suitable statistical inference p-values. demonstrations, begin fitting GAM model. assume final deployment model needs fitted entire dataset.","code":"library(ale) #>  #> Attaching package: 'ale' #> The following object is masked from 'package:base': #>  #>     get  # Sample 1000 rows from the ggplot2::diamonds dataset (for a simple example). set.seed(0) diamonds_sample <- ggplot2::diamonds[sample(nrow(ggplot2::diamonds), 1000), ]  # Create a GAM model with flexible curves to predict diamond price. # Smooth all numeric variables and include all other variables. # Build model on training data, not on the full dataset. gam_diamonds <- mgcv::gam(   price ~ s(carat) + s(depth) + s(table) + s(x) + s(y) + s(z) +     cut + color + clarity +     ti(carat, by = clarity),  # a 2D interaction   data = diamonds_sample )"},{"path":"https://tripartio.github.io/ale/index.html","id":"simple-demonstration","dir":"","previous_headings":"Usage","what":"Simple demonstration","title":"Interpretable Machine Learning and Statistical Inference with Accumulated Local Effects (ALE)","text":"simple demonstration, directly create ALE data ALE() function plot ggplot plot objects.  explanation basic features, see introductory vignette.","code":"# Create ALE data ale_gam_diamonds <- ALE(gam_diamonds, data = diamonds_sample) #> Loading required package: nlme #> This is mgcv 1.9-3. For overview type 'help(\"mgcv-package\")'. #> Loading required package: nlme #> This is mgcv 1.9-3. For overview type 'help(\"mgcv-package\")'. #> Loading required package: nlme #> This is mgcv 1.9-3. For overview type 'help(\"mgcv-package\")'. #> Loading required package: nlme #> This is mgcv 1.9-3. For overview type 'help(\"mgcv-package\")'. #> Loading required package: nlme #> This is mgcv 1.9-3. For overview type 'help(\"mgcv-package\")'. #> Loading required package: nlme #> This is mgcv 1.9-3. For overview type 'help(\"mgcv-package\")'. #> Loading required package: nlme #> This is mgcv 1.9-3. For overview type 'help(\"mgcv-package\")'. #> Loading required package: nlme #> This is mgcv 1.9-3. For overview type 'help(\"mgcv-package\")'. #> Loading required package: nlme #> This is mgcv 1.9-3. For overview type 'help(\"mgcv-package\")'.  # Plot the ALE data plot(ale_gam_diamonds) |>    print(ncol = 2)"},{"path":"https://tripartio.github.io/ale/index.html","id":"statistical-inference-with-ale","dir":"","previous_headings":"Usage","what":"Statistical inference with ALE","title":"Interpretable Machine Learning and Statistical Inference with Accumulated Local Effects (ALE)","text":"statistical functionality ale package rather slow typically involves 100 bootstrap iterations sometimes 1,000 random simulations. Even though functions package implement parallel processing default, procedures still take time. , statistical demonstration gives downloadable objects rapid demonstration. First, need create p-value distribution object ALE statistics can properly distinguished random effects. Now can create bootstrapped ALE data see differences plots bootstrapped ALE p-values:   detailed explanation interpret plots, see vignette ALE-based statistics statistical inference effect sizes.","code":"# Create p_value distribution object  # # To generate the code, uncomment the following lines. # # But it is slow because it retrains the model 100 times, so this vignette loads a pre-created p_value distribution object. # gam_diamonds_p_readme <- ALEpDist( #   gam_diamonds, diamonds_sample, #   # Normally should be default 1000, but just 100 for quicker demo #   rand_it = 100 # ) # saveRDS(gam_diamonds_p_readme, file.choose()) gam_diamonds_p_readme <-    url('https://github.com/tripartio/ale/raw/main/download/gam_diamonds_p_readme.0.5.0.rds') |>    readRDS() # Create ALE data ale_gam_diamonds_stats_readme <- ALE(   gam_diamonds,   # generate all for all 1D variables and the carat:clarity 2D interaction   x_cols = list(d1 = TRUE, d2 = 'carat:clarity'),   data = diamonds_sample,   p_values = gam_diamonds_p_readme,   # Usually at least 100 bootstrap iterations, but just 10 here for a faster demo   boot_it = 10 ) #> Loading required package: nlme #> This is mgcv 1.9-3. For overview type 'help(\"mgcv-package\")'. #> Loading required package: nlme #> This is mgcv 1.9-3. For overview type 'help(\"mgcv-package\")'. #> Loading required package: nlme #> This is mgcv 1.9-3. For overview type 'help(\"mgcv-package\")'. #> Loading required package: nlme #> This is mgcv 1.9-3. For overview type 'help(\"mgcv-package\")'. #> Loading required package: nlme #> This is mgcv 1.9-3. For overview type 'help(\"mgcv-package\")'. #> Loading required package: nlme #> This is mgcv 1.9-3. For overview type 'help(\"mgcv-package\")'. #> Loading required package: nlme #> This is mgcv 1.9-3. For overview type 'help(\"mgcv-package\")'. #> Loading required package: nlme #> This is mgcv 1.9-3. For overview type 'help(\"mgcv-package\")'. #> Loading required package: nlme #> This is mgcv 1.9-3. For overview type 'help(\"mgcv-package\")'. #> Loading required package: nlme #> This is mgcv 1.9-3. For overview type 'help(\"mgcv-package\")'.  # Create an ALEPlots object for fine-tuned plotting ale_plots <- plot(ale_gam_diamonds_stats_readme)  # Plot 1D ALE plots  ale_plots |>    # Only select 1D ALE plots.   # Use subset() instead of get() to keep the special ALEPlots object    # plot and print functionality.   subset(list(d1 = TRUE)) |>    print(ncol = 2) # Plot a selected 2D plot ale_plots |>    # get() retrieves a specific desired plot   get('carat:clarity')"},{"path":"https://tripartio.github.io/ale/index.html","id":"getting-help","dir":"","previous_headings":"","what":"Getting help","title":"Interpretable Machine Learning and Statistical Inference with Accumulated Local Effects (ALE)","text":"find bug, please report GitHub. sure always include minimal reproducible example usage requests. include dataset question, use one built-datasets frame help request: var_cars census. may also use ggplot2::diamonds larger sample.","code":""},{"path":"https://tripartio.github.io/ale/index.html","id":"citations","dir":"","previous_headings":"","what":"Citations","title":"Interpretable Machine Learning and Statistical Inference with Accumulated Local Effects (ALE)","text":"find package useful, appreciate cite appropriate sources follows, depending aspects use.","code":""},{"path":"https://tripartio.github.io/ale/index.html","id":"core-idea-of-accumulated-local-effects","dir":"","previous_headings":"Citations","what":"Core idea of accumulated local effects","title":"Interpretable Machine Learning and Statistical Inference with Accumulated Local Effects (ALE)","text":"Apley, Daniel W., Jingyu Zhu (2020). “Visualizing effects predictor variables black box supervised learning models.” Journal Royal Statistical Society Series B: Statistical Methodology 82, . 4: 1059-1086.","code":""},{"path":"https://tripartio.github.io/ale/index.html","id":"ale-statistics-aled-aler-naled-naler","dir":"","previous_headings":"Citations","what":"ALE statistics (ALED, ALER, NALED, NALER)","title":"Interpretable Machine Learning and Statistical Inference with Accumulated Local Effects (ALE)","text":"Okoli, Chitu (2023). “Statistical inference using machine learning classical techniques based accumulated local effects (ALE).” arXiv preprint arXiv:2310.09877. Okoli, Chitu (2024). “Model-Agnostic Interpretability: Effect Size Measures Accumulated Local Effects (ALE)”. INFORMS Workshop Data Science 2024. Seattle","code":""},{"path":"https://tripartio.github.io/ale/index.html","id":"ale-based-inference-confidence-regions","dir":"","previous_headings":"Citations","what":"ALE-based inference (confidence regions)","title":"Interpretable Machine Learning and Statistical Inference with Accumulated Local Effects (ALE)","text":"Okoli, Chitu (2023). “Statistical inference using machine learning classical techniques based accumulated local effects (ALE).” arXiv preprint arXiv:2310.09877. Okoli, Chitu (2024). “Model-Agnostic Interpretability: Effect Size Measures Accumulated Local Effects (ALE)”. INFORMS Workshop Data Science 2024. Seattle","code":""},{"path":"https://tripartio.github.io/ale/index.html","id":"use-of-the-ale-package-the-software-itself","dir":"","previous_headings":"Citations","what":"Use of the ale package (the software itself)","title":"Interpretable Machine Learning and Statistical Inference with Accumulated Local Effects (ALE)","text":"Okoli, Chitu ([year package version used]). “ale: Interpretable Machine Learning Statistical Inference Accumulated Local Effects (ALE)”. R software package version [enter version number]. https://CRAN.R-project.org/package=ale.","code":""},{"path":"https://tripartio.github.io/ale/reference/ALEPlots.html","id":null,"dir":"Reference","previous_headings":"","what":"ALE plots with print and plot methods — ALEPlots","title":"ALE plots with print and plot methods — ALEPlots","text":"ALEPlots S7 object contains ALE plots ALE ModelBoot objects stored ggplot objects. ALEPlots constructor creates possible plots ALE ModelBoot passed —individual 1D 2D ALE plots, also special plots like ALE effects plot. , ALEPlots object collection plots, almost never single plot. retrieve specific plots, use get.ALEPlots() method. See examples ALE() ModelBoot() objects manipulate ALEPlots objects.","code":""},{"path":"https://tripartio.github.io/ale/reference/ALEPlots.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"ALE plots with print and plot methods — ALEPlots","text":"","code":"ALEPlots(   obj,   ...,   ale_centre = \"median\",   y_1d_refs = c(\"25%\", \"75%\"),   rug_sample_size = obj@params$sample_size,   min_rug_per_interval = 1,   y_nonsig_band = 0.05,   seed = 0,   silent = FALSE )"},{"path":"https://tripartio.github.io/ale/reference/ALEPlots.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"ALE plots with print and plot methods — ALEPlots","text":"obj ALE ModelBoot object. object containing ALE data plotted. ... used. Inserted require explicit naming subsequent arguments. ale_centre character(1) c('median', 'mean', 'zero'). ALE y values plots centred relative value. 'median' default. 'zero' maintain actual ALE values, centred zero. y_1d_refs character numeric vector. 1D ALE plots, y outcome values reference line drawn. character vector, y_1d_refs values names obj@params$y_summary (usually quantile names). numeric vector, y_1d_refs values must values within range y, , obj@params$y_summary$min obj@params$y_summary$max inclusive. rug_sample_size, min_rug_per_interval non-negative integer(1). Rug plots -sampled rug_sample_size rows, otherwise can slow large datasets. default, size value obj@params$sample_size. maintain representativeness data guaranteeing ALE bins retain least min_rug_per_interval elements; usually set just 1 (default) 2. prevent -sampling, set rug_sample_size Inf (ALEPlots object store entire dataset, become large). y_nonsig_band numeric(1) 0 1. p-values, plots (notably 1D effects plot) shade grey inner y_nonsig_band quantile ale_centre average (median, default) indicate nonsignificant effects. seed See documentation ALE() silent See documentation ALE()","code":""},{"path":"https://tripartio.github.io/ale/reference/ALEPlots.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"ALE plots with print and plot methods — ALEPlots","text":"object class ALEPlots properties plots params.","code":""},{"path":"https://tripartio.github.io/ale/reference/ALEPlots.html","id":"properties","dir":"Reference","previous_headings":"","what":"Properties","title":"ALE plots with print and plot methods — ALEPlots","text":"plots Stores ALE plots. Use get.ALEPlots() access . params parameters used calculate ALE plots. include arguments used construct ALEPlots object. either values provided user used default user change also includes several objects created within constructor. extra objects described , well parameters stored differently form arguments:","code":"* `y_col`, `y_cats`: See documentation for [ALE()] * `max_d`: See documentation for [ALE()] * `requested_x_cols`: See documentation for [ALE()]. Note, however, that `ALEPlots` does not store `ordered_x_cols`."},{"path":"https://tripartio.github.io/ale/reference/ALEPlots.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"ALE plots with print and plot methods — ALEPlots","text":"","code":"# See examples with ALE and ModelBoot objects"},{"path":"https://tripartio.github.io/ale/reference/ALEpDist.html","id":null,"dir":"Reference","previous_headings":"","what":"Random variable distributions of ALE statistics for generating p-values — ALEpDist","title":"Random variable distributions of ALE statistics for generating p-values — ALEpDist","text":"ALE statistics accompanied two indicators confidence values. First, bootstrapping creates confidence intervals ALE effects ALE statistics give range possible ALE values. Second, calculate p-values, indicator probability given ALE statistic random. ALEpDist S7 object contains necessary distribution data generating p-values.","code":""},{"path":"https://tripartio.github.io/ale/reference/ALEpDist.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Random variable distributions of ALE statistics for generating p-values — ALEpDist","text":"","code":"ALEpDist(   model,   data = NULL,   ...,   y_col = NULL,   rand_it = NULL,   surrogate = FALSE,   parallel = \"all\",   model_packages = NULL,   random_model_call_string = NULL,   random_model_call_string_vars = character(),   positive = TRUE,   pred_fun = function(object, newdata, type = pred_type) {      stats::predict(object =     object, newdata = newdata, type = type)  },   pred_type = \"response\",   output_residuals = FALSE,   seed = 0,   silent = FALSE,   .skip_validation = FALSE )"},{"path":"https://tripartio.github.io/ale/reference/ALEpDist.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Random variable distributions of ALE statistics for generating p-values — ALEpDist","text":"model See documentation ALE() data See documentation ALE() ... used. Inserted require explicit naming subsequent arguments. y_col See documentation ALE() rand_it non-negative integer(1). Number times model retrained new random variable. default NULL generate 1000 iterations, give reasonably stable p-values; considered \"exact\" p-values. can reduced approximate (\"approx\") p-values low 100 faster test runs p-values stable. rand_it 100 allowed p-values inaccurate. surrogate logical(1). Create p-value distributions based surrogate linear model (TRUE) instead original model (default FALSE). Note faster surrogate p-values convenient interactive analysis, acceptable definitive conclusions publication. See details. parallel See documentation ALE(). Note exact p-values, default 1000 random variables trained. , even parallel processing, procedure slow. model_packages See documentation ALE() random_model_call_string character(1). NULL, ALEpDist() constructor tries automatically detect construct call p-values. , constructor fail. case, character string full call model must provided includes random variable. See details. random_model_call_string_vars See documentation model_call_string_vars ModelBoot(); operation similar. positive See documentation ModelBoot() pred_fun, pred_type See documentation ALE() output_residuals logical(1). TRUE, returns residuals addition raw data generated random statistics (always returned). default FALSE return residuals. seed See documentation ALE() silent See documentation ALE() .skip_validation Internal use . logical(1). Skip non-mutating data validation checks. Changing default FALSE risks crashing incomprehensible error messages.","code":""},{"path":"https://tripartio.github.io/ale/reference/ALEpDist.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Random variable distributions of ALE statistics for generating p-values — ALEpDist","text":"object class ALEpDist properties rand_stats, residual_distribution, residuals, params.","code":""},{"path":"https://tripartio.github.io/ale/reference/ALEpDist.html","id":"properties","dir":"Reference","previous_headings":"","what":"Properties","title":"Random variable distributions of ALE statistics for generating p-values — ALEpDist","text":"rand_stats named list tibbles. normally one element whose name y_col except y_col categorical variable; case, elements named category y_col. element tibble whose rows rand_it_ok iterations random variable analysis whose columns ALE statistics obtained random variable. residual_distribution univariateML object closest estimated distribution residuals determined univariateML::model_select(). distribution used generate random variables. residuals output_residuals == TRUE, returns matrix actual y_col values data minus predicted values model (without random variables) data. rows correspond row data. columns correspond named elements (y_col categories) described rand_stats. NULL output_residuals == FALSE (default). params Parameters used generate p-value distributions. repeat selected arguments passed ALEpDist(). either values provided user used default user change following additional modified objects notable:","code":"* `model`: selected elements that describe the `model` used to generate the random distributions. * `rand_it`: the number of random iterations requested by the user either explicitly (by specifying a whole number) or implicitly with the default `NULL`: exact p distributions imply 1000 iterations and surrogate distributions imply 100 unless an explicit number of iterations is requested. * `rand_it_ok`: A whole number with the number of `rand_it` iterations that successfully generated a random variable, that is, those that did not fail for whatever reason. The `rand_it` - `rand_it_ok` failed attempts are discarded. * `exactness`: A string. For regular p-values generated from the original model, `'exact'` if `rand_it_ok >= 1000` and `'approx'` otherwise. `'surrogate'` for p-values generated from a surrogate model. `'invalid'` if `rand_it_ok < 100`.  * `probs_inverted`: `TRUE` if the original probability values of the `ALEpDist` object have been inverted. This is accomplished using [invert_probs()] on an `ALE` object. `FALSE`, `NULL`, or absent otherwise."},{"path":"https://tripartio.github.io/ale/reference/ALEpDist.html","id":"exact-p-values-for-ale-statistics","dir":"Reference","previous_headings":"","what":"Exact p-values for ALE statistics","title":"Random variable distributions of ALE statistics for generating p-values — ALEpDist","text":"ALE non-parametric (, assume particular distribution data), {ale} package takes literal frequentist approach calculation empirical (Monte Carlo) p-values. , literally retrains model 1000 times, time modifying adding distinct random variable model. (number iterations customizable rand_it argument.) ALEs ALE statistics calculated random variable. percentiles distribution random-variable ALEs used determine p-values non-random variables. Thus, p-values interpreted frequency random variable ALE statistics exceed value ALE statistic actual variable question. specific steps follows: residuals original model trained training data calculated (residuals actual y target value minus predicted values). closest distribution residuals detected univariateML::model_select(). 1000 new models trained generating random variable time univariateML::rml() training new model random variable added. ALEs ALE statistics calculated random variable. ALE statistic, empirical cumulative distribution function (stats::ecdf()) used create function determine p-values according distribution random variables' ALE statistics. ale package model-agnostic (, works kind R model), ALEpDist() constructor always automatically manipulate model object create p-values. can models follow standard R statistical modelling conventions, includes almost base R algorithms (like stats::lm() stats::glm()) many widely used statistics packages (like mgcv survival), excludes machine learning algorithms (like tidymodels caret). non-standard algorithms, user needs little work help ALEpDist() constructor correctly manipulate model object: full model call must passed character string argument random_model_call_string, two slight modifications follows. formula specifies model, must add variable named 'random_variable'. corresponds random variables constructor use estimate p-values. dataset model trained must named 'rand_data'. corresponds modified datasets used train random variables. See example implemented. model generation unstable (small dataset size finicky model algorithm), one iterations might fail, possibly dropping number successful iterations 1000. p-values considered approximate; longer exact. case, request rand_it sufficiently high number even iterations fail, least 1000 succeed. example, ALEpDist object named p_dist, p_dist@params$rand_it_ok 950, rerun ALEpDist() rand_it = 1100 higher allow 100 possible failures.","code":""},{"path":"https://tripartio.github.io/ale/reference/ALEpDist.html","id":"faster-approximate-and-surrogate-p-values","dir":"Reference","previous_headings":"","what":"Faster approximate and surrogate p-values","title":"Random variable distributions of ALE statistics for generating p-values — ALEpDist","text":"procedure just described requires least 1000 random iterations p-values considered \"exact\". Unfortunately, procedure rather slow–takes least 1000 times long time takes train model . fewer iterations (least 100), p-values can considered approximate (\"approx\"). Fewer 100 p-values invalid. might fewer iterations either user requests rand_it argument iterations fail whatever reason. long least 1000 iterations succeed, p-values considered exact. procedure can slow, faster version algorithm generates \"surrogate\" p-values substituting original model linear model predicts y_col outcome columns data. default, surrogate p-values use 100 iterations dataset large, surrogate model samples 1000 rows. Thus, surrogate p-values can generated much faster slower model algorithms larger datasets. Although suitable model development analysis faster generate, less reliable approximate p-values based original model. case, definitive conclusions (e.g., publication) always require exact p-values least 1000 iterations original model. Note surrogate p-values always marked \"surrogate\"; even generated based 1000 iterations, can never considered exact based original model.","code":""},{"path":"https://tripartio.github.io/ale/reference/ALEpDist.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Random variable distributions of ALE statistics for generating p-values — ALEpDist","text":"Okoli, Chitu. 2023. \"Statistical Inference Using Machine Learning Classical Techniques Based Accumulated Local Effects (ALE).\" arXiv. doi:10.48550/arXiv.2310.09877.","code":""},{"path":"https://tripartio.github.io/ale/reference/ALEpDist.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Random variable distributions of ALE statistics for generating p-values — ALEpDist","text":"","code":"# \\donttest{ # Sample 1000 rows from the ggplot2::diamonds dataset (for a simple example) set.seed(0) diamonds_sample <- ggplot2::diamonds[sample(nrow(ggplot2::diamonds), 1000), ]  # Create a GAM with flexible curves to predict diamond price # Smooth all numeric variables and include all other variables gam_diamonds <- mgcv::gam(   price ~ s(carat) + s(depth) + s(table) + s(x) + s(y) + s(z) +     cut + color + clarity +     ti(carat, by = clarity),  # a 2D interaction   data = diamonds_sample ) summary(gam_diamonds) #>  #> Family: gaussian  #> Link function: identity  #>  #> Formula: #> price ~ s(carat) + s(depth) + s(table) + s(x) + s(y) + s(z) +  #>     cut + color + clarity + ti(carat, by = clarity) #>  #> Parametric coefficients: #>             Estimate Std. Error t value Pr(>|t|)     #> (Intercept)  3001.89     260.67  11.516  < 2e-16 *** #> cut.L         127.31     153.83   0.828 0.408134     #> cut.Q          72.52     111.14   0.653 0.514238     #> cut.C         -55.92      83.03  -0.673 0.500810     #> cut^4          51.68      64.61   0.800 0.423979     #> color.L     -1632.19      91.78 -17.785  < 2e-16 *** #> color.Q      -472.22      83.82  -5.634 2.34e-08 *** #> color.C       -35.91      76.97  -0.467 0.640944     #> color^4        27.23      70.13   0.388 0.697875     #> color^5      -142.75      65.77  -2.170 0.030237 *   #> color^6         1.52      59.47   0.026 0.979618     #> clarity.L   -1523.84    1015.27  -1.501 0.133718     #> clarity.Q   -3469.55     893.39  -3.884 0.000110 *** #> clarity.C   -1380.98     790.93  -1.746 0.081137 .   #> clarity^4     678.13     761.51   0.890 0.373429     #> clarity^5    1437.67     622.47   2.310 0.021127 *   #> clarity^6    1305.16     379.50   3.439 0.000609 *** #> clarity^7     653.21     159.89   4.085 4.78e-05 *** #> --- #> Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 #>  #> Approximate significance of smooth terms: #>                         edf Ref.df      F p-value     #> s(carat)              8.594  8.888  6.954 < 2e-16 *** #> s(depth)              2.177  2.874  0.778 0.42173     #> s(table)              1.000  1.000  0.107 0.74371     #> s(x)                  7.954  8.513  2.788 0.00401 **  #> s(y)                  5.234  6.467  8.077 < 2e-16 *** #> s(z)                  3.404  4.479  1.623 0.15244     #> ti(carat):claritySI2  3.737  3.948 14.107 < 2e-16 *** #> ti(carat):claritySI1  1.000  1.000 52.139 < 2e-16 *** #> ti(carat):clarityVS2  2.884  3.390 22.095 < 2e-16 *** #> ti(carat):clarityVS1  3.948  3.996 33.200 < 2e-16 *** #> ti(carat):clarityVVS2 2.279  2.660 55.728 < 2e-16 *** #> ti(carat):clarityVVS1 3.924  3.994 36.573 < 2e-16 *** #> ti(carat):clarityIF   3.911  3.992 38.323 < 2e-16 *** #> --- #> Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 #>  #> R-sq.(adj) =  0.962   Deviance explained = 96.5% #> GCV = 6.2787e+05  Scale est. = 5.8514e+05  n = 1000  # Create p_value distribution pd_diamonds <- ALEpDist(   gam_diamonds,   diamonds_sample,   # only 100 iterations for a quick demo; but usually should remain at 1000   rand_it = 100 )  # Examine the structure of the returned object print(pd_diamonds) #> <ale::ALEpDist> #>  @ rand_stats           :List of 1 #>  .. $ price: tibble [100 × 6] (S3: tbl_df/tbl/data.frame) #>  ..  ..$ aled     : num [1:100] 22.5 55.5 21.9 14.9 23.8 ... #>  ..  ..$ aler_min : num [1:100] -167 -446 -209 -143 -194 ... #>  ..  ..$ aler_max : num [1:100] 210 367 230 112 273 ... #>  ..  ..$ naled    : num [1:100] 0.33 0.655 0.323 0.246 0.351 ... #>  ..  ..$ naler_min: num [1:100] -1.6 -6 -2.4 -1.4 -2 -5.1 -0.2 -1.2 -0.9 -0.5 ... #>  ..  ..$ naler_max: num [1:100] 2 3.3 2.3 1.5 2.9 3 0.6 1.1 1.7 1 ... #>  @ residual_distribution: 'univariateML' Named num [1:4] 7.19e-04 7.39e+02 7.16e-01 1.14 #>  .. - attr(*, \"logLik\")= num -7814 #>  .. - attr(*, \"call\")= language f(x = x, na.rm = na.rm) #>  .. - attr(*, \"n\")= int 1000 #>  .. - attr(*, \"model\")= chr \"Skew Generalized Error\" #>  .. - attr(*, \"density\")= chr \"fGarch::dsged\" #>  .. - attr(*, \"support\")= num [1:2] -Inf Inf #>  .. - attr(*, \"names\")= chr [1:4] \"mean\" \"sd\" \"nu\" \"xi\" #>  .. - attr(*, \"default\")= num [1:4] 0 1 3 3 #>  .. - attr(*, \"continuous\")= logi TRUE #>  @ residuals            : NULL #>  @ params               :List of 11 #>  .. $ model                        :List of 4 #>  ..  ..$ class  : chr [1:3] \"gam\" \"glm\" \"lm\" #>  ..  ..$ call   : chr \"mgcv::gam(formula = price ~ s(carat) + s(depth) + s(table) + \\n    s(x) + s(y) + s(z) + cut + color + clarity +\"| __truncated__ #>  ..  ..$ print  : chr \"\\nFamily: gaussian \\nLink function: identity \\n\\nFormula:\\nprice ~ s(carat) + s(depth) + s(table) + s(x) + s(y)\"| __truncated__ #>  ..  ..$ summary: chr \"\\nFamily: gaussian \\nLink function: identity \\n\\nFormula:\\nprice ~ s(carat) + s(depth) + s(table) + s(x) + s(y)\"| __truncated__ #>  .. $ y_col                        : chr \"price\" #>  .. $ rand_it                      : num 100 #>  .. $ parallel                     : Named int 4 #>  ..  ..- attr(*, \"names\")= chr \"system\" #>  .. $ model_packages               : chr \"mgcv\" #>  .. $ random_model_call_string     : NULL #>  .. $ random_model_call_string_vars: chr(0)  #>  .. $ positive                     : logi TRUE #>  .. $ seed                         : num 0 #>  .. $ rand_it_ok                   : int 100 #>  .. $ exactness                    : chr \"approx\" # In RStudio: View(pd_diamonds)  # Calculate ALEs with p-values ale_gam_diamonds <- ALE(   gam_diamonds,   p_values = pd_diamonds ) #> Warning: Could not recover model data from environment. Please make sure your #>   data is available in your workspace. #>   Trying to retrieve data from the model frame now. #> Error in (function (.x, .f, ..., .progress = FALSE) {    map_(\"list\", .x, .f, ..., .progress = .progress)})(.x = c(\"cut\", \"color\"), .f = function (...) {    {        ...furrr_chunk_seeds_i <- ...furrr_chunk_seeds_env[[\"i\"]]        ...furrr_chunk_seeds_env[[\"i\"]] <- ...furrr_chunk_seeds_i +             1L        assign(x = \".Random.seed\", value = ...furrr_chunk_seeds[[...furrr_chunk_seeds_i]],             envir = globalenv(), inherits = FALSE)    }    NULL    ...furrr_out <- ...furrr_fn(...)    ...furrr_out}): ℹ In index: 1. #> Caused by error in `map()`: #> ℹ In index: 1. #> Caused by error in `predict.gam()`: #> ! newdata is a model.frame: it should contain all required variables  # Plot the ALE data. The horizontal bands in the plots use the p-values. plot(ale_gam_diamonds) #> Error: object 'ale_gam_diamonds' not found   # For non-standard models that give errors with the default settings, # you can use 'random_model_call_string' to specify a model for the estimation # of p-values from random variables as in this example. # See details above for an explanation. pd_diamonds <- ALEpDist(   gam_diamonds,   diamonds_sample,   random_model_call_string = 'mgcv::gam(     price ~ s(carat) + s(depth) + s(table) + s(x) + s(y) + s(z) +         cut + color + clarity + random_variable,     data = rand_data   )',   # only 100 iterations for a quick demo; but usually should remain at 1000   rand_it = 100 )  # Examine the structure of the returned object print(pd_diamonds) #> <ale::ALEpDist> #>  @ rand_stats           :List of 1 #>  .. $ price: tibble [100 × 6] (S3: tbl_df/tbl/data.frame) #>  ..  ..$ aled     : num [1:100] 22.43 69.28 3 24.61 3.15 ... #>  ..  ..$ aler_min : num [1:100] -165.8 -556.8 -28.7 -236.9 -25.7 ... #>  ..  ..$ aler_max : num [1:100] 208.8 458 31.5 186.1 36.1 ... #>  ..  ..$ naled    : num [1:100] 0.3287 0.7999 0.0677 0.3541 0.071 ... #>  ..  ..$ naler_min: num [1:100] -1.6 -7.5 -0.2 -2.9 -0.2 -6.2 -1.2 -1.3 -1 -0.2 ... #>  ..  ..$ naler_max: num [1:100] 2 4.2 0.6 2 0.6 3.1 1.6 1.1 1.9 0.5 ... #>  @ residual_distribution: 'univariateML' Named num [1:4] 7.19e-04 7.39e+02 7.16e-01 1.14 #>  .. - attr(*, \"logLik\")= num -7814 #>  .. - attr(*, \"call\")= language f(x = x, na.rm = na.rm) #>  .. - attr(*, \"n\")= int 1000 #>  .. - attr(*, \"model\")= chr \"Skew Generalized Error\" #>  .. - attr(*, \"density\")= chr \"fGarch::dsged\" #>  .. - attr(*, \"support\")= num [1:2] -Inf Inf #>  .. - attr(*, \"names\")= chr [1:4] \"mean\" \"sd\" \"nu\" \"xi\" #>  .. - attr(*, \"default\")= num [1:4] 0 1 3 3 #>  .. - attr(*, \"continuous\")= logi TRUE #>  @ residuals            : NULL #>  @ params               :List of 11 #>  .. $ model                        :List of 4 #>  ..  ..$ class  : chr [1:3] \"gam\" \"glm\" \"lm\" #>  ..  ..$ call   : chr \"mgcv::gam(formula = price ~ s(carat) + s(depth) + s(table) + \\n    s(x) + s(y) + s(z) + cut + color + clarity +\"| __truncated__ #>  ..  ..$ print  : chr \"\\nFamily: gaussian \\nLink function: identity \\n\\nFormula:\\nprice ~ s(carat) + s(depth) + s(table) + s(x) + s(y)\"| __truncated__ #>  ..  ..$ summary: chr \"\\nFamily: gaussian \\nLink function: identity \\n\\nFormula:\\nprice ~ s(carat) + s(depth) + s(table) + s(x) + s(y)\"| __truncated__ #>  .. $ y_col                        : chr \"price\" #>  .. $ rand_it                      : num 100 #>  .. $ parallel                     : Named int 4 #>  ..  ..- attr(*, \"names\")= chr \"system\" #>  .. $ model_packages               : chr \"mgcv\" #>  .. $ random_model_call_string     : chr \"mgcv::gam(\\n    price ~ s(carat) + s(depth) + s(table) + s(x) + s(y) + s(z) +\\n        cut + color + clarity + \"| __truncated__ #>  .. $ random_model_call_string_vars: chr(0)  #>  .. $ positive                     : logi TRUE #>  .. $ seed                         : num 0 #>  .. $ rand_it_ok                   : int 100 #>  .. $ exactness                    : chr \"approx\" # In RStudio: View(pd_diamonds)  # }"},{"path":"https://tripartio.github.io/ale/reference/ModelBoot.html","id":null,"dir":"Reference","previous_headings":"","what":"Statistics and ALE data for a bootstrapped model — ModelBoot","title":"Statistics and ALE data for a bootstrapped model — ModelBoot","text":"ModelBoot S7 object contains full-model bootstrapped statistics ALE data trained model. Full-model bootstrapping (distinct data-bootstrapping) retrains model bootstrap iteration. Thus, can rather slow, though much reliable. However, obtaining bootstrapped ALE data, plots, statistics, full-model bootstrapping provided ModelBoot necessary models developed cross-validation. cross-validated models, sufficient (much faster) create regular [ALE()] object bootstrapping setting boot_it argument constructor. fact, full-model bootstrapping ModelBoot often infeasible slow machine-learning models trained large datasets, rather cross-validated assure reliability. However, models cross-validated, full-model bootstrapping ModelBoot necessary reliable results. details follow ; see also vignette('ale-statistics').","code":""},{"path":"https://tripartio.github.io/ale/reference/ModelBoot.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Statistics and ALE data for a bootstrapped model — ModelBoot","text":"","code":"ModelBoot(   model,   data = NULL,   ...,   model_call_string = NULL,   model_call_string_vars = character(),   parallel = \"all\",   model_packages = NULL,   y_col = NULL,   positive = TRUE,   pred_fun = function(object, newdata, type = pred_type) {      stats::predict(object =     object, newdata = newdata, type = type)  },   pred_type = \"response\",   boot_it = 100,   boot_alpha = 0.05,   boot_centre = \"mean\",   seed = 0,   output_model_stats = TRUE,   output_model_coefs = TRUE,   output_ale = TRUE,   output_boot_data = FALSE,   ale_options = list(),   ale_p = \"auto\",   tidy_options = list(),   glance_options = list(),   silent = FALSE )"},{"path":"https://tripartio.github.io/ale/reference/ModelBoot.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Statistics and ALE data for a bootstrapped model — ModelBoot","text":"model Required. See documentation ALE() data dataframe. Dataset bootstrapped. must data model trained. provided, ModelBoot() try detect automatically. non-standard models, data provided. ... used. Inserted require explicit naming subsequent arguments. model_call_string character(1). NULL (default), ModelBoot tries automatically detect construct call bootstrapped datasets. , function fail early. case, character string full call model must provided includes boot_data data argument call. See examples. model_call_string_vars character. Names variables included model_call_string columns data. variables exist, must specified else parallel processing may produce error. parallelization disabled parallel = 0, concern. See documentation model_packages argument ALE(). parallel, model_packages See documentation ALE() y_col, pred_fun, pred_type See documentation ALE(). Used calculate bootstrapped performance measures. left default values, relevant performance measures calculated arguments can automatically detected. Otherwise, specified. positive single atomic value. model represented model model_call_string binary classification model, positive specifies 'positive' value y_col (target outcome), , value interest considered TRUE; value y_col considered FALSE. argument ignored model binary classification model. example, 2 means TRUE 1 means FALSE, set positive = 2. boot_it non-negative integer(1). Number bootstrap iterations full-model bootstrapping. bootstrapping ALE values, see details verify ALE() bootstrapping appropriate ModelBoot(). boot_it = 0, model run normal full data bootstrapping. boot_alpha numeric(1) 0 1. Alpha percentile-based confidence interval range bootstrap intervals; bootstrap confidence intervals lowest highest (1 - 0.05) / 2 percentiles. example, boot_alpha = 0.05 (default), intervals 2.5 97.5 percentiles. boot_centre character(1) c('mean', 'median'). bootstrapping, main estimate ALE y value considered boot_centre. Regardless value specified , mean median available. seed integer. Random seed. Supply runs assure identical bootstrap samples generated time data. See documentation ALE() details. output_model_stats logical(1). TRUE (default), return overall model statistics using broom::glance() (available model) bootstrap-validated statistics boot_it > 0. output_model_coefs logical(1). TRUE (default), return model coefficients using broom::tidy() (available model). output_ale logical(1). TRUE (default), return ALE data statistics. output_boot_data logical(1). TRUE, return full raw data bootstrap iteration, specifically, bootstrapped models model row indices. Default FALSE return large, detailed data. ale_options, tidy_options, glance_options list named arguments. Arguments pass ALE() constructor ale = TRUE, broom::tidy() model_coefs = TRUE, broom::glance() model_stats = TRUE, respectively, beyond (overriding) defaults. Note: obtain p-values ALE statistics, see ale_p argument. ale_p p_values argument ALE() constructor; see documentation . argument overrides p_values element ale_options argument. silent See documentation ALE()","code":""},{"path":"https://tripartio.github.io/ale/reference/ModelBoot.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Statistics and ALE data for a bootstrapped model — ModelBoot","text":"object class ALE properties model_stats, model_coefs, ale, model_stats, boot_data, params.","code":""},{"path":"https://tripartio.github.io/ale/reference/ModelBoot.html","id":"properties","dir":"Reference","previous_headings":"","what":"Properties","title":"Statistics and ALE data for a bootstrapped model — ModelBoot","text":"model_stats tibble bootstrapped results broom::glance(). NULL model_stats argument FALSE. general, broom::glance() results make sense bootstrapped included, df adj.r.squared. Results incomparable across bootstrapped datasets (aic) excluded. addition, certain model performance measures included; bootstrap-validated .632 correction (Efron & Tibshirani 1986) (.632+ correction): regression (numeric prediction) models: mae: mean absolute error (MAE) sa_mae: standardized accuracy MAE referenced mean absolute deviation rmse: root mean squared error (RMSE) sa_rmse: standardized accuracy RMSE referenced standard deviation binary categorical classification (probability) models: auc: area ROC curve model_coefs tibble bootstrapped results broom::tidy(). NULL model_coefs argument FALSE. ale list bootstrapped ALE results using default ALE() settings unless overridden ale_options. NULL ale argument FALSE. Elements :   boot_data tibble bootstrap results. row represents bootstrap iteration. NULL boot_data argument FALSE. columns :   params Parameters used calculate bootstrapped data. repeat arguments passed ModelBoot(). either values provided user used default user change following additional objects created internally also provided:","code":"* `single`: an `ALE` object of ALE calculations on the full dataset without bootstrapping.   * `boot`: a list of bootstrapped ALE data and statistics. This element is not an `ALE` object; it uses a special internal format. * `it`: the specific bootstrap iteration from 0 to `boot_it` iterations. Iteration 0 is the results from the full dataset (not bootstrapped).   * `row_idxs`: the row indexes for the bootstrapped sample for that iteration. To save space, the row indexes are returned rather than the full datasets. So, for example, iteration i's bootstrap sample can be reproduced by `data[ModelBoot_obj@boot_data$row_idxs[[2]], ]` where `data` is the dataset and `ModelBoot_obj` is the result of `ModelBoot()`.   * `model`: the model object trained on that iteration.   * `ale`: the results of `ALE()` on that iteration.   * `tidy`: the results of `broom::tidy(model)` on that iteration.   * `stats`: the results of `broom::glance(model)` on that iteration.   * `perf`: performance measures on the entire dataset. These are the measures specified above for regression and classification models. * `y_cats`: same as `ALE@params$y_cats` (see documentation there). * `y_type`: same as `ALE@params$y_type` (see documentation there). * `model`: same as `ALE@params$model` (see documentation there). * `data`: same as `ALE@params$data` (see documentation there)."},{"path":"https://tripartio.github.io/ale/reference/ModelBoot.html","id":"full-model-bootstrapping","dir":"Reference","previous_headings":"","what":"Full-model bootstrapping","title":"Statistics and ALE data for a bootstrapped model — ModelBoot","text":"modelling results, without ALE, considered reliable without appropriate validation. ALE, trained model ALE explains trained model must validated. ALE must validated bootstrapping. trained model might validated either cross-validation bootstrapping. ALE explains trained models developed cross-validation, sufficient bootstrap just training data. ALE object boot_it argument. However, unvalidated models must validated bootstrapping along calculation ALE; ModelBoot object boot_it argument. ModelBoot() carries full-model bootstrapping validate models. Specifically, : Creates multiple bootstrap samples (default 100; user can specify number); Creates model bootstrap sample; Calculates overall model statistics, variable coefficients, ALE values model bootstrap sample; Calculates mean, median, lower upper confidence intervals values across bootstrap samples.","code":""},{"path":"https://tripartio.github.io/ale/reference/ModelBoot.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Statistics and ALE data for a bootstrapped model — ModelBoot","text":"Okoli, Chitu. 2023. “Statistical Inference Using Machine Learning Classical Techniques Based Accumulated Local Effects (ALE).” arXiv. doi:10.48550/arXiv.2310.09877.< Efron, Bradley, Robert Tibshirani. \"Bootstrap methods standard errors, confidence intervals, measures statistical accuracy.\" Statistical science (1986): 54-75. doi:10.1214/ss/1177013815","code":""},{"path":"https://tripartio.github.io/ale/reference/ModelBoot.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Statistics and ALE data for a bootstrapped model — ModelBoot","text":"","code":"# attitude dataset attitude #>    rating complaints privileges learning raises critical advance #> 1      43         51         30       39     61       92      45 #> 2      63         64         51       54     63       73      47 #> 3      71         70         68       69     76       86      48 #> 4      61         63         45       47     54       84      35 #> 5      81         78         56       66     71       83      47 #> 6      43         55         49       44     54       49      34 #> 7      58         67         42       56     66       68      35 #> 8      71         75         50       55     70       66      41 #> 9      72         82         72       67     71       83      31 #> 10     67         61         45       47     62       80      41 #> 11     64         53         53       58     58       67      34 #> 12     67         60         47       39     59       74      41 #> 13     69         62         57       42     55       63      25 #> 14     68         83         83       45     59       77      35 #> 15     77         77         54       72     79       77      46 #> 16     81         90         50       72     60       54      36 #> 17     74         85         64       69     79       79      63 #> 18     65         60         65       75     55       80      60 #> 19     65         70         46       57     75       85      46 #> 20     50         58         68       54     64       78      52 #> 21     50         40         33       34     43       64      33 #> 22     64         61         52       62     66       80      41 #> 23     53         66         52       50     63       80      37 #> 24     40         37         42       58     50       57      49 #> 25     63         54         42       48     66       75      33 #> 26     66         77         66       63     88       76      72 #> 27     78         75         58       74     80       78      49 #> 28     48         57         44       45     51       83      38 #> 29     85         85         71       71     77       74      55 #> 30     82         82         39       59     64       78      39  ## ALE for generalized additive models (GAM) ## GAM is tweaked to work on the small dataset. gam_attitude <- mgcv::gam(rating ~ complaints + privileges + s(learning) +                             raises + s(critical) + advance,                           data = attitude) summary(gam_attitude) #>  #> Family: gaussian  #> Link function: identity  #>  #> Formula: #> rating ~ complaints + privileges + s(learning) + raises + s(critical) +  #>     advance #>  #> Parametric coefficients: #>             Estimate Std. Error t value Pr(>|t|)     #> (Intercept) 36.97245   11.60967   3.185 0.004501 **  #> complaints   0.60933    0.13297   4.582 0.000165 *** #> privileges  -0.12662    0.11432  -1.108 0.280715     #> raises       0.06222    0.18900   0.329 0.745314     #> advance     -0.23790    0.14807  -1.607 0.123198     #> --- #> Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 #>  #> Approximate significance of smooth terms: #>               edf Ref.df     F p-value   #> s(learning) 1.923  2.369 3.761  0.0312 * #> s(critical) 2.296  2.862 3.272  0.0565 . #> --- #> Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 #>  #> R-sq.(adj) =  0.776   Deviance explained = 83.9% #> GCV = 47.947  Scale est. = 33.213    n = 30  # \\donttest{ # Full model bootstrapping # Only 4 bootstrap iterations for a rapid example; default is 100 # Increase value of boot_it for more realistic results mb_gam <- ModelBoot(   gam_attitude,   boot_it = 4 )  # If the model is not standard, supply model_call_string with 'data = boot_data' # in the string instead of the actual dataset name (in addition to the actual dataset # as the 'data' argument directly to the `ModelBoot` constructor). mb_gam <- ModelBoot(   gam_attitude,   data = attitude,  # the actual dataset   model_call_string = 'mgcv::gam(     rating ~ complaints + privileges + s(learning) +       raises + s(critical) + advance,     data = boot_data  # required for model_call_string   )',   boot_it = 4 )  # Model statistics and coefficients mb_gam@model_stats #> # A tibble: 9 × 7 #>   name          boot_valid conf.low median   mean conf.high       sd #>   <chr>              <dbl>    <dbl>  <dbl>  <dbl>     <dbl>    <dbl> #> 1 df               NA        15.2   18.5   18.3      20.9   2.50e+ 0 #> 2 df.residual      NA         9.15  11.5   11.7      14.8   2.50e+ 0 #> 3 nobs             NA        30     30     30        30     0        #> 4 adj.r.squared    NA         1.000  1.000  1.000     1.000 1.93e-15 #> 5 npar             NA        23     23     23        23     0        #> 6 mae              19.7      13.7   NA     NA        58.4   2.20e+ 1 #> 7 sa_mae            0.0639   -1.42  NA     NA         0.268 8.09e- 1 #> 8 rmse             24.9      17.8   NA     NA        76.9   2.98e+ 1 #> 9 sa_rmse           0.0523   -1.66  NA     NA         0.240 9.46e- 1 mb_gam@model_coefs #> # A tibble: 2 × 6 #>   term        conf.low median  mean conf.high std.error #>   <chr>          <dbl>  <dbl> <dbl>     <dbl>     <dbl> #> 1 s(learning)     6.92   7.63  7.77      8.85     0.874 #> 2 s(critical)     2.80   6.10  5.49      7.13     2.13   # Plot ALE plot(mb_gam)   # Retrieve ALE data get(mb_gam, type = 'boot')    # bootstrapped #> $complaints #> # A tibble: 10 × 7 #>    complaints.ceil    .n    .y .y_lo .y_mean .y_median .y_hi #>              <dbl> <int> <dbl> <dbl>   <dbl>     <dbl> <dbl> #>  1              67     3  63.8  63.8    63.8      63.8  63.8 #>  2              78     3  55.3  55.3    55.3      55.3  55.3 #>  3              83     3  65.4  52.2    65.4      65.4  78.7 #>  4              37     1  47.0  46.2    47.0      47.0  47.9 #>  5              60     3  66.0  63.8    66.0      65.8  68.4 #>  6              75     4  73.9  73.9    73.9      73.9  73.9 #>  7              90     3  68.5  53.6    68.5      68.5  83.4 #>  8              57     3  70.1  70.1    70.1      70.1  70.1 #>  9              53     3  NA    NA      NA        NA    NA   #> 10              63     4  NA    NA      NA        NA    NA   #>  #> $privileges #> # A tibble: 10 × 7 #>    privileges.ceil    .n    .y .y_lo .y_mean .y_median .y_hi #>              <dbl> <int> <dbl> <dbl>   <dbl>     <dbl> <dbl> #>  1              30     1  66.2  55.7    66.2      69.5  71.2 #>  2              42     5  65.5  61.0    65.5      67.1  67.4 #>  3              83     3  66.4  58.8    66.4      59.5  79.7 #>  4              52     3  64.7  64.1    64.7      64.7  65.4 #>  5              68     3  58.8  58.8    58.8      58.8  58.8 #>  6              46     3  66.1  66.1    66.1      66.1  66.1 #>  7              50     4  65.6  65.4    65.6      65.6  65.8 #>  8              44     1  66.9  66.9    66.9      66.9  66.9 #>  9              57     4  64.4  64.4    64.4      64.4  64.4 #> 10              65     3  62.9  62.9    62.9      62.9  62.9 #>  #> $learning #> # A tibble: 10 × 7 #>    learning.ceil    .n    .y .y_lo .y_mean .y_median .y_hi #>            <dbl> <int> <dbl> <dbl>   <dbl>     <dbl> <dbl> #>  1            34     1  44.2  30.6    44.2      44.2  57.7 #>  2            45     3  74.9  68.0    74.9      68.3  87.6 #>  3            48     3  73.0  71.1    73.0      71.9  75.9 #>  4            75     2  73.7  61.9    73.7      63.5  94.2 #>  5            58     4  66.5  66.5    66.5      66.5  66.5 #>  6            63     3  60.5  60.5    60.5      60.5  60.5 #>  7            72     3  70.0  70.0    70.0      70.0  70.0 #>  8            42     3  58.8  55.3    58.8      58.8  62.3 #>  9            55     4  59.3  59.3    59.3      59.3  59.3 #> 10            69     4  NA    NA      NA        NA    NA   #>  #> $raises #> # A tibble: 10 × 7 #>    raises.ceil    .n    .y .y_lo .y_mean .y_median .y_hi #>          <dbl> <int> <dbl> <dbl>   <dbl>     <dbl> <dbl> #>  1          43     1  39.6  38.9    39.6      39.6  40.4 #>  2          54     4  62.2  55.2    62.2      65.0  67.0 #>  3          59     3  62.9  61.2    62.9      62.1  65.1 #>  4          75     3  72.2  62.9    72.2      72.2  81.4 #>  5          63     5  66.2  65.1    66.2      65.5  67.8 #>  6          64     2  65.6  65.6    65.6      65.6  65.6 #>  7          79     4  64.0  61.7    64.0      64.0  66.3 #>  8          88     2  85.6  67.8    85.6      85.6 103.  #>  9          55     2  61.6  56.6    61.6      61.6  66.6 #> 10          70     4  63.6  63.6    63.6      63.6  63.6 #>  #> $critical #> # A tibble: 10 × 7 #>    critical.ceil    .n    .y .y_lo .y_mean .y_median .y_hi #>            <dbl> <int> <dbl> <dbl>   <dbl>     <dbl> <dbl> #>  1            67     3  68.5  52.6    68.5      68.5  84.4 #>  2            77     4  61.8  57.3    61.8      61.8  66.3 #>  3            80     5  62.2  56.2    62.2      61.7  69.0 #>  4            83     3  60.8  57.6    60.8      60.8  64.0 #>  5            84     1  66.9  66.9    66.9      66.9  66.9 #>  6            92     3  53.0  46.0    53.0      48.4  68.0 #>  7            49     1  54.7  45.3    54.7      53.7  65.0 #>  8            74     4  68.1  68.1    68.1      68.1  68.1 #>  9            78     3  72.8  66.0    72.8      72.8  79.5 #> 10            63     3  79.6  70.0    79.6      79.6  89.2 #>  #> $advance #> # A tibble: 9 × 7 #>   advance.ceil    .n    .y .y_lo .y_mean .y_median .y_hi #>          <dbl> <int> <dbl> <dbl>   <dbl>     <dbl> <dbl> #> 1           33     3  65.2  60.6    65.2      63.8  72.4 #> 2           35     5  65.5  62.2    65.5      63.6  70.5 #> 3           41     7  66.1  64.6    66.1      66.3  67.2 #> 4           47     5  71.5  70.7    71.5      71.5  72.2 #> 5           72     3  49.5  32.8    49.5      49.5  66.2 #> 6           25     1  69.6  58.4    69.6      69.6  80.8 #> 7           55     2  49.8  49.8    49.8      49.8  49.8 #> 8           36     1  NA    NA      NA        NA    NA   #> 9           49     3  NA    NA      NA        NA    NA   #>  get(mb_gam, type = 'single')  # full (unbootstrapped) model #> $complaints #> # A tibble: 10 × 7 #>    complaints.ceil    .n    .y .y_lo .y_mean .y_median .y_hi #>              <dbl> <int> <dbl> <dbl>   <dbl>     <dbl> <dbl> #>  1              37     1  47.9  47.9    47.9      47.9  47.9 #>  2              53     3  57.7  57.7    57.7      57.7  57.7 #>  3              57     3  60.1  60.1    60.1      60.1  60.1 #>  4              60     3  61.9  61.9    61.9      61.9  61.9 #>  5              63     4  63.8  63.8    63.8      63.8  63.8 #>  6              67     3  66.2  66.2    66.2      66.2  66.2 #>  7              75     4  71.1  71.1    71.1      71.1  71.1 #>  8              78     3  72.9  72.9    72.9      72.9  72.9 #>  9              83     3  75.9  75.9    75.9      75.9  75.9 #> 10              90     3  80.2  80.2    80.2      80.2  80.2 #>  #> $privileges #> # A tibble: 10 × 7 #>    privileges.ceil    .n    .y .y_lo .y_mean .y_median .y_hi #>              <dbl> <int> <dbl> <dbl>   <dbl>     <dbl> <dbl> #>  1              30     1  68.3  68.3    68.3      68.3  68.3 #>  2              42     5  66.8  66.8    66.8      66.8  66.8 #>  3              44     1  66.5  66.5    66.5      66.5  66.5 #>  4              46     3  66.3  66.3    66.3      66.3  66.3 #>  5              50     4  65.8  65.8    65.8      65.8  65.8 #>  6              52     3  65.5  65.5    65.5      65.5  65.5 #>  7              57     4  64.9  64.9    64.9      64.9  64.9 #>  8              65     3  63.9  63.9    63.9      63.9  63.9 #>  9              68     3  63.5  63.5    63.5      63.5  63.5 #> 10              83     3  61.6  61.6    61.6      61.6  61.6 #>  #> $learning #> # A tibble: 10 × 7 #>    learning.ceil    .n    .y .y_lo .y_mean .y_median .y_hi #>            <dbl> <int> <dbl> <dbl>   <dbl>     <dbl> <dbl> #>  1            34     1  61.9  61.9    61.9      61.9  61.9 #>  2            42     3  61.8  61.8    61.8      61.8  61.8 #>  3            45     3  61.8  61.8    61.8      61.8  61.8 #>  4            48     3  62.1  62.1    62.1      62.1  62.1 #>  5            55     4  63.6  63.6    63.6      63.6  63.6 #>  6            58     4  64.9  64.9    64.9      64.9  64.9 #>  7            63     3  67.4  67.4    67.4      67.4  67.4 #>  8            69     4  70.9  70.9    70.9      70.9  70.9 #>  9            72     3  72.7  72.7    72.7      72.7  72.7 #> 10            75     2  74.5  74.5    74.5      74.5  74.5 #>  #> $raises #> # A tibble: 10 × 7 #>    raises.ceil    .n    .y .y_lo .y_mean .y_median .y_hi #>          <dbl> <int> <dbl> <dbl>   <dbl>     <dbl> <dbl> #>  1          43     1  64.2  64.2    64.2      64.2  64.2 #>  2          54     4  64.9  64.9    64.9      64.9  64.9 #>  3          55     2  65.0  65.0    65.0      65.0  65.0 #>  4          59     3  65.2  65.2    65.2      65.2  65.2 #>  5          63     5  65.4  65.4    65.4      65.4  65.4 #>  6          64     2  65.5  65.5    65.5      65.5  65.5 #>  7          70     4  65.9  65.9    65.9      65.9  65.9 #>  8          75     3  66.2  66.2    66.2      66.2  66.2 #>  9          79     4  66.4  66.4    66.4      66.4  66.4 #> 10          88     2  67.0  67.0    67.0      67.0  67.0 #>  #> $critical #> # A tibble: 10 × 7 #>    critical.ceil    .n    .y .y_lo .y_mean .y_median .y_hi #>            <dbl> <int> <dbl> <dbl>   <dbl>     <dbl> <dbl> #>  1            49     1  55.7  55.7    55.7      55.7  55.7 #>  2            63     3  66.3  66.3    66.3      66.3  66.3 #>  3            67     3  67.8  67.8    67.8      67.8  67.8 #>  4            74     4  68.1  68.1    68.1      68.1  68.1 #>  5            77     4  67.2  67.2    67.2      67.2  67.2 #>  6            78     3  66.9  66.9    66.9      66.9  66.9 #>  7            80     5  66.0  66.0    66.0      66.0  66.0 #>  8            83     3  64.5  64.5    64.5      64.5  64.5 #>  9            84     1  64.0  64.0    64.0      64.0  64.0 #> 10            92     3  58.9  58.9    58.9      58.9  58.9 #>  #> $advance #> # A tibble: 9 × 7 #>   advance.ceil    .n    .y .y_lo .y_mean .y_median .y_hi #>          <dbl> <int> <dbl> <dbl>   <dbl>     <dbl> <dbl> #> 1           25     1  69.5  69.5    69.5      69.5  69.5 #> 2           33     3  67.6  67.6    67.6      67.6  67.6 #> 3           35     5  67.1  67.1    67.1      67.1  67.1 #> 4           36     1  66.8  66.8    66.8      66.8  66.8 #> 5           41     7  65.7  65.7    65.7      65.7  65.7 #> 6           47     5  64.2  64.2    64.2      64.2  64.2 #> 7           49     3  63.8  63.8    63.8      63.8  63.8 #> 8           55     2  62.3  62.3    62.3      62.3  62.3 #> 9           72     3  58.3  58.3    58.3      58.3  58.3 #>  # See get.ALE() for other options  # }"},{"path":"https://tripartio.github.io/ale/reference/ale-package.html","id":null,"dir":"Reference","previous_headings":"","what":"Interpretable Machine Learning and Statistical Inference with Accumulated Local Effects (ALE) — ale-package","title":"Interpretable Machine Learning and Statistical Inference with Accumulated Local Effects (ALE) — ale-package","text":"Accumulated Local Effects (ALE) initially developed model-agnostic approach global explanations results black-box machine learning algorithms. ALE key advantage approaches like partial dependency plots (PDP) SHapley Additive exPlanations (SHAP): values represent clean functional decomposition model. , ALE values affected presence absence interactions among variables mode. Moreover, computation relatively rapid. package reimplements algorithms calculating ALE data develops highly interpretable visualizations plotting ALE values. also extends original ALE concept add bootstrap-based confidence intervals ALE-based statistics can used statistical inference. details, see Okoli, Chitu. 2023. “Statistical Inference Using Machine Learning Classical Techniques Based Accumulated Local Effects (ALE).” arXiv. doi:10.48550/arXiv.2310.09877.","code":""},{"path":"https://tripartio.github.io/ale/reference/ale-package.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Interpretable Machine Learning and Statistical Inference with Accumulated Local Effects (ALE) — ale-package","text":"Okoli, Chitu. 2023. “Statistical Inference Using Machine Learning Classical Techniques Based Accumulated Local Effects (ALE).” arXiv. doi:10.48550/arXiv.2310.09877.","code":""},{"path":[]},{"path":"https://tripartio.github.io/ale/reference/ale-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Interpretable Machine Learning and Statistical Inference with Accumulated Local Effects (ALE) — ale-package","text":"Chitu Okoli Chitu.Okoli@skema.edu","code":""},{"path":"https://tripartio.github.io/ale/reference/ale.html","id":null,"dir":"Reference","previous_headings":"","what":"ALE data and statistics that describe a trained model — ALE","title":"ALE data and statistics that describe a trained model — ALE","text":"ALE S7 object contains ALE data statistics. details, see vignette('ale-intro') details examples .","code":""},{"path":"https://tripartio.github.io/ale/reference/ale.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"ALE data and statistics that describe a trained model — ALE","text":"","code":"ALE(   model,   x_cols = list(d1 = TRUE),   data = NULL,   y_col = NULL,   ...,   exclude_cols = NULL,   parallel = \"all\",   model_packages = NULL,   output_stats = TRUE,   output_boot_data = FALSE,   pred_fun = function(object, newdata, type = pred_type) {      stats::predict(object =     object, newdata = newdata, type = type)  },   pred_type = \"response\",   p_values = \"auto\",   aler_alpha = c(0.01, 0.05),   max_num_bins = 10,   boot_it = 0,   boot_alpha = 0.05,   boot_centre = \"mean\",   seed = 0,   y_type = NULL,   sample_size = 500,   silent = FALSE,   .bins = NULL )"},{"path":"https://tripartio.github.io/ale/reference/ale.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"ALE data and statistics that describe a trained model — ALE","text":"model model object. Required. Model ALE calculated. May kind R object can make predictions data. x_cols, exclude_cols character, list, formula. Columns names data requested one special x_cols formats ALE data calculated. Defaults 1D ALE columns data except y_col. See details documentation resolve_x_cols(). data dataframe. Dataset create predictions ALE. normally dataset model trained. provided, ALE() try detect automatically included model object. y_col character(1). Name outcome target label (y) variable. provided, ALE() try detect automatically model object. non-standard models, y_col provided. time--event (survival) models, see details. ... used. Inserted require explicit naming subsequent arguments. parallel non-negative integer(1) character(1) c(\"\", \"one\"). Number parallel threads (workers tasks) parallel execution constructor. default \"\" uses available physical logical CPU cores. \"one\" uses physical cores reserves one core system. Set parallel = 0 disable parallel processing. See details. model_packages character. Character vector names packages model depends might obvious parallel processing. get weird error messages parallel processing enabled (default) resolved setting parallel = 0, might need specify model_packages. See details. output_stats logical(1). TRUE (default), return ALE statistics. output_boot_data logical(1). TRUE, return raw ALE data bootstrap iteration. Default FALSE. pred_fun, pred_type function,character(1). pred_fun function returns vector predicted values type pred_type model data. See details. p_values instructions calculating p-values. Possible values : NULL: p-values calculated. ALEpDist object: object used calculate p-values. \"auto\" (default): statistics requested (output_stats = TRUE) bootstrapping requested (boot_it > 0), constructor try automatically create fast surrogate ALEpDist object; otherwise, p-values calculated. However, automatic creation surrogate ALEpDist object works standard R model types. automatic process errors, must explicitly create provide ALEpDist() object. Note: although faster surrogate p-values convenient interactive analysis, acceptable definitive conclusions publication. See details . aler_alpha numeric(2) 0 1. Thresholds p-values (\"alpha\") confidence interval ranges ALER band p_values provided (, NULL). inner band range median value y ± aler_alpha[2] relevant ALE statistic (usually ALE range normalized ALE range). second outer band, range median ± aler_alpha[1]. example, ALE plots, default aler_alpha = c(0.01, 0.05), inner band median ± ALER minimum maximum p = 0.05 outer band median ± ALER minimum maximum p = 0.01. max_num_bins positive integer(1). Maximum number ALE bins numeric x_cols variables. number bins eventually lower number unique values numeric variable max_num_bins. Non-numeric variables (binary categorical) always use actual values ALE bins. boot_it non-negative integer(1). Number bootstrap iterations data-bootstrapping ALE data. appropriate models developed cross-validation. models validated, full-model bootstrapping used instead ModelBoot() class object. See details . default boot_it = 0 turns bootstrapping. boot_alpha numeric(1) 0 1. ALE bootstrapped (boot_it > 0), boot_alpha specifies thresholds p-values (\"alpha\") percentile-based confidence interval range bootstrapped ALE values. bootstrap confidence intervals lowest highest (1 - 0.05) / 2 percentiles. example, boot_alpha = 0.05 (default), confidence intervals 2.5 (low) 97.5 (high) percentiles. boot_centre character(1) c('mean', 'median'). bootstrapping, main estimate ALE y value considered boot_centre. Regardless value specified , mean median available. seed integer(1). Random seed. Supply runs assure identical random ALE data generated time bootstrapping. Without bootstrapping, ALE deterministic algorithm result identical results time regardless seed specified. However, parallel processing enabled (default), exact computing setup give reproducible results. reproducible results across different computers, turn parallelization parallel = 0. y_type character(1) c('binary', 'numeric', 'categorical', 'ordinal'). Datatype y (outcome) variable. Normally determined automatically; provide error message complex non-standard model requires . sample_size non-negative integer(1). Size sample data returned ALE object. primarily used rug plots ALEPlots(). silent logical(1), default FALSE. TRUE, display non-essential messages execution (progress bars). Regardless, warnings errors always display. See details customize progress bars. .bins Internal use . List ALE bin n count vectors. provided, vectors used set intervals ALE x axis variable. default (NULL), ALE() automatically calculates bins. .bins normally used advanced analyses bins previous analysis reused subsequent analyses (example, full model bootstrapping ModelBoot()).","code":""},{"path":"https://tripartio.github.io/ale/reference/ale.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"ALE data and statistics that describe a trained model — ALE","text":"object class ALE properties effect params.","code":""},{"path":"https://tripartio.github.io/ale/reference/ale.html","id":"properties","dir":"Reference","previous_headings":"","what":"Properties","title":"ALE data and statistics that describe a trained model — ALE","text":"effect Stores ALE data , optionally, ALE statistics bootstrap data one categories. params parameters used calculate ALE data. include arguments used construct ALE object. either values provided user used default user change also includes several objects created within constructor. extra objects described , well parameters stored differently form arguments:","code":"* `max_d`: the highest dimension of ALE data present. If only 1D ALE is present, then `max_d == 1`. If even one 2D ALE element is present (even with no 1D), then `max_d == 2`. * `requested_x_cols`,`ordered_x_cols`: `requested_x_cols` is the resolved list of `x_cols` as requested by the user (that is, `x_cols` minus `exclude_cols`). `ordered_x_cols` is the same set of `x_cols` but arranged in the internal storage order. * `y_cats`: categories for categorical classification models. For non-categorical models, this is the same as `y_col`. * `y_type`: high-level datatype of the y outcome variable. * `y_summary`: summary statistics of y values used for the ALE calculation. These statistics are based on the actual values of `y_col` unless if `y_type` is a probability or other value that is constrained in the `[0, 1]` range, in which case `y_summary` is based on the predictions of `y_col` from `model` on the `data`. `y_summary` is a named numeric matrix. For most outcomes with a single value per predicted row, there is just one column with the same name as `y_col`. For categorical y outcomes, there is one column for each category in `y_cats` plus an additional column with the same name as `y_col`; this is the mean of the categorical columns. The rows are named mostly as the percentile of the y values. E.g., the '5%' row is the 5th percentile of y values. The following named rows have special meanings: * `min`, `mean`, `max`: the minimum, mean, and maximum y values, respectively. Note that the median is `50%`, the 50th percentile. * `aler_lo_lo`, `aler_lo`, `aler_hi`, `aler_hi_hi`: When p-values are present, `aler_lo` and `aler_hi` are the inner lower and upper confidence intervals of `y_col` values with respect to the median (`50%`); `aler_lo_lo` and `aler_hi_hi` are the outer confidence intervals. See the documentation for the `aler_alpha` argument to understand how these are determined. Without p-values, these elements are absent. * `model`: selected elements that describe the `model` that the `ALE` object interprets. * `data`: selected elements that describe the `data` used to produce the `ALE` object. To avoid the large size of duplicating `data` entirely, only a sample of the size of the `sample_size` argument is retained. * `probs_inverted`: `TRUE` if the original probability values of the ALE object have been inverted using [invert_probs()]. `FALSE`, `NULL`, or absent otherwise."},{"path":"https://tripartio.github.io/ale/reference/ale.html","id":"custom-predict-function","dir":"Reference","previous_headings":"","what":"Custom predict function","title":"ALE data and statistics that describe a trained model — ALE","text":"calculation ALE requires modifying several values original data. Thus, ALE() needs direct access predict function model. default, ALE() uses generic default predict function form predict(object, newdata, type) default prediction type 'response'. , however, desired prediction values generated format, user must specify want. often, modification needed change prediction type value setting pred_type argument (e.g., 'prob' generated classification probabilities). desired predictions need different function signature, user must create custom prediction function pass pred_fun. requirements custom function : must take three required arguments nothing else: object: model newdata: dataframe compatible table type tibble data.table type: string; usually specified type = pred_type argument names according R convention generic stats::predict() function. must return vector matrix numeric values prediction. can see example custom prediction function.","code":""},{"path":"https://tripartio.github.io/ale/reference/ale.html","id":"ale-statistics-and-p-values","dir":"Reference","previous_headings":"","what":"ALE statistics and p-values","title":"ALE data and statistics that describe a trained model — ALE","text":"details ALE-based statistics (ALED, ALER, NALED, NALER), see vignette('ale-statistics'). general details calculation p-values, see ALEpDist(). , clarify automatic calculation p-values ALE() constructor. explained documentation p_values argument, default p_values = \"auto\" try automatically create fast surrogate ALEpDist object. However, condition statistics requested (default, output_stats = TRUE) bootstrapping also requested (default, boot_it value greater 0). Requesting statistics necessary otherwise p-values needed. However, requirement requiring bootstrapping pragmatic design choice. challenge creating ALEpDist object can slow. (Even fast surrogate option rarely takes less 10 seconds, even parallelization.) Thus, optimize speed, p-values calculated unless requested. However, user requests bootstrapping (slower requesting ), can assumed willing sacrifice speed sake greater precision ALE analysis; thus, extra time taken least create relatively faster surrogate ALEpDist object.","code":""},{"path":"https://tripartio.github.io/ale/reference/ale.html","id":"parallel-processing","dir":"Reference","previous_headings":"","what":"Parallel processing","title":"ALE data and statistics that describe a trained model — ALE","text":"Parallel processing using {furrr} framework enabled default. number parallel threads (workers cores) specified parallel argument. default (parallel = \"\"), use available physical logical CPU cores. However, procedure slow (large dataset slow prediction algorithm), might want set parallel = \"one\"), use faster physical cores reserve one physical core computer slow continue working tasks procedure runs. disable parallel processing, set parallel = 0. {ale} package able automatically recognize load packages needed, parallel processing enabled (default), packages might properly loaded. problem might indicated get strange error message mentions something somewhere \"progress interrupted\" \"future\", especially see errors progress bars begin displaying (assuming disable progress bars silent = TRUE). case, first try disabling parallel processing parallel = 0. resolves problem, get faster parallel processing work, try adding package names needed model model_packages argument, e.g., model_packages = c('tidymodels', 'mgcv').","code":""},{"path":"https://tripartio.github.io/ale/reference/ale.html","id":"time-to-event-survival-models","dir":"Reference","previous_headings":"","what":"Time-to-event (survival) models","title":"ALE data and statistics that describe a trained model — ALE","text":"time--event (survival) models, set following arguments: y_col must set name binary event column. Include time column exclude_cols argument ALE calculated, e.g., exclude_cols = 'time'. essential excluded, always result exactly zero ALE effect time outcome, predictor, time--event model's outcome, calculating waste time. pred_type must specified according desired type argument predict() method time--event algorithm (e.g., \"risk\", \"survival\", \"time\", etc.). pred_fun might work fine without modification long settings configured. However, non-standard time--event models, custom pred_fun specified might needed.","code":""},{"path":"https://tripartio.github.io/ale/reference/ale.html","id":"progress-bars","dir":"Reference","previous_headings":"","what":"Progress bars","title":"ALE data and statistics that describe a trained model — ALE","text":"Progress bars implemented {progressr} package. details customizing progress bars, see introduction {progressr} package. disable progress bars calling function ale package, set silent = TRUE.","code":""},{"path":"https://tripartio.github.io/ale/reference/ale.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"ALE data and statistics that describe a trained model — ALE","text":"Okoli, Chitu. 2023. “Statistical Inference Using Machine Learning Classical Techniques Based Accumulated Local Effects (ALE).” arXiv. doi:10.48550/arXiv.2310.09877.","code":""},{"path":"https://tripartio.github.io/ale/reference/ale.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"ALE data and statistics that describe a trained model — ALE","text":"","code":"# Sample 1000 rows from the ggplot2::diamonds dataset (for a simple example) set.seed(0) diamonds_sample <- ggplot2::diamonds[sample(nrow(ggplot2::diamonds), 1000), ]  # Create a GAM model with flexible curves to predict diamond price # Smooth all numeric variables and include all other variables gam_diamonds <- mgcv::gam(   price ~ s(carat) + s(depth) + s(table) + s(x) + s(y) + s(z) +     cut + color + clarity +     ti(carat, by = clarity),  # a 2D interaction   data = diamonds_sample ) summary(gam_diamonds) #>  #> Family: gaussian  #> Link function: identity  #>  #> Formula: #> price ~ s(carat) + s(depth) + s(table) + s(x) + s(y) + s(z) +  #>     cut + color + clarity + ti(carat, by = clarity) #>  #> Parametric coefficients: #>             Estimate Std. Error t value Pr(>|t|)     #> (Intercept)  3001.89     260.67  11.516  < 2e-16 *** #> cut.L         127.31     153.83   0.828 0.408134     #> cut.Q          72.52     111.14   0.653 0.514238     #> cut.C         -55.92      83.03  -0.673 0.500810     #> cut^4          51.68      64.61   0.800 0.423979     #> color.L     -1632.19      91.78 -17.785  < 2e-16 *** #> color.Q      -472.22      83.82  -5.634 2.34e-08 *** #> color.C       -35.91      76.97  -0.467 0.640944     #> color^4        27.23      70.13   0.388 0.697875     #> color^5      -142.75      65.77  -2.170 0.030237 *   #> color^6         1.52      59.47   0.026 0.979618     #> clarity.L   -1523.84    1015.27  -1.501 0.133718     #> clarity.Q   -3469.55     893.39  -3.884 0.000110 *** #> clarity.C   -1380.98     790.93  -1.746 0.081137 .   #> clarity^4     678.13     761.51   0.890 0.373429     #> clarity^5    1437.67     622.47   2.310 0.021127 *   #> clarity^6    1305.16     379.50   3.439 0.000609 *** #> clarity^7     653.21     159.89   4.085 4.78e-05 *** #> --- #> Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 #>  #> Approximate significance of smooth terms: #>                         edf Ref.df      F p-value     #> s(carat)              8.594  8.888  6.954 < 2e-16 *** #> s(depth)              2.177  2.874  0.778 0.42173     #> s(table)              1.000  1.000  0.107 0.74371     #> s(x)                  7.954  8.513  2.788 0.00401 **  #> s(y)                  5.234  6.467  8.077 < 2e-16 *** #> s(z)                  3.404  4.479  1.623 0.15244     #> ti(carat):claritySI2  3.737  3.948 14.107 < 2e-16 *** #> ti(carat):claritySI1  1.000  1.000 52.139 < 2e-16 *** #> ti(carat):clarityVS2  2.884  3.390 22.095 < 2e-16 *** #> ti(carat):clarityVS1  3.948  3.996 33.200 < 2e-16 *** #> ti(carat):clarityVVS2 2.279  2.660 55.728 < 2e-16 *** #> ti(carat):clarityVVS1 3.924  3.994 36.573 < 2e-16 *** #> ti(carat):clarityIF   3.911  3.992 38.323 < 2e-16 *** #> --- #> Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 #>  #> R-sq.(adj) =  0.962   Deviance explained = 96.5% #> GCV = 6.2787e+05  Scale est. = 5.8514e+05  n = 1000   # \\donttest{  # Simple ALE without bootstrapping: by default, all 1D ALE effects ale_gam_diamonds <- ALE(gam_diamonds) #> Warning: Could not recover model data from environment. Please make sure your #>   data is available in your workspace. #>   Trying to retrieve data from the model frame now. #> Error in (function (.x, .f, ..., .progress = FALSE) {    map_(\"list\", .x, .f, ..., .progress = .progress)})(.x = c(\"cut\", \"color\"), .f = function (...) {    {        ...furrr_chunk_seeds_i <- ...furrr_chunk_seeds_env[[\"i\"]]        ...furrr_chunk_seeds_env[[\"i\"]] <- ...furrr_chunk_seeds_i +             1L        assign(x = \".Random.seed\", value = ...furrr_chunk_seeds[[...furrr_chunk_seeds_i]],             envir = globalenv(), inherits = FALSE)    }    NULL    ...furrr_out <- ...furrr_fn(...)    ...furrr_out}): ℹ In index: 1. #> Caused by error in `map()`: #> ℹ In index: 1. #> Caused by error in `predict.gam()`: #> ! newdata is a model.frame: it should contain all required variables  # Simple printing of all plots plot(ale_gam_diamonds) #> Error: object 'ale_gam_diamonds' not found  # Bootstrapped ALE # This can be slow, since bootstrapping runs the algorithm boot_it times  # Create ALE with 100 bootstrap samples ale_gam_diamonds_boot <- ALE(   gam_diamonds,   # request all 1D ALE effects and only the carat:clarity 2D effect   list(d1 = TRUE, d2 = 'carat:clarity'),   boot_it = 100 ) #> Warning: Could not recover model data from environment. Please make sure your #>   data is available in your workspace. #>   Trying to retrieve data from the model frame now. #> Error in (function (.x, .f, ..., .progress = FALSE) {    map_(\"list\", .x, .f, ..., .progress = .progress)})(.x = c(\"carat:clarity\", \"cut\", \"color\"), .f = function (...) {    {        ...furrr_chunk_seeds_i <- ...furrr_chunk_seeds_env[[\"i\"]]        ...furrr_chunk_seeds_env[[\"i\"]] <- ...furrr_chunk_seeds_i +             1L        assign(x = \".Random.seed\", value = ...furrr_chunk_seeds[[...furrr_chunk_seeds_i]],             envir = globalenv(), inherits = FALSE)    }    NULL    ...furrr_out <- ...furrr_fn(...)    ...furrr_out}): ℹ In index: 1. #> Caused by error in `map()`: #> ℹ In index: 1. #> Caused by error in `predict.gam()`: #> ! newdata is a model.frame: it should contain all required variables  #' More advanced plot manipulation ale_plots <- plot(ale_gam_diamonds_boot) # Create an ALEPlots object #> Error: object 'ale_gam_diamonds_boot' not found  # Print the plots: First page prints 1D ALE; second page prints 2D ALE ale_plots  # or print(ale_plots) to be explicit #> Error: object 'ale_plots' not found  # Extract specific plots (as lists of ggplot objects) get(ale_plots, 'carat')  # extract a specific 1D plot #> Error: object 'ale_plots' not found get(ale_plots, 'carat:clarity')  # extract a specific 2D plot #> Error: object 'ale_plots' not found get(ale_plots, type = 'effect')  # ALE effects plot #> Error: object 'ale_plots' not found # See help(get.ALEPlots) for more options, such as for categorical plots    # If the predict function you want is non-standard, you may define a # custom predict function. It must return a single numeric vector. custom_predict <- function(object, newdata, type = pred_type) {   predict(object, newdata, type = type, se.fit = TRUE)$fit }  ale_gam_diamonds_custom <- ALE(   gam_diamonds,   pred_fun = custom_predict, pred_type = 'link' ) #> Warning: Could not recover model data from environment. Please make sure your #>   data is available in your workspace. #>   Trying to retrieve data from the model frame now. #> Error in (function (.x, .f, ..., .progress = FALSE) {    map_(\"list\", .x, .f, ..., .progress = .progress)})(.x = c(\"cut\", \"color\"), .f = function (...) {    {        ...furrr_chunk_seeds_i <- ...furrr_chunk_seeds_env[[\"i\"]]        ...furrr_chunk_seeds_env[[\"i\"]] <- ...furrr_chunk_seeds_i +             1L        assign(x = \".Random.seed\", value = ...furrr_chunk_seeds[[...furrr_chunk_seeds_i]],             envir = globalenv(), inherits = FALSE)    }    NULL    ...furrr_out <- ...furrr_fn(...)    ...furrr_out}): ℹ In index: 1. #> Caused by error in `map()`: #> ℹ In index: 1. #> Caused by error in `predict.gam()`: #> ! newdata is a model.frame: it should contain all required variables  # Plot the ALE data plot(ale_gam_diamonds_custom) #> Error: object 'ale_gam_diamonds_custom' not found   # How to retrieve specific types of ALE data from an ALE object. ale_diamonds_with_boot_data <- ALE(   gam_diamonds,   # For detailed options for x_cols, see examples at resolve_x_cols()   x_cols = ~ carat + cut + clarity + carat:clarity + color:depth,   output_boot_data = TRUE,   boot_it = 10  # just for demonstration ) #> Warning: Could not recover model data from environment. Please make sure your #>   data is available in your workspace. #>   Trying to retrieve data from the model frame now. #> Error in (function (.x, .f, ..., .progress = FALSE) {    map_(\"list\", .x, .f, ..., .progress = .progress)})(.x = \"color:depth\", .f = function (...) {    {        ...furrr_chunk_seeds_i <- ...furrr_chunk_seeds_env[[\"i\"]]        ...furrr_chunk_seeds_env[[\"i\"]] <- ...furrr_chunk_seeds_i +             1L        assign(x = \".Random.seed\", value = ...furrr_chunk_seeds[[...furrr_chunk_seeds_i]],             envir = globalenv(), inherits = FALSE)    }    NULL    ...furrr_out <- ...furrr_fn(...)    ...furrr_out}): ℹ In index: 1. #> Caused by error in `map()`: #> ℹ In index: 1. #> Caused by error in `predict.gam()`: #> ! newdata is a model.frame: it should contain all required variables  # See ?get.ALE for details on the various kinds of data that may be retrieved. get(ale_diamonds_with_boot_data, ~ carat + color:depth)  # default ALE data #> Error: object 'ale_diamonds_with_boot_data' not found get(ale_diamonds_with_boot_data, what = 'boot_data')  # raw bootstrap data #> Error: object 'ale_diamonds_with_boot_data' not found get(ale_diamonds_with_boot_data, stats = 'estimate')  # summary statistics #> Error: object 'ale_diamonds_with_boot_data' not found get(ale_diamonds_with_boot_data, stats = c('aled', 'naled')) #> Error: object 'ale_diamonds_with_boot_data' not found get(ale_diamonds_with_boot_data, stats = 'all') #> Error: object 'ale_diamonds_with_boot_data' not found get(ale_diamonds_with_boot_data, stats = 'conf_regions') #> Error: object 'ale_diamonds_with_boot_data' not found get(ale_diamonds_with_boot_data, stats = 'conf_sig') #> Error: object 'ale_diamonds_with_boot_data' not found # }"},{"path":"https://tripartio.github.io/ale/reference/census.html","id":null,"dir":"Reference","previous_headings":"","what":"Census Income — census","title":"Census Income — census","text":"Census data indicates, among details, respondent's income exceeds $50,000 per year. Also known \"Adult\" dataset.","code":""},{"path":"https://tripartio.github.io/ale/reference/census.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Census Income — census","text":"","code":"census"},{"path":"https://tripartio.github.io/ale/reference/census.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Census Income — census","text":"tibble 32,561 rows 15 columns: higher_income TRUE income > $50,000 age continuous workclass Private, Self-emp--inc, Self-emp-inc, Federal-gov, Local-gov, State-gov, Without-pay, Never-worked fnlwgt continuous. \"proxy demographic background people: 'People similar demographic characteristics similar weights'\" details, see https://www.openml.org/search?type=data&id=1590. education Bachelors, -college, 11th, HS-grad, Prof-school, Assoc-acdm, Assoc-voc, 9th, 7th-8th, 12th, Masters, 1st-4th, 10th, Doctorate, 5th-6th, Preschool education_num continuous marital_status Married-civ-spouse, Divorced, Never-married, Separated, Widowed, Married-spouse-absent, Married-AF-spouse occupation Tech-support, Craft-repair, -service, Sales, Exec-managerial, Prof-specialty, Handlers-cleaners, Machine-op-inspct, Adm-clerical, Farming-fishing, Transport-moving, Priv-house-serv, Protective-serv, Armed-Forces relationship Wife, -child, Husband, --family, -relative, Unmarried race White, Asian-Pac-Islander, Amer-Indian-Eskimo, , Black sex Female, Male capital_gain continuous capital_loss continuous hours_per_week continuous native_country United-States, Cambodia, England, Puerto-Rico, Canada, Germany, Outlying-US(Guam-USVI-etc), India, Japan, Greece, South, China, Cuba, Iran, Honduras, Philippines, Italy, Poland, Jamaica, Vietnam, Mexico, Portugal, Ireland, France, Dominican-Republic, Laos, Ecuador, Taiwan, Haiti, Columbia, Hungary, Guatemala, Nicaragua, Scotland, Thailand, Yugoslavia, El-Salvador, Trinidad&Tobago, Peru, Hong, Holland-Netherlands dataset licensed Creative Commons Attribution 4.0 International (CC 4.0) license.","code":""},{"path":"https://tripartio.github.io/ale/reference/census.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Census Income — census","text":"Becker,Barry Kohavi,Ronny. (1996). Adult. UCI Machine Learning Repository. https://doi.org/10.24432/C5XW20.","code":""},{"path":"https://tripartio.github.io/ale/reference/customize.html","id":null,"dir":"Reference","previous_headings":"","what":"Customize plots contained in an ALEPlots object — customize","title":"Customize plots contained in an ALEPlots object — customize","text":"Customize ALEPlots object modifying plots indicated combination x_cols, type, cats specified. arguments indicate common customizations zooming ; see argument documentation available simple options. flexible option specify list ggplot layers layers argument; appends provided layers plot applying ggplot2::+.gg() method . Thus, customization supported appending ggplot layers can applied. layers simple options like zoom_y specified, layers layers applied first option applied order presented argument list. full control order customizations, provide layers. See get.ALE() explanation parameters described .","code":""},{"path":"https://tripartio.github.io/ale/reference/customize.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Customize plots contained in an ALEPlots object — customize","text":"","code":"customize(   plots_obj,   x_cols = NULL,   ...,   exclude_cols = NULL,   type = \"ale\",   cats = NULL,   layers = NULL,   zoom_x = NULL,   zoom_y = NULL )"},{"path":"https://tripartio.github.io/ale/reference/customize.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Customize plots contained in an ALEPlots object — customize","text":"plots_obj ALEPlots object customize. x_cols, exclude_cols See documentation get.ALE() ... used. Inserted require explicit naming subsequent arguments. type See documentation get.ALE() cats See documentation get.ALE() layers List ggplot layers. appended plot indicated combination x_cols, type, cats applying ggplot2 + operator . zoom_x, zoom_y numeric(2). Zoom specified plots match specified x y limits, respectively. Must two-element numeric vector first element <= second. Default NULL zoom.","code":""},{"path":"https://tripartio.github.io/ale/reference/customize.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Customize plots contained in an ALEPlots object — customize","text":"ALEPlots object elements specified x_cols exclude_cols modified accordingly. Non-specified elements modified.","code":""},{"path":"https://tripartio.github.io/ale/reference/get.ALE.html","id":null,"dir":"Reference","previous_headings":"","what":"get method for ALE objects — get.ALE","title":"get method for ALE objects — get.ALE","text":"Retrieve specific elements ALE object.","code":""},{"path":"https://tripartio.github.io/ale/reference/get.ALE.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"get method for ALE objects — get.ALE","text":"obj ALE object retrieve elements. x_cols, exclude_cols character, list, formula. Columns names interaction terms obj requested one special x_cols formats. default value NULL x_cols retrieves available data output requested . See details documentation resolve_x_cols(). character(1). kind output requested. Must either \"ale\" (default) \"boot_data\". retrieve ALE statistics, see stats argument. ... used. Inserted require explicit naming subsequent arguments. stats character(1). Retrieve ALE statistics. stats specified, must left default (\"ale\"). Otherwise, get() errors stats specified value. See return value details valid values stats. cats character. Optional category names retrieve ALE categorical y outcome model. ale_centre documentation ALEPlots() simplify logical(1). TRUE (default), results simplified simplest list structure possible give requested results. FALSE, complex consistent list structure returned; might preferred programmatic non-interactive use. silent See documentation resolve_x_cols()","code":""},{"path":"https://tripartio.github.io/ale/reference/get.ALE.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"get method for ALE objects — get.ALE","text":"Regardless requested data, get.ALE() common structure: one category y outcome returned, top level list named category. , however, y outcome categorical one category multiple possibilities specified using cats argument, top level never categories, regardless value simplify. next level (top level zero one category) list one two levels: d1: 1D ALE elements. d2: 2D ALE elements. However, elements one dimension (either 1D 2D) requested simplify = TRUE (default), empty list eliminated level skipped provide elements present. example, 1D ALE data requested, d1 sublist list ALE data described next level. simplify = FALSE, d1 d2 sublists always returned; empty sublist NULL. results follow general structure just described, specific type data returned depends values stats arguments: = 'ale' (default) stats = NULL (default) list whose elements, named requested x variable, tibble. rows represent one ALE bin. tibble following columns: * var.bin var.ceil var name variable (column): non-numeric x, var.bin value ALE categories. numeric x, var.ceil value upper bound (ceiling) ALE bin. first \"bin\" numeric variables represents minimum value. 2D ALE var1 var2 interaction, var1.bin var2.bin columns returned (var1.ceil var2.ceilfor numeric var1 var2). * .n: number rows data bin represented var.bin var.ceil. numeric x, first bin contains data elements exactly minimum value x. often 1, might 1 one data element exactly minimum value. * .y: ALE function value calculated bin. bootstrapped ALE, .y_mean default .y_median boot_centre = 'median'. Regardless, .y_mean .y_median returned columns . * .y_lo, .y_hi: lower upper confidence intervals, respectively, bootstrapped .y value based boot_alpha argument ALE() constructor. = 'boot_data' stats = NULL (default) list whose elements, named requested x variable, tibble. data .y_mean, .y_median, .y_lo, .y_hi summarized = 'ale'. rows represent one ALE bin specified bootstrap iteration. tibble following columns: * .: bootstrap iteration. Iteration 0 represents ALE calculations full dataset; remaining values .1 boot_it (number bootstrap iterations specified ALE() constructor. * var var name variable (column): non-numeric x, var value ALE categories. numeric x, var value upper bound (ceiling) ALE bin. otherwise similar meanings described = 'ale' . * .n .y: = 'ale'. = 'ale' (default) stats = 'estimate' list elements d1 d2 value ALE statistic. row represents one variable interaction. tibble following columns: * term: variables columns 1D 2D ALE statistic. * aled, aler_min, aler_max, naled, naler_min, naler_max: respective ALE statistic variable interaction. = 'ale' (default) stats one values c('aled', 'aler_min', 'aler_max', 'naled', 'naler_min', 'naler_max') list elements d1 d2 distribution value single requested ALE statistic. element d1 d2 tibble. row represents one statistic one variable interaction. tibble following columns: * term: stats = 'estimate'. * statistic: requested ALE statistic(s). * estimate, mean, median: average bootstrapped value requested statistic. estimate equal either mean median depending boot_centre argument ALE() constructor. ALE bootstrapped, estimate, mean, median equal. * conf.low, conf.high: lower upper confidence intervals, respectively, bootstrapped statistic based boot_alpha argument ALE() constructor. ALE bootstrapped, estimate, conf.low, conf.high equal. = 'ale' (default) stats = '' list elements d1 d2 distribution values available ALE statistics requested variables interactions. Whereas stats = 'aled' (example) format returns data single statistic, stats = '' returns statistics requested variables. Thus, data structure columns identical single statistics , except available ALE statistics returned. = 'ale' (default) stats = 'conf_regions' list elements d1 d2 confidence regions requested variables interactions. element list requested d1 d2 sub-elements described general structure . data element tibble confidence regions single variable interaction. explanation columns, see vignette('ale-statistics'). = 'ale' (default) stats = 'conf_sig' Identical structure stats = 'conf_regions' except elements filtered terms (variables interactions) statistically significant confidence regions exceeding threshold inner ALER band, specifically, least obj@params$aler_alpha[2] rows data. See vignette(\"ale-statistics\") details.","code":""},{"path":"https://tripartio.github.io/ale/reference/get.ALE.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"get method for ALE objects — get.ALE","text":"","code":"# See examples at ALE() for a demonstration of how to use the get() method."},{"path":"https://tripartio.github.io/ale/reference/get.ALEPlots.html","id":null,"dir":"Reference","previous_headings":"","what":"get method for ALEPlots objects — get.ALEPlots","title":"get method for ALEPlots objects — get.ALEPlots","text":"Retrieve specific plots ALEPlots object. Unlike subset.ALEPlots() returns ALEPlots object subsetted x_cols variables interactions, get.ALEPlots() method returns list ggplot2::ggplot objects specified return value description. retain special ALEPlots behaviour like plotting, printing, summarizing multiple plots, use subset.ALEPlots() instead. See get.ALE() explanation parameters described .","code":""},{"path":"https://tripartio.github.io/ale/reference/get.ALEPlots.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"get method for ALEPlots objects — get.ALEPlots","text":"obj ALEPlots object retrieve ALE elements. type character(1). type ALEPlots retrieve: 'ale' standard ALE plots 'effect' ALE effects plots. See cats argument options categorical plots. cats character. categories (one ) categorical outcome variable retrieve. retrieve categories individual category plots, leave cats default NULL. categorical plots combine categories, specify cats = \".\". (forget \".\" \".\", avoids naming conflicts legitimate categories might named \"\".) -category plots, type must set \"overlay\" \"facet\" specific desired type categorical plot.","code":""},{"path":"https://tripartio.github.io/ale/reference/get.ALEPlots.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"get method for ALEPlots objects — get.ALEPlots","text":"list ggplot objects described documentation return value get.ALE(). different subset.ALEPlots(), returns ALEPlots object subsetted x_cols variables interactions.","code":""},{"path":"https://tripartio.github.io/ale/reference/get.ModelBoot.html","id":null,"dir":"Reference","previous_headings":"","what":"get method for ModelBoot objects — get.ModelBoot","title":"get method for ModelBoot objects — get.ModelBoot","text":"Retrieve specific ALE elements ModelBoot object. method similar get.ALE() except user may specify type ALE data retrieve (see argument definition details). See get.ALE() explanation parameters described .","code":""},{"path":"https://tripartio.github.io/ale/reference/get.ModelBoot.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"get method for ModelBoot objects — get.ModelBoot","text":"obj ModelBoot object retrieve ALE elements. type character(1). type ModelBoot ALE elements retrieve: 'single' ALE calculated full data set 'boot' bootstrapped ALE data (based full-model bootstrapping). default 'auto' retrieve 'boot' available 'single' otherwise.","code":""},{"path":"https://tripartio.github.io/ale/reference/get.ModelBoot.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"get method for ModelBoot objects — get.ModelBoot","text":"See get.ALE()","code":""},{"path":"https://tripartio.github.io/ale/reference/get.html","id":null,"dir":"Reference","previous_headings":"","what":"S7 generic get method for objects in the ale package — get","title":"S7 generic get method for objects in the ale package — get","text":"Retrieve specific data elements object based X column names. obj object ale package, generic passes arguments base::get() function.","code":""},{"path":"https://tripartio.github.io/ale/reference/get.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"S7 generic get method for objects in the ale package — get","text":"","code":"get(obj, ...)"},{"path":"https://tripartio.github.io/ale/reference/get.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"S7 generic get method for objects in the ale package — get","text":"obj object. ... ale package objects, instructions predictor (x) columns retrieved. everything else, arguments pass base::get().","code":""},{"path":"https://tripartio.github.io/ale/reference/invert_probs.html","id":null,"dir":"Reference","previous_headings":"","what":"Invert ALE Probabilities — invert_probs","title":"Invert ALE Probabilities — invert_probs","text":"Inverts predicted probabilities ALE object reflect complementary outcomes (.e., 1 - p). particularly useful model probability predictions opposite desired easy interpretability. invert_probs(), need change original data retrain model; ALE data, p-values, subsequent ALE plots reflect desired inverted probabilities.","code":""},{"path":"https://tripartio.github.io/ale/reference/invert_probs.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Invert ALE Probabilities — invert_probs","text":"","code":"invert_probs(ale_obj, rename_y_col = NULL, force = FALSE)"},{"path":"https://tripartio.github.io/ale/reference/invert_probs.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Invert ALE Probabilities — invert_probs","text":"ale_obj object class ALE. rename_y_col character(1). provided, renames y outcome column. probabilities inverted, name outcome column often needs change intuitive interpretability. default NULL change outcome column name. force logical(1). TRUE, inverts probabilities even already inverted (reverting ). default FALSE error probabilities already inverted.","code":""},{"path":"https://tripartio.github.io/ale/reference/invert_probs.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Invert ALE Probabilities — invert_probs","text":"updated ALE object probabilities relevant statistics inverted.","code":""},{"path":"https://tripartio.github.io/ale/reference/invert_probs.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Invert ALE Probabilities — invert_probs","text":"function inverts ALE y-values (.e., .y, .y_mean, .y_median, etc.) terms, including main ALE effects, bootstrap data, ALE statistics (aler_min, aler_max, etc.). also updates y_col name y_summary column names rename_y_col provided. ALE object already inverted (probs_inverted = TRUE), function throws error default. force reinversion (.e., revert original probabilities), set force = TRUE. operation permitted y-summary probabilities [0, 1] interval.","code":""},{"path":"https://tripartio.github.io/ale/reference/invert_probs.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Invert ALE Probabilities — invert_probs","text":"","code":"# \\donttest{ # Binary model setosa <- iris |>   dplyr::mutate(setosa = Species == \"setosa\") |>   dplyr::select(-Species)  ale_obj <- glm(setosa ~ ., data = setosa, family = binomial()) |>   ALE() #> Warning: glm.fit: algorithm did not converge #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: no non-missing arguments to max; returning -Inf  # Invert the predicted probabilities ale_inverted <- invert_probs(ale_obj)  # Revert back to original by inverting again ale_reverted <- invert_probs(ale_inverted, force = TRUE) #> ! Probabilities are already inverted; they will now be reverted.  # }"},{"path":"https://tripartio.github.io/ale/reference/plot.ALEPlots.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot method for ALEPlots object — plot.ALEPlots","title":"Plot method for ALEPlots object — plot.ALEPlots","text":"Plot ALEPlots object.","code":""},{"path":"https://tripartio.github.io/ale/reference/plot.ALEPlots.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot method for ALEPlots object — plot.ALEPlots","text":"x object class ALEPlots. max_print integer(1). maximum number plots may printed time. 1D plots 2D printed separate pages, maximum applies separately dimension ALE plots, dimensions combined. ... Arguments pass patchwork::wrap_plots()","code":""},{"path":"https://tripartio.github.io/ale/reference/plot.ALEPlots.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot method for ALEPlots object — plot.ALEPlots","text":"Invisibly returns x.","code":""},{"path":"https://tripartio.github.io/ale/reference/plot.ModelBoot.html","id":null,"dir":"Reference","previous_headings":"","what":"plot method for ModelBoot objects — plot.ModelBoot","title":"plot method for ModelBoot objects — plot.ModelBoot","text":"plot method simply calls constructor ALEPlots object.","code":""},{"path":"https://tripartio.github.io/ale/reference/plot.ModelBoot.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"plot method for ModelBoot objects — plot.ModelBoot","text":"x ModelBoot object. ... Arguments passed ALEPlots()","code":""},{"path":"https://tripartio.github.io/ale/reference/plot.ale.html","id":null,"dir":"Reference","previous_headings":"","what":"plot method for ALE objects — plot.ALE","title":"plot method for ALE objects — plot.ALE","text":"plot method simply calls constructor ALEPlots object.","code":""},{"path":"https://tripartio.github.io/ale/reference/plot.ale.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"plot method for ALE objects — plot.ALE","text":"x ALE object. ... Arguments passed ALEPlots()","code":""},{"path":"https://tripartio.github.io/ale/reference/print.ALEPlots.html","id":null,"dir":"Reference","previous_headings":"","what":"Print method for ALEPlots object — print.ALEPlots","title":"Print method for ALEPlots object — print.ALEPlots","text":"Print ALEPlots object calling plot().","code":""},{"path":"https://tripartio.github.io/ale/reference/print.ALEPlots.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print method for ALEPlots object — print.ALEPlots","text":"x object class ALEPlots. max_print See documentation plot.ALEPlots() ... Additional arguments (currently used).","code":""},{"path":"https://tripartio.github.io/ale/reference/print.ALEPlots.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Print method for ALEPlots object — print.ALEPlots","text":"Invisibly returns x.","code":""},{"path":"https://tripartio.github.io/ale/reference/print.ModelBoot.html","id":null,"dir":"Reference","previous_headings":"","what":"print method for ModelBoot object — print.ModelBoot","title":"print method for ModelBoot object — print.ModelBoot","text":"Print ModelBoot object.","code":""},{"path":"https://tripartio.github.io/ale/reference/print.ModelBoot.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"print method for ModelBoot object — print.ModelBoot","text":"x object class ModelBoot. ... Additional arguments (currently used).","code":""},{"path":"https://tripartio.github.io/ale/reference/print.ModelBoot.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"print method for ModelBoot object — print.ModelBoot","text":"Invisibly returns x.","code":""},{"path":"https://tripartio.github.io/ale/reference/print.ModelBoot.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"print method for ModelBoot object — print.ModelBoot","text":"","code":"# \\donttest{ lm_cars <- stats::lm(mpg ~ wt + gear, mtcars) mb <- ModelBoot(lm_cars, boot_it = 2, ale_p = NULL) print(mb) #> <ModelBoot> object of a <lm> model that predicts `mpg` (a numeric outcome) from #> a 32-row by 3-column dataset. #> * The model was retrained with 2 bootstrap iterations. #>  #> The following overall model summary statistics are available: #> * Overall average statistics: r.squared, adj.r.squared, sigma, statistic, #> p.value, df, df.residual, and nobs #> * Bootstrap-validated model accuracy: mae, sa_mae, rmse, and sa_rmse #> Statistics for the following specific variables or interactions are available: #> (Intercept), wt, and gear #>  #> Accumulated local effects (ALE) data and statistics are provided for the #> following terms: #> 2 1D terms: wt and gear #> no 2D terms: # }"},{"path":"https://tripartio.github.io/ale/reference/print.ale.html","id":null,"dir":"Reference","previous_headings":"","what":"print Method for ALE object — print.ALE","title":"print Method for ALE object — print.ALE","text":"Print ALE object.","code":""},{"path":"https://tripartio.github.io/ale/reference/print.ale.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"print Method for ALE object — print.ALE","text":"x object class ALE. ... Additional arguments (currently used).","code":""},{"path":"https://tripartio.github.io/ale/reference/print.ale.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"print Method for ALE object — print.ALE","text":"Invisibly returns x.","code":""},{"path":"https://tripartio.github.io/ale/reference/print.ale.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"print Method for ALE object — print.ALE","text":"","code":"# \\donttest{ lm_cars <- stats::lm(mpg ~ ., mtcars) ale_cars <- ALE(lm_cars, p_values = NULL) print(ale_cars) #> <ALE> object of a <lm> model that predicts `mpg` (a numeric outcome) from a #> 32-row by 11-column dataset. #> ALE data and statistics are provided for the following terms: #> 10 1D terms: cyl, disp, hp, drat, wt, qsec, vs, am, gear, and carb #> no 2D terms: #> The results were not bootstrapped. # }"},{"path":"https://tripartio.github.io/ale/reference/resolve_x_cols.html","id":null,"dir":"Reference","previous_headings":"","what":"Resolve x_cols and exclude_cols to their standardized format — resolve_x_cols","title":"Resolve x_cols and exclude_cols to their standardized format — resolve_x_cols","text":"Resolve x_cols exclude_cols standardized format x_cols specify 1D 2D ALE elements required. specification used throughout ALE package. x_cols specifies desired columns interactions whereas exclude_cols optionally specifies columns interactions remove x_cols. result x_cols – exclude_cols, giving considerable flexibility specifying precise columns desired.","code":""},{"path":"https://tripartio.github.io/ale/reference/resolve_x_cols.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Resolve x_cols and exclude_cols to their standardized format — resolve_x_cols","text":"","code":"resolve_x_cols(x_cols, col_names, y_col, exclude_cols = NULL, silent = FALSE)"},{"path":"https://tripartio.github.io/ale/reference/resolve_x_cols.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Resolve x_cols and exclude_cols to their standardized format — resolve_x_cols","text":"x_cols character, list, formula. Columns interactions requested one special x_cols formats. x_cols variable names found col_names error. See examples. col_names character. column names dataset. values x_cols must contained among values col_names. interaction terms x_cols, e.g., \":b\", individual variable names must contained col_names, e.g, c(\"\", \"b\"). y_col character(1). y outcome column. found x_cols value, silently removed. exclude_cols possible formats x_cols. Columns interactions exclude requested x_cols. exclude_cols values found col_names ignored message (can silenced silent). silent logical(1). TRUE, message given; particular, x_cols found col_names silently ignored. Default FALSE. Regardless, warnings errors never silenced (e.g, invalid x_cols formats still report errors).","code":""},{"path":"https://tripartio.github.io/ale/reference/resolve_x_cols.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Resolve x_cols and exclude_cols to their standardized format — resolve_x_cols","text":"x_cols canonical format, always list two elements, d1 d2. element character vector requested column 1D ALE (d1) 2D ALE interaction pair (d2). either dimension empty, value empty character, character(). See examples details.","code":""},{"path":"https://tripartio.github.io/ale/reference/resolve_x_cols.html","id":"x-cols-format-options","dir":"Reference","previous_headings":"","what":"x_cols format options","title":"Resolve x_cols and exclude_cols to their standardized format — resolve_x_cols","text":"x_cols argument determines predictor variables interactions included analysis. supports multiple input formats: Character vector: Users can explicitly specify 1D terms 2D ALE interactions, e.g., c(\"\", \"b\", \":b\", \":c\"). Formula (~): Allows specifying variables interactions formula notation (e.g., ~ + b + :b), automatically converted structured format. outcome term optional ignored regardless. , ~ + b + :b produces results identical whatever ~ + b + :b. List format: basic list format list character vectors named d1 1D ALE terms, d2 2D interactions, . example, list(d1 = c(\"\", \"b\"), d2 = c(\":b\", \":c\")) Boolean selection entire dimension: list(d1 = TRUE) selects available variables 1D ALE, excluding y_col. list(d2 = TRUE) selects possible 2D interactions among columns col_names, excluding y_col. character vector 1D terms named d2_all may used include 2D interactions include specified 1D terms. example, specifying list(d2_all = \"\") select c(\":b\", \":c\", \":d\"), etc. addition terms requested d1 d2 elements. NULL (unspecified): x_cols = NULL, variables selected. function ensures variables valid col_names, providing informative messages unless silent = TRUE. regardless specification format, result always standardized format specified return value. Note y_col removed included x_cols. However, message alerts included, case mistake. Run examples details.","code":""},{"path":"https://tripartio.github.io/ale/reference/resolve_x_cols.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Resolve x_cols and exclude_cols to their standardized format — resolve_x_cols","text":"","code":"## Sample data set.seed(0) df <- data.frame(   y = runif(10),   a = sample(letters[1:3], 10, replace = TRUE),   b = rnorm(10),   c = sample(1:5, 10, replace = TRUE) ) col_names <- names(df) y_col <- \"y\"  # Assume 'y' is the outcome variable   ## Examples with just x_cols to show different formats for specifying x_cols ## (same format for exclude_cols)  # Character vector: Simple ALE with no interactions resolve_x_cols(c(\"a\", \"b\"), col_names, y_col) #> $d1 #> [1] \"a\" \"b\" #>  #> $d2 #> character(0) #>   # Character string: Select just one 1D element resolve_x_cols(\"c\", col_names, y_col) #> $d1 #> [1] \"c\" #>  #> $d2 #> character(0) #>   # list of 1- and 2-length character vectors: specify precise 1D and 2D elements desired resolve_x_cols(c('a:b', \"c\", 'c:a', \"b\"), col_names, y_col) #> $d1 #> [1] \"c\" \"b\" #>  #> $d2 #> [1] \"a:b\" \"c:a\" #>   # Formula: Converts to a list of individual elements resolve_x_cols(~ a + b, col_names, y_col) #> $d1 #> [1] \"a\" \"b\" #>  #> $d2 #> character(0) #>   # Formula with interactions (1D and 2D). # This format is probably more convenient if you know precisely which terms you want. # Note that the outcome on the left-hand-side is always silently ignored. resolve_x_cols(whatever ~ a + b + a:b + c:b, col_names, y_col) #> $d1 #> [1] \"a\" \"b\" #>  #> $d2 #> [1] \"a:b\" \"b:c\" #>   # List specifying d1 (1D ALE) resolve_x_cols(list(d1 = c(\"a\", \"b\")), col_names, y_col) #> $d1 #> [1] \"a\" \"b\" #>  #> $d2 #> character(0) #>   # List specifying d2 (2D ALE) resolve_x_cols(list(d2 = 'a:b'), col_names, y_col) #> $d1 #> character(0) #>  #> $d2 #> [1] \"a:b\" #>   # List specifying both d1 and d2 resolve_x_cols(list(d1 = c(\"a\", \"b\"), d2 = 'a:b'), col_names, y_col) #> $d1 #> [1] \"a\" \"b\" #>  #> $d2 #> [1] \"a:b\" #>   # d1 as TRUE (select all columns except y_col) resolve_x_cols(list(d1 = TRUE), col_names, y_col) #> $d1 #> [1] \"a\" \"b\" \"c\" #>  #> $d2 #> character(0) #>   # d2 as TRUE (select all possible 2D interactions) resolve_x_cols(list(d2 = TRUE), col_names, y_col) #> $d1 #> character(0) #>  #> $d2 #> [1] \"a:b\" \"a:c\" \"b:c\" #>   # d2_all: Request all 2D interactions involving a specific variable resolve_x_cols(list(d2_all = \"a\"), col_names, y_col) #> $d1 #> character(0) #>  #> $d2 #> [1] \"a:b\" \"a:c\" #>   # NULL: No variables selected resolve_x_cols(NULL, col_names, y_col) #> $d1 #> character(0) #>  #> $d2 #> character(0) #>     ## Examples of how exclude_cols are removed from x_cols to obtain various desired results  # Exclude one column from a simple character vector resolve_x_cols(   x_cols = c(\"a\", \"b\", \"c\"),   col_names = col_names,   y_col = y_col,   exclude_cols = \"b\" ) #> $d1 #> [1] \"a\" \"c\" #>  #> $d2 #> character(0) #>   # Exclude multiple columns resolve_x_cols(   x_cols = c(\"a\", \"b\", \"c\"),   col_names = col_names,   y_col = y_col,   exclude_cols = c(\"a\", \"c\") ) #> $d1 #> [1] \"b\" #>  #> $d2 #> character(0) #>   # Exclude an interaction term from a formula input resolve_x_cols(   x_cols = ~ a + b + a:b,   col_names = col_names,   y_col = y_col,   exclude_cols = ~ a:b ) #> $d1 #> [1] \"a\" \"b\" #>  #> $d2 #> character(0) #>   # Exclude all columns from x_cols resolve_x_cols(   x_cols = c(\"a\", \"b\", \"c\"),   col_names = col_names,   y_col = y_col,   exclude_cols = c(\"a\", \"b\", \"c\") ) #> $d1 #> character(0) #>  #> $d2 #> character(0) #>   # Exclude non-existent columns (should be ignored) resolve_x_cols(   x_cols = c(\"a\", \"b\"),   col_names = col_names,   y_col = y_col,   exclude_cols = \"z\" ) #> ℹ The following columns in exclude_cols were not found in `col_names`: z #> $d1 #> [1] \"a\" \"b\" #>  #> $d2 #> character(0) #>   # Exclude one column from a list-based input resolve_x_cols(   x_cols = list(d1 = c(\"a\", \"b\"), d2 = c(\"a:b\", \"a:c\")),   col_names = col_names,   y_col = y_col,   exclude_cols = list(d1 = \"a\") ) #> $d1 #> [1] \"b\" #>  #> $d2 #> [1] \"a:b\" \"a:c\" #>   # Exclude interactions only resolve_x_cols(   x_cols = list(d1 = c(\"a\", \"b\", \"c\"), d2 = c(\"a:b\", \"a:c\")),   col_names = col_names,   y_col = y_col,   exclude_cols = list(d2 = 'a:b') ) #> $d1 #> [1] \"a\" \"b\" \"c\" #>  #> $d2 #> [1] \"a:c\" #>   # Exclude everything, including interactions resolve_x_cols(   x_cols = list(d1 = c(\"a\", \"b\", \"c\"), d2 = c(\"a:b\", \"a:c\")),   col_names = col_names,   y_col = y_col,   exclude_cols = list(d1 = c(\"a\", \"b\", \"c\"), d2 = c(\"a:b\", \"a:c\")) ) #> $d1 #> character(0) #>  #> $d2 #> character(0) #>   # Exclude a column implicitly removed by y_col resolve_x_cols(   x_cols = c(\"y\", \"a\", \"b\"),   col_names = col_names,   y_col = \"y\",   exclude_cols = \"a\" ) #> ℹ `y_col` (y) was requested in x_cols. #> $d1 #> [1] \"y\" \"b\" #>  #> $d2 #> character(0) #>   # Exclude entire 2D dimension from x_cols with d2 = TRUE resolve_x_cols(   x_cols = list(d1 = TRUE, d2 = c(\"a:b\", \"a:c\")),   col_names = col_names,   y_col = y_col,   exclude_cols = list(d1 = c(\"a\"), d2 = TRUE) ) #> $d1 #> [1] \"b\" \"c\" #>  #> $d2 #> character(0) #>"},{"path":"https://tripartio.github.io/ale/reference/subset.ALEPlots.html","id":null,"dir":"Reference","previous_headings":"","what":"subset method for ALEPlots object — subset.ALEPlots","title":"subset method for ALEPlots object — subset.ALEPlots","text":"Subset ALEPlots object produce another ALEPlots object subsetted x_cols variables interactions, specified return value description. See get.ALE() explanation parameters described .","code":""},{"path":"https://tripartio.github.io/ale/reference/subset.ALEPlots.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"subset method for ALEPlots object — subset.ALEPlots","text":"x object class ALEPlots. ... used. Inserted require explicit naming subsequent arguments. include_eff logical(1). x_cols exclude_cols specify precisely variables include exclude subset. However, multivariable plots like ALE effects plot ambiguous subsetted remove existing variables. include_eff = TRUE (default) includes ALE effects plot subset rather dropping , available.","code":""},{"path":"https://tripartio.github.io/ale/reference/subset.ALEPlots.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"subset method for ALEPlots object — subset.ALEPlots","text":"ALEPlots object reduced cover variables interactions specified x_cols exclude_cols. different get.ALEPlots(), returns list ggplot objects loses special ALEPlots behaviour like plotting, printing, summarizing multiple plots.","code":""},{"path":"https://tripartio.github.io/ale/reference/summary.ALEPlots.html","id":null,"dir":"Reference","previous_headings":"","what":"summary method for ALEPlots object — summary.ALEPlots","title":"summary method for ALEPlots object — summary.ALEPlots","text":"Present concise summary information ALEPlots object.","code":""},{"path":"https://tripartio.github.io/ale/reference/summary.ALEPlots.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"summary method for ALEPlots object — summary.ALEPlots","text":"object object class ALEPlots. ... used","code":""},{"path":"https://tripartio.github.io/ale/reference/summary.ALEPlots.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"summary method for ALEPlots object — summary.ALEPlots","text":"Summary string.","code":""},{"path":"https://tripartio.github.io/ale/reference/var_cars.html","id":null,"dir":"Reference","previous_headings":"","what":"Multi-variable transformation of the mtcars dataset. — var_cars","title":"Multi-variable transformation of the mtcars dataset. — var_cars","text":"transformation mtcars dataset R produce small dataset fundamental datatypes: logical, factor, ordered, integer, double, character. transformations obvious, noteworthy: row names (car model) saved character vector. unordered factors, country continent car manufacturer obtained based row names (model). ordered factor, gears 3, 4, 5 encoded 'three', 'four', 'five', respectively. text labels make explicit variable ordinal, yet number names make order crystal clear. adaptation original description mtcars dataset: data extracted 1974 Motor Trend US magazine, comprises fuel consumption 10 aspects automobile design performance 32 automobiles (1973–74 models).","code":""},{"path":"https://tripartio.github.io/ale/reference/var_cars.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Multi-variable transformation of the mtcars dataset. — var_cars","text":"","code":"var_cars"},{"path":"https://tripartio.github.io/ale/reference/var_cars.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Multi-variable transformation of the mtcars dataset. — var_cars","text":"tibble 32 observations 14 variables. model character: Car model mpg double: Miles/(US) gallon cyl integer: Number cylinders disp double: Displacement (cu..) hp double: Gross horsepower drat double: Rear axle ratio wt double: Weight (1000 lbs) qsec double: 1/4 mile time vs logical: Engine (0 = V-shaped, 1 = straight) logical: Transmission (0 = automatic, 1 = manual) gear ordered: Number forward gears carb integer: Number carburetors country factor: Country car manufacturer continent factor: Continent car manufacturer","code":""},{"path":"https://tripartio.github.io/ale/reference/var_cars.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Multi-variable transformation of the mtcars dataset. — var_cars","text":"Henderson Velleman (1981) comment footnote Table 1: 'Hocking (original transcriber)'s noncrucial coding Mazda's rotary engine straight six-cylinder engine Porsche's flat engine V engine, well inclusion diesel Mercedes 240D, retained enable direct comparisons made previous analyses.'","code":""},{"path":"https://tripartio.github.io/ale/reference/var_cars.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Multi-variable transformation of the mtcars dataset. — var_cars","text":"Henderson Velleman (1981), Building multiple regression models interactively. Biometrics, 37, 391–411.","code":""},{"path":[]},{"path":"https://tripartio.github.io/ale/news/index.html","id":"new-features-0-5-1","dir":"Changelog","previous_headings":"","what":"New features","title":"ale 0.5.1","text":"Customize ALEPlots appending ggplot layers [customize()] function. Function [invert_probs()] inverts probabilities (subtracts 1) ALE ALEpDist objects.","code":""},{"path":"https://tripartio.github.io/ale/news/index.html","id":"bug-fixes-0-5-1","dir":"Changelog","previous_headings":"","what":"Bug fixes","title":"ale 0.5.1","text":"ALEPlot package delisted CRAN, replace internal copy refALEPlot(). Allow numeric binary predictions. Formerly, binary predictions errored, even numeric. Larger datasets now properly sample. datasets > 500 lines, code mismatch size original dataset sampled dataset.","code":""},{"path":"https://tripartio.github.io/ale/news/index.html","id":"ale-050","dir":"Changelog","previous_headings":"","what":"ale 0.5.0","title":"ale 0.5.0","text":"CRAN release: 2025-04-09 deeply rethought vision package completely rewritten entire package support existing, new, future planned functionality. changes radical continuity previous version 0.3.1. Thus, ’ve skipped version number now version 0.5.0. Honestly, can’t keep track changes; experienced users advised rerun vignettes get speed new version. apologize discontinuity trust latest version easier use much functional. follows list notable changes ’ve kept track .","code":""},{"path":"https://tripartio.github.io/ale/news/index.html","id":"breaking-changes-0-5-0","dir":"Changelog","previous_headings":"","what":"Breaking changes","title":"ale 0.5.0","text":"underlying algorithm calculating ALE completely rewritten scalable. addition rewriting code hood, structure ale package objects completely rewritten. latest objects compatible earlier versions. However, new structure supports roadmap future functionality, hope minimal changes future interrupt backward compatibility. ALE: core ale package object holds ALE data model (replaces former ale() ale_ixn() functions). ModelBoot: results full-model bootstrapping (replaces former model_bootstrap() function). ALEPlots: store ALE plots generated either ALE ModelBoot convenient print() plot() methods. ALEpDist: p-value distribution information (replaces former create_p_dist() function). extensive rewrite, longer depend {ALEPlot} package code now claim full authorship code. One significant implications decided change package license GPL 2 MIT, permits maximum dissemination algorithms. ale_ixn() eliminated now 1D 2D ALE calculated ALE() constructor . ALE object constructor longer produces plots directly. ALE plots now created ale_plot objects using newly added plot() methods create possible plots ALE data ALE ale_boot objects. Thus, serializing ALE objects now avoids previous problems environment bloat included ggplot objects. Renamed rug_sample_size argument ALE constructor sample_size. Now reflects size data sampled ale object, can used rug plots purposes.","code":""},{"path":"https://tripartio.github.io/ale/news/index.html","id":"bug-fixes-0-5-0","dir":"Changelog","previous_headings":"","what":"Bug fixes","title":"ale 0.5.0","text":"dealt innumerable bugs development journey , fortunately, publicly signalled bugs. fixes publicly reported bugs indicated . Gracefully fails instead crashing input data missing values.","code":""},{"path":"https://tripartio.github.io/ale/news/index.html","id":"other-user-visible-changes-0-5-0","dir":"Changelog","previous_headings":"","what":"Other user-visible changes","title":"ale 0.5.0","text":"x_cols argument ALE() now supports complex syntax specifying specific columns 1D ALE pairs columns 2D interactions desired. also supports specification using standard R formula syntax. New get() methods now provide convenient access ALE, ModelBoot, ALEPlots objects. Confidence regions 1D ALE now reported compactly. creation plot() methods, eliminated compact_plots ale(). print() plot() methods added ale_plots object. print() method added ALE object. Interactions now supported pairs categorical variables. (, numerical pairs pairs one numerical one categorical supported.) Bootstrapping now supported ALE interactions. 2D ALE plots completely rewritten. still implemented tiled heatmaps now faceted bootstrap quantile ALE bootstrapped. ALE statistics now supported interactions, including confidence regions. Categorical y outcomes now supported. categorical y outcomes, plots created one category time also categories combined. 1D ALE, separate plots available categories overlaid one plot categories faceted. 2D ALE, plots faceted category available. ‘boot_data’ now output option ale(). outputs ALE values bootstrap iteration. model_bootstrap() added various model performance measures validated using bootstrap validation .632 correction. structure p_funs completely changed; now converted object named ale_p functions separated object internal functions. function create_p_funs() renamed create_p_dist(). ALEpDist() now produces three types p-values: “exact” (slow) least 1000 random iterations original model; “approx” 100 999 iterations original model; “surrogate” much faster less reliable p-values based surrogate linear model. See ALEpDist() details. Character input data now accepted categorical datatype. handled unordered factors. Plots display categorical outcomes one plot yet implemented. now, class category must plotted time. Although standard {ALE} class supports 2D ALE interactions ALE bootstrapping, {ModelBoot} yet support full-model bootstrapping 2D ALE interactions.","code":""},{"path":"https://tripartio.github.io/ale/news/index.html","id":"under-the-hood-0-5-0","dir":"Changelog","previous_headings":"","what":"Under the hood","title":"ale 0.5.0","text":"One fundamental changes directly visible affects ALE values calculated. certain specific cases, ALE values now slightly different reference {ALEPlot} package. non-numerical variables prediction types predictions scaled response variable. (E.g., binary categorical variable logarithmic prediction scaled scale response variable.) made change two reasons: can understand implementation interpretation edge cases much better reference {ALEPlot} implementation. cases covered base ALE scientific article poorly documented {ALEPlot} code. help users interpret results understand . implementation lets us write code scales smoothly interactions arbitrary depth. contrast, {ALEPlot} reference implementation scalable: custom code must written type degree interaction. edge cases, implementation continues give identical results reference {ALEPlot} package. notable changes might readily visible users: Update required R version >= 4.2.0 uses |> pipe placeholder. Move performance metrics new dedicated package, staccuracy. Reduce dependencies rlang cli packages. Reduced imported functions minimum. Package messages, warnings, errors now use cli. Replace {assertthat} custom validation functions adapt {assertthat} code. Use helper.R test files testing objects available loaded package. Configure future parallelization code restore original values exit. Configure code uses random seed restore original system seed exit. Improve memory efficiency ale_p objects. Update plotting code compatibility ggplot2 3.5. Add testing code coverage covr.","code":""},{"path":"https://tripartio.github.io/ale/news/index.html","id":"known-issues-to-be-addressed-in-a-future-version-0-5-0","dir":"Changelog","previous_headings":"","what":"Known issues to be addressed in a future version","title":"ale 0.5.0","text":"Effects plots interactions yet implemented.","code":""},{"path":"https://tripartio.github.io/ale/news/index.html","id":"ale-030","dir":"Changelog","previous_headings":"","what":"ale 0.3.0","title":"ale 0.3.0","text":"CRAN release: 2024-02-13 significant updates addition p-values ALE statistics, launching pkgdown website henceforth host development version package, parallelization core functions resulting performance boost.","code":""},{"path":"https://tripartio.github.io/ale/news/index.html","id":"breaking-changes-0-3-0","dir":"Changelog","previous_headings":"","what":"Breaking changes","title":"ale 0.3.0","text":"One key goals ale package truly model-agnostic: support R object can considered model, model defined object makes prediction input row data provided. Towards goal, adjust custom predict function make flexible various kinds model objects. happy changes now enable support tidymodels objects various survival models (now, return single-vector predictions). , addition taking required object newdata arguments, custom predict function pred_fun ale() function now also requires argument type specify prediction type, whether used . change breaks previous code used custom predict functions, allows ale analyze many new model types . Code require custom predict functions affected change. See updated documentation ale() function details. Another change breaks former code arguments model_bootstrap() modified. Instead cumbersome model_call_string, model_bootstrap() now uses insight package automatically detect many R models directly manipulate model object needed. , second argument now model object. However, non-standard models insight automatically parse, modified model_call_string still available assure model-agnostic functionality. Although change breaks former code ran model_bootstrap(), believe new function interface much user-friendly. slight change might break existing code conf_regions output associated ALE statistics restructured. new structure provides useful information. See help(ale) details.","code":""},{"path":"https://tripartio.github.io/ale/news/index.html","id":"other-user-visible-changes-0-3-0","dir":"Changelog","previous_headings":"","what":"Other user-visible changes","title":"ale 0.3.0","text":"package now uses pkgdown website located https://tripartio.github.io/ale/. recent development features documented. P-values now provided ALE statistics. However, calculation slow, disabled default; must explicitly requested. requested, automatically calculated possible (standard R model types); , additional steps must taken calculation. See new create_p_funs() function details example. normalization formula ALE statistics changed minor differences median normalized zero. adjustment, former normalization formula give tiny differences apparently large normalized effects. See updated documentation vignette('ale-statistics') details. vignette expanded details properly interpret normalized ALE statistics. Normalized ALE range (NALER) now expressed percentile points relative median (ranging -50% +50%) rather original formulation absolute percentiles (ranging 0 100%). See updated documentation vignette('ale-statistics') details. Performance dramatically improved addition parallelization default. use furrr library. tests, practically, typically found speed-ups n – 2 n number physical cores (machine learning generally unable use logical cores). example, computer 4 physical cores see least ×2 speed-computer 6 physical cores see least ×4 speed-. However, parallelization tricky model-agnostic design. users work models follow standard R conventions, ale package able automatically configure system parallelization. non-standard models users may explicitly list model’s packages new model_packages argument parallel thread can find necessary functions. concern get weird errors. See help(ale) details. Fully documented output ale() function. See help(ale) details. median_band_pct argument ale() now takes vector two numbers, one inner band one outer. Switched recommendation calculating ALE data test data instead calculate full dataset final deployment model. Replaced {gridExtra} patchwork examples vignettes printing plots. Separated ale() function documentation ale-package documentation. p-values provided, ALE effects plot now shows NALED band instead median band. alt tags describe plots accessibility. accurate rug plots ALE interaction plots. Various minor tweaks plots.","code":""},{"path":"https://tripartio.github.io/ale/news/index.html","id":"under-the-hood-0-3-0","dir":"Changelog","previous_headings":"","what":"Under the hood","title":"ale 0.3.0","text":"Uses insight package automatically detect y_col model call objects possible; increases range automatic model detection ale package general. switched using progressr package progress bars. cli progression handler, enables accurate estimated times arrival (ETA) long procedures, even parallel computing. message displayed per session informing users customize progress bars. details, see help(ale), particularly documentation progress bars silent argument. Moved ggplot2 dependency import. , longer automatically loaded package. detailed information internal var_summary() function. particular, encodes whether user using p-values (ALER band) (median band). Separated validation functions reused across functions internal validation.R file. Added argument compact_plots plotting functions strip plot environments reduce size returned objects. See help(ale) details. Created package_scope environment. Many minor bug fixes improvements. Improved validation problematic inputs informative error messages. Various minor performance boosts profiling refactoring code.","code":""},{"path":"https://tripartio.github.io/ale/news/index.html","id":"known-issues-to-be-addressed-in-a-future-version-0-3-0","dir":"Changelog","previous_headings":"","what":"Known issues to be addressed in a future version","title":"ale 0.3.0","text":"Bootstrapping yet supported ALE interactions (ale_ixn()). ALE statistics yet supported ALE interactions (ale_ixn()). ale() yet support multi-output model prediction types (e.g., multi-class classification multi-time survival probabilities).","code":""},{"path":"https://tripartio.github.io/ale/news/index.html","id":"ale-020","dir":"Changelog","previous_headings":"","what":"ale 0.2.0","title":"ale 0.2.0","text":"CRAN release: 2023-10-19 version introduces various ALE-based statistics let ALE used statistical inference, just interpretable machine learning. dedicated vignette introduces functionality (see “ALE-based statistics statistical inference effect sizes” vignettes link main CRAN page https://CRAN.R-project.org/package=ale). introduce statistics detail working paper: Okoli, Chitu. 2023. “Statistical Inference Using Machine Learning Classical Techniques Based Accumulated Local Effects (ALE).” arXiv. https://doi.org/10.48550/arXiv.2310.09877. Please note might refined peer review.","code":""},{"path":"https://tripartio.github.io/ale/news/index.html","id":"breaking-changes-0-2-0","dir":"Changelog","previous_headings":"","what":"Breaking changes","title":"ale 0.2.0","text":"changed output data structure ALE data plots. necessary add ALE statistics. Unfortunately, change breaks code refers objects created initial 0.1.0 version, especially code printing plots. However, felt necessary new structure makes coding workflows much easier. See vignettes examples code examples print plots using new structure.","code":""},{"path":"https://tripartio.github.io/ale/news/index.html","id":"other-user-visible-changes-0-2-0","dir":"Changelog","previous_headings":"","what":"Other user-visible changes","title":"ale 0.2.0","text":"added new ALE-based statistics: ALED ALER normalized versions NALED NALER. ale() model_bootstrap() now output statistics. (ale_ixn() come later.) added rug plots numeric values percentage frequencies plots categories. indicators give quick visual indication distribution plotted data. added vignette introduces ALE-based statistics, especially effect size measures, demonstrates use statistical inference: “ALE-based statistics statistical inference effect sizes” (available vignettes link main CRAN page https://CRAN.R-project.org/package=ale). added vignette compares ale package reference {ALEPlot} package: “Comparison {ALEPlot} ale packages” (available vignettes link main CRAN page https://CRAN.R-project.org/package=ale). var_cars modified version mtcars features many different types variables. census polished version adult income dataset used vignette {ALEPlot} package. Progress bars show progression analysis. can disabled passing silent = TRUE ale(), ale_ixn(), model_bootstrap(). user can specify random seed passing seed argument ale(), ale_ixn(), model_bootstrap().","code":""},{"path":"https://tripartio.github.io/ale/news/index.html","id":"under-the-hood-0-2-0","dir":"Changelog","previous_headings":"","what":"Under the hood","title":"ale 0.2.0","text":"far extensive changes assure accuracy stability package software engineering perspective. Even though visible users, make package robust hopefully fewer bugs. Indeed, extensive data validation may help users debug errors. Added data validation exported functions. hood, user-facing function carefully validates user entered valid data using {assertthat} package; , function fails quickly appropriate error message. Created unit tests exported functions. hood, testthat package now used testing outputs user-facing function. help code base robust going forward future developments. importantly, created tests compare results original reference {ALEPlot} package. tests ensure future code breaks accuracy ALE calculations caught quickly. Bootstrapped ALE values now centred mean default, instead median. Mean averaging generally stable, especially smaller datasets. code base extensively reorganized efficient development moving forward. Numerous bugs fixed following internal usage testing.","code":""},{"path":"https://tripartio.github.io/ale/news/index.html","id":"known-issues-to-be-addressed-in-a-future-version-0-2-0","dir":"Changelog","previous_headings":"","what":"Known issues to be addressed in a future version","title":"ale 0.2.0","text":"Bootstrapping yet supported ALE interactions (ale_ixn()). ALE statistics yet supported ALE interactions (ale_ixn()).","code":""},{"path":"https://tripartio.github.io/ale/news/index.html","id":"ale-010","dir":"Changelog","previous_headings":"","what":"ale 0.1.0","title":"ale 0.1.0","text":"CRAN release: 2023-08-29 first CRAN release ale package. official description initial release: Accumulated Local Effects (ALE) initially developed model-agnostic approach global explanations results black-box machine learning algorithms. (Apley, Daniel W., Jingyu Zhu. “Visualizing effects predictor variables black box supervised learning models.” Journal Royal Statistical Society Series B: Statistical Methodology 82.4 (2020): 1059-1086 doi:10.1111/rssb.12377.) ALE two primary advantages approaches like partial dependency plots (PDP) SHapley Additive exPlanations (SHAP): values affected presence interactions among variables model computation relatively rapid. package rewrites original code ‘ALEPlot’ package calculating ALE data completely reimplements plotting ALE values. (package uses GPL-2 license {ALEPlot} package.) initial release replicates full functionality {ALEPlot} package lot . currently presents three functions: ale(): create data plot one-way ALE (single variables). ALE values may bootstrapped. ale_ixn(): create data plot two-way ALE interactions. Bootstrapping interaction ALE values yet implemented. model_bootstrap(): bootstrap entire model, just ALE values. function returns bootstrapped model statistics coefficients well bootstrapped ALE values. appropriate approach small samples. release provides details following vignettes (available vignettes link main CRAN page https://CRAN.R-project.org/package=ale): Introduction ale package Analyzing small datasets (fewer 2000 rows) ALE ale() function handling various datatypes x","code":""}]
