[{"path":"https://tripartio.github.io/ale/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2024 ale authors Permission hereby granted, free charge, person obtaining copy software associated documentation files (“Software”), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED “”, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":"https://tripartio.github.io/ale/articles/ale-acdc-corn.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Analyzing a Large Corn Yield Dataset with ALE-Based Inference","text":"article, analyze Agro-Climatic Data County (ACDC) dataset (Yun & Gramig 2017, licensed CC-), county-level panel 48 contiguous U.S. states spanning 1981–2015, designed agricultural production climate research. combines crop yields key agro-climatic drivers, notably growing season degree days, total precipitation, major soil characteristics, preprocessed focus agricultural production areas. focus predicting county-level corn yield per year (measured bushels per acre) interpreting factors contribute prediction. dataset’s structure matches standard agro-climatic production framing, output depends temperature, precipitation, soils, controls.","code":""},{"path":"https://tripartio.github.io/ale/articles/ale-acdc-corn.html","id":"setup-r-environment","dir":"Articles","previous_headings":"","what":"Setup R environment","title":"Analyzing a Large Corn Yield Dataset with ALE-Based Inference","text":"begin loading packages used throughout analysis. installed locally, next step install running rest document. Note {ale} package CRAN, features used install current development version GitHub (code shows , via {pak}).","code":"library(dplyr)  # data manipulation library(purrr)  # functional programming library(ranger)  # random forests library(tictoc)  # performance timing library(staccuracy)  # performance metrics library(rsample)  # cross-validation  # Other packages accessed with :: direct access but not loaded (install them if needed): # * stringr: string processing # * readr: input CSV files # * tidyr: data manipulation # * cli: command line interface printing  # Accumulated Local Effects: ale package # Install the development version of ale for this workshop, which is more recent than the current CRAN version. # If needed, first install the pak package manager to easily install a GitHub package: # install.packages('pak') # pak::pak('tripartio/ale') library(ale)  # load the ale package only after installing the development version # For speed, these examples use retrieve_rds() to load precreated objects  # from an online repository. # To run the code yourself, execute the code blocks directly.   serialized_objects_site <- \"https://github.com/tripartio/ale/raw/main/download/corn_objects\""},{"path":"https://tripartio.github.io/ale/articles/ale-acdc-corn.html","id":"dataset-acdc-corn-yields","dir":"Articles","previous_headings":"","what":"Dataset: ACDC corn yields","title":"Analyzing a Large Corn Yield Dataset with ALE-Based Inference","text":"work Agro-Climatic Data County (ACDC), 1981–2015 (Yun & Gramig 2017). Rather reproducing full compilation code , summarize key transformations used assemble analysis-ready dataset. ACDC data arrive several components require harmonization. First, agricultural land area reported grids measured different years. normalize measures county-year level express agricultural land area square kilometres (ag_km2). Temperature involved transformation. ACDC stores temperatures counts days falling within one-degree Celsius bins (e.g., 2–3°C, 4–5°C, etc.). modelling, aggregate bins temperature ranges meaningful corn (maize) growth, creating variables count, county-year, many days fall within selected range. data description defines ranges notes agronomically relevant. defining “-season” windows, restrict attention months align typical crop calendars. table records windows used analysis (initially chosen based quick background guidance). Soil composition variables come county-level surveys conducted 1992, 2001, 2006, 2011. carry soil attributes forward county-year panel merge annual corn yield, measured bushels per acre (corn). U.S. dataset, report values bushels per acre provide metric conversion alongside . assembling dataset, inspect structure (e.g., glimpse()) verify variable types see sample rows. also compute summary statistics (min, max, mean, interquartile values) variable. variables used numeric; next section defines variable explicitly. outcome interest corn, corn yield (bushels per acre) given county given year. 90,010 rows data record one county one year. county-years recorded produced corn specified year. data encoded numeric except stco (factor) year (integer). soil variables come Gridded Soil Survey Geographic Database (gSSURGO). Full details can obtained manual provided Yun & Gramig (2017). stco: State-county code 3,070 counties continental United States. year: Year: 1981–2015 corn: corn yields bushels per acre (bu/ac) ag_km2: total agricultural land county km2, calculated data ACDC “gridInfo.csv” file temp_lt_00: growing season degree days (°C·days) temperature interval 0°C, constructed 1°C intervals −60°C +60°C temp_00_10: growing season degree days (°C·days) 0°C 10°C interval, aggregated 1°C bins temp_11_20: growing season degree days (°C·days) 11°C 20°C interval, aggregated 1°C bins temp_21_30: growing season degree days (°C·days) 21°C 30°C interval, aggregated 1°C bins temp_31_35: growing season degree days (°C·days) 31°C 35°C interval, aggregated 1°C bins temp_36_45: growing season degree days (°C·days) 36°C 45°C interval, aggregated 1°C bins temp_gt_45: growing season degree days (°C·days) temperature interval 45°C, aggregated 1°C bins ppt: total precipitation growing season (mm) whc: water holding capacity (cm/cm) (awc gSSURGO) sand: sand proportion (%) (sandtotal gSSURGO) silt: silt proportion (%) (silttotal gSSURGO) clay: clay proportion (%) (claytotal gSSURGO) om: organic matter 2 mm top soil (%) (om gSSURGO) kwfactor: soil erodibility factor water adjusted rock fragments (kwfact gSSURGO) kffactor: soil erodibility factor water (kffact gSSURGO) spH: soil pH (ph1to1h2o_r gSSURGO) slope: slope (m) (slopelenusle gSSURGO) tfactor: soil loss tolerance factor (tons/acre/yr) (tfact gSSURGO) target outcome variable, corn (maize), measured bushels corn per acre (bu/ac, American units), 1 bu/ac corn 62.8 kilograms per hectare (kg/ha) 1 kg/ha 0.016 bu/ac corn. dataset, mean 106 bu/ac mean absolute deviation (mad) 30.2 bu/ac. One consequential preprocessing choice exclude county identifier (stco) modelling dataset. raw data, county represented state-county code spanning 3,070 counties across 48 contiguous U.S. states. initially included county predictor, created substantial computational problems little benefit. GLM-style models, treating county factor 3,070 levels expands design matrix dramatically (thousands dummy variables) can make estimation impractically slow, sometimes requiring mixed-model machinery sparse-matrix handling. experiments, slowed GLM estimation orders magnitude without improving predictive performance. Random forests, contrast, performed essentially without county. clarity tractability, therefore omit county, given neither improved performance best-performing model justified computational cost GLM models.","code":"corn_data <- serialized_objects_site |>    file.path(\"corn_data.rds\") |>   url() |>    readRDS() corn_data |> glimpse() Rows: 90,010 Columns: 22 $ stco       <fct> 1001, 1003, 1005, 1009, 1011, 1013, 1015, 1019, 1021, 1023,… $ year       <int> 1981, 1981, 1981, 1981, 1981, 1981, 1981, 1981, 1981, 1981,… $ corn       <dbl> 17.3, 101.4, 37.9, 53.8, 22.1, 50.5, 46.6, 65.5, 31.8, 45.9… $ ag_km2     <dbl> 317.4507, 1000.1241, 429.0003, 447.9057, 266.2884, 187.1748… $ temp_lt_00 <dbl> 1.252724e-03, 1.334438e-04, 2.644859e-02, 5.219093e-01, 2.0… $ temp_00_10 <dbl> 9.108736, 5.825083, 9.556071, 16.302810, 10.703252, 9.11353… $ temp_11_20 <dbl> 42.16270, 37.20385, 42.41642, 46.73110, 43.30999, 41.31729,… $ temp_21_30 <dbl> 94.14356, 104.18624, 93.96831, 92.51842, 91.61782, 94.43539… $ temp_31_35 <dbl> 34.43768, 35.64974, 34.00982, 26.71666, 34.06262, 34.72649,… $ temp_36_45 <dbl> 4.14606767, 1.13495440, 4.02292888, 1.20910496, 4.28570742,… $ temp_gt_45 <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,… $ ppt        <dbl> 620.8656, 679.8329, 567.0682, 652.4704, 551.0441, 540.4134,… $ whc        <dbl> 24.78343, 23.53884, 21.48367, 18.28257, 22.58728, 24.71647,… $ sand       <dbl> 59.68140, 59.09199, 61.74435, 37.50056, 39.39067, 50.83622,… $ silt       <dbl> 20.04843, 21.80517, 16.41010, 33.40470, 25.92334, 21.17595,… $ clay       <dbl> 20.27016, 19.10284, 21.84554, 29.09474, 34.68599, 27.98784,… $ om         <dbl> 111.80678, 185.66755, 88.42968, 79.91542, 120.90292, 71.662… $ kwfactor   <dbl> 0.2230648, 0.2503898, 0.2123219, 0.2454282, 0.2304381, 0.21… $ kffactor   <dbl> 0.2263995, 0.2561335, 0.2123997, 0.2962476, 0.2328219, 0.21… $ spH        <dbl> 5.139626, 4.940044, 5.127343, 4.914515, 5.529810, 5.031030,… $ slope      <dbl> 51.03629, 106.22105, 65.98003, 32.14657, 46.05617, 63.86830… $ tfactor    <dbl> 4.950716, 4.936530, 4.926214, 3.174986, 4.988563, 4.889981,… corn_data |> summary() stco            year           corn           ag_km2  1049   :   45   Min.   :1981   Min.   :  0.0   Min.   :   0.4806  1077   :   45   1st Qu.:1988   1st Qu.: 80.0   1st Qu.: 316.7863  1079   :   45   Median :1993   Median :105.0   Median : 663.9057  1083   :   45   Mean   :1995   Mean   :106.0   Mean   : 767.3234  1089   :   45   3rd Qu.:2002   3rd Qu.:131.9   3rd Qu.:1076.1543  5021   :   45   Max.   :2015   Max.   :238.8   Max.   :5242.2723  (Other):89740    temp_lt_00       temp_00_10          temp_11_20        temp_21_30  Min.   : 0.000   Min.   : 0.000576   Min.   :  8.025   Min.   : 10.85  1st Qu.: 1.006   1st Qu.:19.224752   1st Qu.: 47.998   1st Qu.: 65.89  Median : 4.248   Median :29.188436   Median : 55.020   Median : 77.60  Mean   : 6.241   Mean   :27.847689   Mean   : 54.521   Mean   : 77.61  3rd Qu.: 9.698   3rd Qu.:37.250469   3rd Qu.: 62.071   3rd Qu.: 89.24  Max.   :52.734   Max.   :68.807006   Max.   :131.138   Max.   :128.56     temp_31_35       temp_36_45        temp_gt_45             ppt  Min.   : 0.000   Min.   : 0.0000   Min.   :0.0000000   Min.   :   0.9432  1st Qu.: 5.813   1st Qu.: 0.0000   1st Qu.:0.0000000   1st Qu.: 507.3542  Median :13.841   Median : 0.2692   Median :0.0000000   Median : 629.2561  Mean   :15.924   Mean   : 1.8541   Mean   :0.0007444   Mean   : 630.1739  3rd Qu.:23.581   3rd Qu.: 2.1338   3rd Qu.:0.0000000   3rd Qu.: 756.9606  Max.   :69.766   Max.   :63.5800   Max.   :2.6532670   Max.   :1601.6897        whc              sand             silt            clay  Min.   : 9.696   Min.   : 4.212   Min.   : 2.63   Min.   : 1.174  1st Qu.:20.826   1st Qu.:17.634   1st Qu.:29.97   1st Qu.:21.886  Median :24.658   Median :30.088   Median :40.92   Median :26.693  Mean   :24.834   Mean   :33.193   Mean   :39.77   Mean   :27.039  3rd Qu.:28.602   3rd Qu.:44.467   3rd Qu.:50.00   3rd Qu.:32.724  Max.   :43.765   Max.   :93.499   Max.   :75.53   Max.   :58.713         om             kwfactor         kffactor           spH  Min.   :  22.62   Min.   :0.0458   Min.   :0.0458   Min.   :4.630  1st Qu.:  91.74   1st Qu.:0.2511   1st Qu.:0.2788   1st Qu.:5.392  Median : 139.98   Median :0.3075   Median :0.3317   Median :6.287  Mean   : 180.11   Mean   :0.3082   Mean   :0.3280   Mean   :6.362  3rd Qu.: 210.54   3rd Qu.:0.3654   3rd Qu.:0.3875   3rd Qu.:7.241  Max.   :1888.36   Max.   :0.5579   Max.   :0.5579   Max.   :8.602       slope            tfactor  Min.   :  1.522   Min.   :2.259  1st Qu.: 42.695   1st Qu.:4.089  Median : 55.488   Median :4.519  Mean   : 61.019   Mean   :4.394  3rd Qu.: 67.398   3rd Qu.:4.820  Max.   :850.000   Max.   :5.000 # stco processing is problematic for GLM models like OLS, # yet is not needed for the random forest model. corn_data$stco <- NULL"},{"path":"https://tripartio.github.io/ale/articles/ale-acdc-corn.html","id":"corn-data-preparation","dir":"Articles","previous_headings":"","what":"Corn data preparation","title":"Analyzing a Large Corn Yield Dataset with ALE-Based Inference","text":"work Agro-Climatic Data County (ACDC), 1981–2015 (Yun & Gramig 2017). Rather reproducing full compilation code , summarize key transformations used assemble analysis-ready dataset. ACDC data arrive several components require harmonization. First, agricultural land area reported grids measured different years. normalize measures county-year level express agricultural land area square kilometres (ag_km2). Temperature involved transformation. ACDC stores temperatures counts days falling within one-degree Celsius bins (e.g., 2–3°C, 4–5°C, etc.). modelling, aggregate bins temperature ranges meaningful corn (maize) growth, creating variables count, county-year, many days fall within selected range. data description defines ranges notes agronomically relevant. defining “-season” windows, restrict attention months align typical crop calendars. table records windows used analysis (initially chosen based quick background guidance). Soil composition variables come county-level surveys conducted 1992, 2001, 2006, 2011. carry soil attributes forward county-year panel merge annual corn yield, measured bushels per acre (corn). U.S. dataset, report values bushels per acre provide metric conversion alongside . assembling dataset, inspect structure (e.g., glimpse()) verify variable types see sample rows. also compute summary statistics (min, max, mean, interquartile values) variable. variables used numeric; next section defines variable explicitly. outcome interest corn, corn yield (bushels per acre) given county given year.","code":"corn_data <- serialized_objects_site |>    file.path(\"corn_data.rds\") |>   url() |>    readRDS()"},{"path":"https://tripartio.github.io/ale/articles/ale-acdc-corn.html","id":"data-description","dir":"Articles","previous_headings":"","what":"Data description","title":"Analyzing a Large Corn Yield Dataset with ALE-Based Inference","text":"90,010 rows data record one county one year. county-years recorded produced corn specified year. data encoded numeric except stco (factor) year (integer). soil variables come Gridded Soil Survey Geographic Database (gSSURGO). Full details can obtained manual provided Yun & Gramig (2017). stco: State-county code 3,070 counties continental United States. year: Year: 1981–2015 corn: corn yields bushels per acre (bu/ac) ag_km2: total agricultural land county km2, calculated data ACDC “gridInfo.csv” file temp_lt_00: growing season degree days (°C·days) temperature interval 0°C, constructed 1°C intervals −60°C +60°C temp_00_10: growing season degree days (°C·days) 0°C 10°C interval, aggregated 1°C bins temp_11_20: growing season degree days (°C·days) 11°C 20°C interval, aggregated 1°C bins temp_21_30: growing season degree days (°C·days) 21°C 30°C interval, aggregated 1°C bins temp_31_35: growing season degree days (°C·days) 31°C 35°C interval, aggregated 1°C bins temp_36_45: growing season degree days (°C·days) 36°C 45°C interval, aggregated 1°C bins temp_gt_45: growing season degree days (°C·days) temperature interval 45°C, aggregated 1°C bins ppt: total precipitation growing season (mm) whc: water holding capacity (cm/cm) (awc gSSURGO) sand: sand proportion (%) (sandtotal gSSURGO) silt: silt proportion (%) (silttotal gSSURGO) clay: clay proportion (%) (claytotal gSSURGO) om: organic matter 2 mm top soil (%) (om gSSURGO) kwfactor: soil erodibility factor water adjusted rock fragments (kwfact gSSURGO) kffactor: soil erodibility factor water (kffact gSSURGO) spH: soil pH (ph1to1h2o_r gSSURGO) slope: slope (m) (slopelenusle gSSURGO) tfactor: soil loss tolerance factor (tons/acre/yr) (tfact gSSURGO) target outcome variable, corn (maize), measured bushels corn per acre (bu/ac, American units), 1 bu/ac corn 62.8 kilograms per hectare (kg/ha) 1 kg/ha 0.016 bu/ac corn. dataset, mean 106 bu/ac mean absolute deviation (mad) 30.2 bu/ac.","code":"corn_data |> glimpse() Rows: 90,010 Columns: 22 $ stco       <fct> 1001, 1003, 1005, 1009, 1011, 1013, 1015, 1019, 1021, 1023,… $ year       <int> 1981, 1981, 1981, 1981, 1981, 1981, 1981, 1981, 1981, 1981,… $ corn       <dbl> 17.3, 101.4, 37.9, 53.8, 22.1, 50.5, 46.6, 65.5, 31.8, 45.9… $ ag_km2     <dbl> 317.4507, 1000.1241, 429.0003, 447.9057, 266.2884, 187.1748… $ temp_lt_00 <dbl> 1.252724e-03, 1.334438e-04, 2.644859e-02, 5.219093e-01, 2.0… $ temp_00_10 <dbl> 9.108736, 5.825083, 9.556071, 16.302810, 10.703252, 9.11353… $ temp_11_20 <dbl> 42.16270, 37.20385, 42.41642, 46.73110, 43.30999, 41.31729,… $ temp_21_30 <dbl> 94.14356, 104.18624, 93.96831, 92.51842, 91.61782, 94.43539… $ temp_31_35 <dbl> 34.43768, 35.64974, 34.00982, 26.71666, 34.06262, 34.72649,… $ temp_36_45 <dbl> 4.14606767, 1.13495440, 4.02292888, 1.20910496, 4.28570742,… $ temp_gt_45 <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,… $ ppt        <dbl> 620.8656, 679.8329, 567.0682, 652.4704, 551.0441, 540.4134,… $ whc        <dbl> 24.78343, 23.53884, 21.48367, 18.28257, 22.58728, 24.71647,… $ sand       <dbl> 59.68140, 59.09199, 61.74435, 37.50056, 39.39067, 50.83622,… $ silt       <dbl> 20.04843, 21.80517, 16.41010, 33.40470, 25.92334, 21.17595,… $ clay       <dbl> 20.27016, 19.10284, 21.84554, 29.09474, 34.68599, 27.98784,… $ om         <dbl> 111.80678, 185.66755, 88.42968, 79.91542, 120.90292, 71.662… $ kwfactor   <dbl> 0.2230648, 0.2503898, 0.2123219, 0.2454282, 0.2304381, 0.21… $ kffactor   <dbl> 0.2263995, 0.2561335, 0.2123997, 0.2962476, 0.2328219, 0.21… $ spH        <dbl> 5.139626, 4.940044, 5.127343, 4.914515, 5.529810, 5.031030,… $ slope      <dbl> 51.03629, 106.22105, 65.98003, 32.14657, 46.05617, 63.86830… $ tfactor    <dbl> 4.950716, 4.936530, 4.926214, 3.174986, 4.988563, 4.889981,… corn_data |> summary() stco            year           corn           ag_km2  1049   :   45   Min.   :1981   Min.   :  0.0   Min.   :   0.4806  1077   :   45   1st Qu.:1988   1st Qu.: 80.0   1st Qu.: 316.7863  1079   :   45   Median :1993   Median :105.0   Median : 663.9057  1083   :   45   Mean   :1995   Mean   :106.0   Mean   : 767.3234  1089   :   45   3rd Qu.:2002   3rd Qu.:131.9   3rd Qu.:1076.1543  5021   :   45   Max.   :2015   Max.   :238.8   Max.   :5242.2723  (Other):89740    temp_lt_00       temp_00_10          temp_11_20        temp_21_30  Min.   : 0.000   Min.   : 0.000576   Min.   :  8.025   Min.   : 10.85  1st Qu.: 1.006   1st Qu.:19.224752   1st Qu.: 47.998   1st Qu.: 65.89  Median : 4.248   Median :29.188436   Median : 55.020   Median : 77.60  Mean   : 6.241   Mean   :27.847689   Mean   : 54.521   Mean   : 77.61  3rd Qu.: 9.698   3rd Qu.:37.250469   3rd Qu.: 62.071   3rd Qu.: 89.24  Max.   :52.734   Max.   :68.807006   Max.   :131.138   Max.   :128.56     temp_31_35       temp_36_45        temp_gt_45             ppt  Min.   : 0.000   Min.   : 0.0000   Min.   :0.0000000   Min.   :   0.9432  1st Qu.: 5.813   1st Qu.: 0.0000   1st Qu.:0.0000000   1st Qu.: 507.3542  Median :13.841   Median : 0.2692   Median :0.0000000   Median : 629.2561  Mean   :15.924   Mean   : 1.8541   Mean   :0.0007444   Mean   : 630.1739  3rd Qu.:23.581   3rd Qu.: 2.1338   3rd Qu.:0.0000000   3rd Qu.: 756.9606  Max.   :69.766   Max.   :63.5800   Max.   :2.6532670   Max.   :1601.6897        whc              sand             silt            clay  Min.   : 9.696   Min.   : 4.212   Min.   : 2.63   Min.   : 1.174  1st Qu.:20.826   1st Qu.:17.634   1st Qu.:29.97   1st Qu.:21.886  Median :24.658   Median :30.088   Median :40.92   Median :26.693  Mean   :24.834   Mean   :33.193   Mean   :39.77   Mean   :27.039  3rd Qu.:28.602   3rd Qu.:44.467   3rd Qu.:50.00   3rd Qu.:32.724  Max.   :43.765   Max.   :93.499   Max.   :75.53   Max.   :58.713         om             kwfactor         kffactor           spH  Min.   :  22.62   Min.   :0.0458   Min.   :0.0458   Min.   :4.630  1st Qu.:  91.74   1st Qu.:0.2511   1st Qu.:0.2788   1st Qu.:5.392  Median : 139.98   Median :0.3075   Median :0.3317   Median :6.287  Mean   : 180.11   Mean   :0.3082   Mean   :0.3280   Mean   :6.362  3rd Qu.: 210.54   3rd Qu.:0.3654   3rd Qu.:0.3875   3rd Qu.:7.241  Max.   :1888.36   Max.   :0.5579   Max.   :0.5579   Max.   :8.602       slope            tfactor  Min.   :  1.522   Min.   :2.259  1st Qu.: 42.695   1st Qu.:4.089  Median : 55.488   Median :4.519  Mean   : 61.019   Mean   :4.394  3rd Qu.: 67.398   3rd Qu.:4.820  Max.   :850.000   Max.   :5.000"},{"path":"https://tripartio.github.io/ale/articles/ale-acdc-corn.html","id":"removal-of-county-identifier","dir":"Articles","previous_headings":"","what":"Removal of county identifier","title":"Analyzing a Large Corn Yield Dataset with ALE-Based Inference","text":"One consequential preprocessing choice exclude county identifier (stco) modelling dataset. raw data, county represented state-county code spanning 3,070 counties across 48 contiguous U.S. states. initially included county predictor, created substantial computational problems little benefit. GLM-style models, treating county factor 3,070 levels expands design matrix dramatically (thousands dummy variables) can make estimation impractically slow, sometimes requiring mixed-model machinery sparse-matrix handling. experiments, slowed GLM estimation orders magnitude without improving predictive performance. Random forests, contrast, performed essentially without county. clarity tractability, therefore omit county, given neither improved performance best-performing model justified computational cost GLM models.","code":"# stco processing is problematic for GLM models like OLS, # yet is not needed for the random forest model. corn_data$stco <- NULL"},{"path":"https://tripartio.github.io/ale/articles/ale-acdc-corn.html","id":"model-evaluation","dir":"Articles","previous_headings":"","what":"Model evaluation","title":"Analyzing a Large Corn Yield Dataset with ALE-Based Inference","text":"evaluate models dataset roughly 90,000 county-year observations. scale, bootstrapping becomes prohibitively slow, cross-validation feasible reliable. therefore use 10-fold cross-validation throughout. keep evaluation consistent across models, use dedicated cross-validation function written analysis. computes mean absolute error (MAE) standardized accuracy folds, differences across models reflect modelling choices rather differences resampling.","code":"# Cross validate a model and calculate MAE and staccuracy cv_mae_sa <- function(data, y_col, folds, fit_fn, pred_fn) {      fold_results <- folds |>     mutate(       metrics = splits |>          map(\\(it.split) {           it.id <- it.split$id           cli::cli_alert_info(\"Analyzing {it.id}...\")                      it.train <- analysis(it.split)           it.test  <- assessment(it.split)                      it.fit  <- fit_fn(it.train)           it.pred <- pred_fn(it.fit, it.test) |> as.numeric()                      it.mae <- mae(actual = it.test[[y_col]], pred = it.pred)           it.sa  <- sa_wmae_mad(actual = it.test[[y_col]], pred = it.pred)                      cli::cli_alert_info(\"MAE: {it.mae |> round(3)} | SA: {round(it.sa * 100, 1)}%\")                      tibble(             mae = it.mae,             sa  = it.sa           )         })     ) |>     tidyr::unnest(metrics)      summary <- fold_results |>     summarise(       mean_mae = mean(mae),       sd_mae   = sd(mae),       mean_sa  = mean(sa),       sd_sa    = sd(sa)     )      list(     fold_results = fold_results,     summary = summary   ) }   # Create folds for 10-fold cross-validation (used across all models) set.seed(0) corn_folds <- vfold_cv(corn_data, v = 10)"},{"path":"https://tripartio.github.io/ale/articles/ale-acdc-corn.html","id":"cross-validation-function","dir":"Articles","previous_headings":"","what":"Cross-validation function","title":"Analyzing a Large Corn Yield Dataset with ALE-Based Inference","text":"","code":"# Cross validate a model and calculate MAE and staccuracy cv_mae_sa <- function(data, y_col, folds, fit_fn, pred_fn) {      fold_results <- folds |>     mutate(       metrics = splits |>          map(\\(it.split) {           it.id <- it.split$id           cli::cli_alert_info(\"Analyzing {it.id}...\")                      it.train <- analysis(it.split)           it.test  <- assessment(it.split)                      it.fit  <- fit_fn(it.train)           it.pred <- pred_fn(it.fit, it.test) |> as.numeric()                      it.mae <- mae(actual = it.test[[y_col]], pred = it.pred)           it.sa  <- sa_wmae_mad(actual = it.test[[y_col]], pred = it.pred)                      cli::cli_alert_info(\"MAE: {it.mae |> round(3)} | SA: {round(it.sa * 100, 1)}%\")                      tibble(             mae = it.mae,             sa  = it.sa           )         })     ) |>     tidyr::unnest(metrics)      summary <- fold_results |>     summarise(       mean_mae = mean(mae),       sd_mae   = sd(mae),       mean_sa  = mean(sa),       sd_sa    = sd(sa)     )      list(     fold_results = fold_results,     summary = summary   ) }   # Create folds for 10-fold cross-validation (used across all models) set.seed(0) corn_folds <- vfold_cv(corn_data, v = 10)"},{"path":"https://tripartio.github.io/ale/articles/ale-acdc-corn.html","id":"ols-regression","dir":"Articles","previous_headings":"","what":"OLS regression","title":"Analyzing a Large Corn Yield Dataset with ALE-Based Inference","text":"begin standard ordinary least squares (OLS) regression using lm(), predicting corn available covariates. gives us familiar GLM baseline compare machine-learning model later. central limitation GLM approaches like OLS “discover” interactions. interactions matter, must anticipate include explicitly. setting, tricky () limited guidance interactions truly important, (b) adding interactions can make estimation dramatically slower. Given panel structure data, one interaction especially natural: county (stco) year. allows county time trend, effectively fitting separate time-specific effects 3,070 counties. exploratory analyses shown , also experimented including county identifier directly (stco). Accuracy reasonably strong (78.2% standardized accuracy), model extremely slow: county-year interaction, takes roughly hour run machine. bottleneck hyper-cardinality stco. factor, generates 3,069 dummy variables even add interaction term. comparison, modelling variables without interaction took “” 17 minutes. short, GLM methods struggle predictor thousands levels, interactions can make struggle explode. Although county-year interaction substantially improved accuracy (roughly 12 percentage points standardized accuracy), unacceptable computational cost, report full OLS--interaction output . Instead, summarize timing accuracy comparison table conclusion focus interpretation better-performing, tractable models. GLM output, tempting focus coefficient p-values. dataset large, approach mostly distraction. around 90,000 observations, essentially everything becomes statistically significant, “significance” mainly tells us estimates stable, effects practically important. trying interpret coefficients, check whether model predicts well enough worth interpreting. adjusted R-squared 0.435, hard evaluate isolation, rely preferred accuracy metrics. large dataset, descriptive cross-validated metrics similar, indicating little overfitting. OLS model mean absolute error (MAE) 21.4 bushels per acre (SD 0.178) standardized accuracy 64.7% (SD 0.005). respectable, clearly outperformed random forest model, pursue ALE-based interpretation OLS.","code":"tic() lm_corn <- lm(corn ~ ., data = corn_data) toc()  # 0.14 sec (with county 3539.29 sec elapsed (59 minutes = 1 hour)) 0.541 sec elapsed summary(lm_corn) Call: lm(formula = corn ~ ., data = corn_data)  Residuals:      Min       1Q   Median       3Q      Max -160.420  -16.282    1.204   17.656  166.706  Coefficients: (1 not defined because of singularities)               Estimate Std. Error t value Pr(>|t|) (Intercept) -6.401e+03  1.384e+03  -4.626 3.74e-06 *** year         1.643e+00  1.057e-02 155.335  < 2e-16 *** ag_km2       4.286e-03  2.016e-04  21.263  < 2e-16 *** temp_lt_00   1.498e+01  7.520e+00   1.992 0.046394 * temp_00_10   1.621e+01  7.520e+00   2.155 0.031168 * temp_11_20   1.647e+01  7.520e+00   2.190 0.028515 * temp_21_30   1.693e+01  7.520e+00   2.252 0.024327 * temp_31_35   1.499e+01  7.520e+00   1.994 0.046159 * temp_36_45   1.578e+01  7.520e+00   2.098 0.035892 * temp_gt_45   4.853e+01  8.264e+00   5.873 4.29e-09 *** ppt         -4.950e-03  6.298e-04  -7.860 3.88e-15 *** whc          4.685e-01  3.185e-02  14.710  < 2e-16 *** sand         9.197e-01  1.495e-02  61.534  < 2e-16 *** silt         1.439e+00  3.166e-02  45.447  < 2e-16 *** clay                NA         NA      NA       NA om           2.959e-03  7.658e-04   3.864 0.000112 *** kwfactor    -3.990e+01  3.323e+00 -12.009  < 2e-16 *** kffactor     1.472e+01  4.070e+00   3.617 0.000298 *** spH          1.297e+01  1.565e-01  82.898  < 2e-16 *** slope        3.162e-02  2.478e-03  12.764  < 2e-16 *** tfactor      6.285e+00  2.799e-01  22.456  < 2e-16 *** --- Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1  Residual standard error: 28.18 on 89990 degrees of freedom Multiple R-squared:  0.4352,    Adjusted R-squared:  0.435 F-statistic:  3649 on 19 and 89990 DF,  p-value: < 2.2e-16 # Descriptive metrics (on the entire dataset; these evaluations overfit) sa_lm_corn  <- sa_wmae_mad(corn_data$corn, predict(lm_corn))  # 0.6466406 (with county 0.7823067) mae_lm_corn <- mae(corn_data$corn, predict(lm_corn))  # 21.36306  # More realistic predictive MAE by cross-validation cv_lm <- cv_mae_sa(   data = corn_data, y_col = \"corn\", folds = corn_folds,   fit_fn = \\(train) lm(corn ~ ., data = corn_data),   pred_fn = \\(fit, newdata) predict(fit, newdata) ) cv_lm$summary # A tibble: 1 × 4   mean_mae sd_mae mean_sa   sd_sa      <dbl>  <dbl>   <dbl>   <dbl> 1     21.4  0.178   0.647 0.00452 # $summary # # A tibble: 1 × 4 #   mean_mae sd_mae mean_sa   sd_sa #      <dbl>  <dbl>   <dbl>   <dbl> # 1     21.4  0.178   0.647 0.00452"},{"path":"https://tripartio.github.io/ale/articles/ale-acdc-corn.html","id":"random-forest","dir":"Articles","previous_headings":"","what":"Random forest","title":"Analyzing a Large Corn Yield Dataset with ALE-Based Inference","text":"next fit random forest using ranger. principle, first step tune hyperparameters dataset. tested {tuneRanger} package purpose. case, tuning produced marginal accuracy gains, slowing training substantially. Given downstream interpretation computationally heavy, prioritize speed. therefore use default ranger settings one key adjustment: reduce number trees default 500 50. dataset size, change yields almost identical level accuracy cutting training time roughly order magnitude. Training prediction speed matter two reasons. First, estimating p-value distributions requires retraining model 1,000 refits. Second, ALE computation bootstrapping many variables requires thousands full-dataset predictions. faster model turns steps “nope” “doable.” final model report , defining choices reduced forest size (50 trees) along ranger’s default settings (e.g., mtry = 4, min.node.size = 5, variance split rule). deviation defaults tree count. Whenever procedures slow demonstration, code blocks commented presaved objects loaded instead, document runs quickly. ranger package reports --bag MSE R2 internally, evaluate cross-validated metrics consistency. random forest achieves mean MAE 4.1 bushels per acre (SD 0.05) mean standardized accuracy 93.1%. Descriptive cross-validated values virtually identical, even 50 trees model overfit. machine, training fast enough repeated resampling runs (roughly order 10 seconds per training round). Notably, including county variable additional tests yielded essentially cross-validated performance, reinforcing can proceed without . level performance, treat random forest primary model interpretation, use basis ALE analysis follows","code":"# Default ranger model tic() rf_corn <- ranger(   corn ~ ., data = corn_data,   # 50 trees are much faster than default 500 trees, with almost identical accuracy on such a large dataset   num.trees = 50,   # Warning: original ranger object trained in other serialized data for this   # article did not use this seed. So, your version might randomly not match   # some details in this article.   seed = 1   ) toc()  # 7.92  sec elapsed 22.916 sec elapsed # default 500 trees: 86.52 sec elapsed # saveRDS(rf_corn, file.choose()) # Descriptive metrics (on the entire dataset; these evaluations overfit) sa_rf_corn  <- sa_wmae_mad(corn_data$corn, predict(rf_corn, corn_data)$predictions)  # 0.9305763 mae_rf_corn <- mae(corn_data$corn, predict(rf_corn, corn_data)$predictions)  # 4.197151  rf_corn Ranger result  Call:  ranger(corn ~ ., data = corn_data, num.trees = 50, seed = 1)  Type:                             Regression Number of trees:                  50 Sample size:                      90010 Number of independent variables:  20 Mtry:                             4 Target node size:                 5 Variable importance mode:         none Splitrule:                        variance OOB prediction error (MSE):       202.3054 R squared (OOB):                  0.8560274 # SLOW: uncomment to run yourself; load the saved object for rapid execution  # # More realistic predictive MAE by cross-validation # tic() # cv_rf <- cv_mae_sa( #   data = corn_data, y_col = \"corn\", folds = corn_folds, #   fit_fn = \\(train) ranger(corn ~ ., data = corn_data, num.trees = 50), #   pred_fn = \\(fit, newdata) ranger:::predict.ranger(fit, newdata)$predictions # ) # toc()  # 79.86 sec elapsed # # saveRDS(cv_rf, file.choose()) # $summary # # A tibble: 1 × 4 #   mean_mae sd_mae mean_sa   sd_sa #      <dbl>  <dbl>   <dbl>   <dbl> # 1     4.14 0.0565   0.931 0.00123  cv_rf <- serialized_objects_site |>    file.path(\"cv_rf.rds\") |>   url() |>    readRDS()  cv_rf$summary # A tibble: 1 × 4   mean_mae sd_mae mean_sa   sd_sa      <dbl>  <dbl>   <dbl>   <dbl> 1     4.19 0.0545   0.931 0.00106"},{"path":"https://tripartio.github.io/ale/articles/ale-acdc-corn.html","id":"ale-analysis","dir":"Articles","previous_headings":"","what":"ALE analysis","title":"Analyzing a Large Corn Yield Dataset with ALE-Based Inference","text":"now turn ALE analysis. data set contains one outcome variable 20 predictors. structure immediately determines scope exercise. First, estimate 20 main effects, one predictor. part straightforward. computational weight comes interactions. 20 predictors, number unique pairwise combinations 190, giving total 210 ALE calculations. takes random forest around 17 minutes. worth emphasizing works practice. default ranger settings (500 trees), task take roughly ten times longer; reduction 50 trees (feasible large dataset) renders type comprehensive interaction analysis feasible. initial ALE run produces large set results (210 terms), immediate practical problem triage: effects large enough justify deeper inspection bootstrapping? dataset big, non-bootstrapped results often close bootstrapped ones, analysis want stand behind, still need bootstrapping. catch compute time. Even 100 bootstrap iterations (bare minimum stable inference, still modest publication) multiplies runtime roughly 100. single pass takes order minutes, blindly bootstrapping every term practical, especially many effects visibly tiny. ALE summary statistics earn keep. Instead paging 210 plots guessing matters, use effect-size summaries ALE deviation (ALED) identify small number terms plausibly meaningful. explain ALE statistics detail another article. stage, usual “statistically significant?” question wrong tool. roughly 90,000 observations, estimated effects statistically reliable (therefore often statistically significant) whether matter real world. Reliability tells us estimate stable; tell us important. actually need effect-size yardstick. corn yield, managerial question simple stubborn: large change yield (bushels per acre) care? 1 bushel/acre swing meaningful, need something like 5 bushels/acre rises noise real decisions? something p-value can answer. common attempt dodge decision “least significant difference” (LSD) idea: translate p-value threshold (often 0.05) equivalent difference y-scale. large samples, typically produces vanishingly small threshold, mathematically consistent practically useless. example, LSD 90,000-row corn_data dataset rf_corn model 0.05 p-value level piddling 0.07 bu/ac. words, re-labels statistical reliability “importance” without solving real problem. Using LSD criterion dataset result selecting 205out 210 variables. end, domain expertise set practical threshold. role provide effect-size estimates interpretable original scale (bushels per acre), experts can decide counts meaningful. case, somewhat arbitrarily assume threshold 2 bu/ac (125.5 kg/ha) practically meaningful threshold. Since non-bootstrapped ALE results precise, use cut-half value (, 1 bu/ac) ALED variables select analysis. cutoff focuses 14 main effects 2 interactions. Statistical results (ALE otherwise) generally reliable bootstrap . dataset large training ALE calculation times lengthy, use data-bootstrapping, faster approach resamples ALE calculation data without retraining model. appropriate approach large datasets slow models already validated cross-validation, case. explain difference bootstrap approaches article ALE statistics inference. default, use 100 bootstrap iterations. publication, increase number, analysis, 100 iterations typically sufficient lead conclusions, especially large dataset. bootstrapping, let’s first generate ALE p-value distribution. slowest step ALE analysis relies simulation rather parametric assumptions. can use p-value distribution data-bootstrapping procedure {ale} package, specifying boot_it argument ALE() constructor. specifically request ALE filtered set variables meet 1 bu/ac threshold ALED. bootstrap process ALE results become reliable. bootstrapped ALED results closely match non-bootstrapped results, expect dataset size: even single ALE computation usually quite reliable. Bootstrapping mainly serves two purposes . First, confirms ranking larger effects stable. Second, reassures us small ALED values really small, rather artifacts single run. confirmation, interpretation fairly direct. Year far strongest effect: across roughly 35-year span study, average range 11 bushels per acre. Next, several temperature ranges show largest climate effects, notably 21–30°C, 31–35°C, 36–45°C, exceeding 4 bushels per acre effect size. Agricultural land area (ag_km2) also practically important. Among soil variables, water holding capacity (whc), K/W factor (kwfactor), soil pH (spH) clear practical-importance threshold 2. interactions, neither two bootstrapped interactions exceeds practical threshold 2. matters means can interpret main-effect ALE plots largely terms: interactions exist model, appear strong enough (scale) meaningfully distort main-effect conclusions. make ALE plots readable, adjust default output. print 1D 2D plots separately subsetting plot objects, apply customization step zoom y-axis 1D ALE plots. y-axis limits chosen improve visibility keeping plots common scale, makes relative effect sizes easier compare across variables.  view, plots align cleanly ALED rankings: year shows largest range, followed key temperature ranges (especially 21–30°C 31–35°C). also interpret plots rug marks mind. Extreme x-values often sparse support, put interpretive weight regions predictor data dense ALE curve well supported.  Looking interaction plots, visible pattern involves year number days temperatures 45°C. appears small regime shift: roughly 1–2 days, earlier years associated higher yield, later years associated lower yield. However, interaction heatmaps also display fraction observations cell (size little grey squares within cells). “statistically significant” regions, squares tiny, often representing less 1% data. practice, county-years days 45°C, interaction, real statistically significant, supported little data. similar caution applies interaction days 45°C days 0–10°C range. visual suggests conditional effects, relevant cells sparsely populated, treat interaction signals weak practically decisive.","code":"# SLOW: uncomment to run yourself; load the saved object for rapid execution  # # ALE for all 1D and 2D variables # tic() # ale_single_rf_corn <- ALE( #   rf_corn, #   # d1=TRUE: all 1D variables (main effects): d2=TRUE: all 2D interactions #   x_cols = list(d1 = TRUE, d2 = TRUE), #   data = corn_data, #   parallel = 0 # ) # toc()   # # 21 1D ALE + 210 2D ALE: 1032.01 sec elapsed (17.2 minutes) # # saveRDS(ale_single_rf_corn, file.choose())  ale_single_rf_corn <- serialized_objects_site |>    file.path(\"ale_single_rf_corn.rds\") |>   url() |>    readRDS()  summary(ale_single_rf_corn) # A tibble: 210 × 7     term                     aled aler_min aler_max  naled naler_min naler_max     <chr>                   <dbl>    <dbl>    <dbl>  <dbl>     <dbl>     <dbl>   1 year                  10.9     -15.2     27.4   11.2     -16.5      25.5   2 ag_km2                 2.01     -5.85     2.68   2.40     -6.41      2.89   3 temp_lt_00             1.36     -7.00     2.66   1.69     -7.37      2.89   4 temp_00_10             1.28     -4.40     1.86   1.72     -4.56      2.09   5 temp_11_20             0.750    -4.49     1.73   1.12     -4.60      2.04   6 temp_21_30             4.20    -17.7      8.39   4.61    -18.5       8.63   7 temp_31_35             4.57    -11.1      6.33   4.91    -12.0       6.85   8 temp_36_45             4.75    -14.7      5.31   5.38    -15.2       5.92   9 temp_gt_45             0        -1.74     1.74   0        -2.03      2.04  10 ppt                    1.05     -3.00     1.31   1.50     -3.05      1.87  11 whc                    2.15     -3.55     5.99   2.56     -3.79      6.20  12 sand                   0.166    -0.751    1.21   0.583    -1.09      1.83  13 silt                   1.27     -2.18     2.39   1.57     -2.67      2.78  14 clay                   1.10     -2.13     1.14   1.49     -2.67      1.80  15 om                     0.786    -2.20     1.56   1.27     -2.67      1.93  16 kwfactor               2.12     -2.80     4.69   2.51     -3.01      4.75  17 kffactor               0.292    -0.746    1.08   0.817    -1.09      1.74  18 spH                    2.07     -3.70     4.69   2.40     -3.84      4.75  19 slope                  0.825    -1.36     2.63   1.30     -1.85      2.89  20 tfactor                1.92     -3.15    10.6    2.30     -3.61     10.8  21 year:ag_km2            0.484    -1.40     1.30   0.957    -1.85      1.83  22 year:temp_lt_00        0.707    -4.07     2.90   1.10     -4.45      3.04  23 year:temp_00_10        0.484    -1.24     1.20   0.955    -1.82      1.80  24 year:temp_11_20        0.616    -4.26     2.13   1.07     -4.53      2.70  25 year:temp_21_30        0.443    -1.20     2.04   0.897    -1.75      2.65  26 year:temp_31_35        0.824    -3.10     2.05   1.26     -3.56      2.65  27 year:temp_36_45        0.602    -4.72     1.73   1.07     -4.75      2.04  28 year:temp_gt_45        1.63     -1.99     1.93   1.99     -2.11      2.15  29 year:ppt               0.581    -3.49     1.52   1.01     -3.74      1.93  30 year:whc               0.254    -1.20     0.612  0.699    -1.82      1.06  31 year:sand              0.348    -2.08     1.12   0.765    -2.61      1.80  32 year:silt              0.140    -0.583    0.416  0.532    -1.01      0.965  33 year:clay              0.139    -0.573    0.349  0.486    -1.01      0.930  34 year:om                0.290    -0.958    1.07   0.746    -1.16      1.74  35 year:kwfactor          0.265    -0.733    0.946  0.672    -1.09      1.20  36 year:kffactor          0.195    -0.760    0.554  0.602    -1.09      1.01  37 year:spH               0.578    -2.94     1.57   1.00     -3.05      1.93  38 year:slope             0.518    -2.48     2.18   0.915    -2.81      2.70  39 year:tfactor           0.336    -1.09     1.03   0.797    -1.70      1.74  40 ag_km2:temp_lt_00      0.207    -0.535    1.88   0.627    -1.01      2.09  41 ag_km2:temp_00_10      0.152    -0.592    0.55   0.496    -1.01      1.01  42 ag_km2:temp_11_20      0.195    -1.23     0.736  0.534    -1.82      1.10  43 ag_km2:temp_21_30      0.199    -1.08     1.59   0.555    -1.70      1.93  44 ag_km2:temp_31_35      0.236    -1.08     0.679  0.655    -1.70      1.06  45 ag_km2:temp_36_45      0.203    -0.545    0.985  0.649    -1.01      1.20  46 ag_km2:temp_gt_45      0.512    -0.940    0.514  0.985    -1.16      1.01  47 ag_km2:ppt             0.144    -1.25     0.473  0.27     -1.82      0.965  48 ag_km2:whc             0.236    -0.832    1.15   0.631    -1.11      1.80  49 ag_km2:sand            0.142    -0.393    0.551  0.484    -0.921     1.01  50 ag_km2:silt            0.183    -0.462    0.834  0.533    -0.957     1.15  51 ag_km2:clay            0.150    -0.484    0.604  0.488    -0.957     1.06  52 ag_km2:om              0.191    -0.416    2.42   0.551    -0.957     2.81  53 ag_km2:kwfactor        0.122    -0.564    0.394  0.494    -1.01      0.930  54 ag_km2:kffactor        0.220    -0.709    1.18   0.610    -1.09      1.80  55 ag_km2:spH             0.205    -0.527    1.46   0.613    -1.01      1.89  56 ag_km2:slope           0.128    -0.739    0.657  0.352    -1.09      1.06  57 ag_km2:tfactor         0.186    -0.846    0.903  0.545    -1.11      1.20  58 temp_lt_00:temp_00_10  0.200    -1.37     2.93   0.668    -1.85      3.04  59 temp_lt_00:temp_11_20  0.240    -0.431    1.75   0.699    -0.957     2.04  60 temp_lt_00:temp_21_30  0.317    -0.620    1.88   0.788    -1.05      2.09  61 temp_lt_00:temp_31_35  0.120    -2.34     2.52   0.426    -2.77      2.86  62 temp_lt_00:temp_36_45  0.173    -0.555    1.88   0.546    -1.01      2.09  63 temp_lt_00:temp_gt_45  0.546    -0.496    1.32   1.06     -0.957     1.87  64 temp_lt_00:ppt         0.324    -1.54     2.46   0.722    -1.93      2.81  65 temp_lt_00:whc         0.106    -0.676    0.362  0.359    -1.05      0.930  66 temp_lt_00:sand        0.0843   -0.455    0.622  0.233    -0.957     1.06  67 temp_lt_00:silt        0.0951   -0.204    0.724  0.259    -0.876     1.10  68 temp_lt_00:clay        0.155    -0.551    0.878  0.445    -1.01      1.15  69 temp_lt_00:om          0.125    -0.349    1.90   0.417    -0.921     2.15  70 temp_lt_00:kwfactor    0.123    -0.262    0.612  0.424    -0.876     1.06  71 temp_lt_00:kffactor    0.101    -0.360    0.585  0.258    -0.921     1.01  72 temp_lt_00:spH         0.228    -0.567    1.96   0.662    -1.01      2.15  73 temp_lt_00:slope       0.0907   -0.271    0.405  0.266    -0.876     0.965  74 temp_lt_00:tfactor     0.0978   -0.551    0.345  0.353    -1.01      0.930  75 temp_00_10:temp_11_20  0.160    -0.404    2.48   0.442    -0.957     2.81  76 temp_00_10:temp_21_30  0.261    -1.05     3.11   0.760    -1.70      3.62  77 temp_00_10:temp_31_35  0.168    -0.662    2.37   0.598    -1.05      2.78  78 temp_00_10:temp_36_45  0.274    -1.45     2.02   0.739    -1.90      2.65  79 temp_00_10:temp_gt_45  1.68     -0.255    2.50   2.03     -0.876     2.86  80 temp_00_10:ppt         0.224    -0.616    2.20   0.616    -1.05      2.75  81 temp_00_10:whc         0.0818   -0.371    0.468  0.245    -0.921     0.965  82 temp_00_10:sand        0.135    -0.495    1.01   0.415    -0.957     1.74  83 temp_00_10:silt        0.226    -0.970    1.02   0.527    -1.16      1.74  84 temp_00_10:clay        0.205    -1.12     0.704  0.630    -1.75      1.10  85 temp_00_10:om          0.0836   -0.565    0.508  0.245    -1.01      1.01  86 temp_00_10:kwfactor    0.177    -0.604    0.714  0.616    -1.05      1.10  87 temp_00_10:kffactor    0.125    -0.565    0.728  0.302    -1.01      1.10  88 temp_00_10:spH         0.151    -0.352    0.771  0.554    -0.921     1.10  89 temp_00_10:slope       0.106    -0.362    0.393  0.311    -0.921     0.930  90 temp_00_10:tfactor     0.105    -0.91     0.435  0.286    -1.16      0.965  91 temp_11_20:temp_21_30  0.304    -1.87     1.21   0.745    -2.06      1.83  92 temp_11_20:temp_31_35  0.208    -1.52     3.38   0.629    -1.93      3.69  93 temp_11_20:temp_36_45  0.193    -1.22     2.83   0.598    -1.82      2.99  94 temp_11_20:temp_gt_45  0.419    -0.797    0.546  0.869    -1.09      1.01  95 temp_11_20:ppt         0.162    -1.31     0.577  0.428    -1.85      1.01  96 temp_11_20:whc         0.204    -0.934    2.04   0.537    -1.16      2.65  97 temp_11_20:sand        0.123    -0.385    0.358  0.426    -0.921     0.930  98 temp_11_20:silt        0.098    -0.382    0.551  0.297    -0.921     1.01  99 temp_11_20:clay        0.0908   -0.604    0.361  0.295    -1.05      0.930 100 temp_11_20:om          0.297    -1.38     0.831  0.774    -1.85      1.15 # ℹ 110 more rows # A tibble: 420 × 7     statistic term                  estimate conf.low    mean  median conf.high     <ord>     <chr>                    <dbl>    <dbl>   <dbl>   <dbl>     <dbl>   1 aled      year                   10.9     10.9    10.9    10.9      10.9   2 aled      ag_km2                  2.01     2.01    2.01    2.01      2.01   3 aled      temp_lt_00              1.36     1.36    1.36    1.36      1.36   4 aled      temp_00_10              1.28     1.28    1.28    1.28      1.28   5 aled      temp_11_20              0.750    0.750   0.750   0.750     0.750   6 aled      temp_21_30              4.20     4.20    4.20    4.20      4.20   7 aled      temp_31_35              4.57     4.57    4.57    4.57      4.57   8 aled      temp_36_45              4.75     4.75    4.75    4.75      4.75   9 aled      temp_gt_45              0        0       0       0         0  10 aled      ppt                     1.05     1.05    1.05    1.05      1.05  11 aled      whc                     2.15     2.15    2.15    2.15      2.15  12 aled      sand                    0.166    0.166   0.166   0.166     0.166  13 aled      silt                    1.27     1.27    1.27    1.27      1.27  14 aled      clay                    1.10     1.10    1.10    1.10      1.10  15 aled      om                      0.786    0.786   0.786   0.786     0.786  16 aled      kwfactor                2.12     2.12    2.12    2.12      2.12  17 aled      kffactor                0.292    0.292   0.292   0.292     0.292  18 aled      spH                     2.07     2.07    2.07    2.07      2.07  19 aled      slope                   0.825    0.825   0.825   0.825     0.825  20 aled      tfactor                 1.92     1.92    1.92    1.92      1.92  21 aled      year:ag_km2             0.484    0.484   0.484   0.484     0.484  22 aled      year:temp_lt_00         0.707    0.707   0.707   0.707     0.707  23 aled      year:temp_00_10         0.484    0.484   0.484   0.484     0.484  24 aled      year:temp_11_20         0.616    0.616   0.616   0.616     0.616  25 aled      year:temp_21_30         0.443    0.443   0.443   0.443     0.443  26 aled      year:temp_31_35         0.824    0.824   0.824   0.824     0.824  27 aled      year:temp_36_45         0.602    0.602   0.602   0.602     0.602  28 aled      year:temp_gt_45         1.63     1.63    1.63    1.63      1.63  29 aled      year:ppt                0.581    0.581   0.581   0.581     0.581  30 aled      year:whc                0.254    0.254   0.254   0.254     0.254  31 aled      year:sand               0.348    0.348   0.348   0.348     0.348  32 aled      year:silt               0.140    0.140   0.140   0.140     0.140  33 aled      year:clay               0.139    0.139   0.139   0.139     0.139  34 aled      year:om                 0.290    0.290   0.290   0.290     0.290  35 aled      year:kwfactor           0.265    0.265   0.265   0.265     0.265  36 aled      year:kffactor           0.195    0.195   0.195   0.195     0.195  37 aled      year:spH                0.578    0.578   0.578   0.578     0.578  38 aled      year:slope              0.518    0.518   0.518   0.518     0.518  39 aled      year:tfactor            0.336    0.336   0.336   0.336     0.336  40 aled      ag_km2:temp_lt_00       0.207    0.207   0.207   0.207     0.207  41 aled      ag_km2:temp_00_10       0.152    0.152   0.152   0.152     0.152  42 aled      ag_km2:temp_11_20       0.195    0.195   0.195   0.195     0.195  43 aled      ag_km2:temp_21_30       0.199    0.199   0.199   0.199     0.199  44 aled      ag_km2:temp_31_35       0.236    0.236   0.236   0.236     0.236  45 aled      ag_km2:temp_36_45       0.203    0.203   0.203   0.203     0.203  46 aled      ag_km2:temp_gt_45       0.512    0.512   0.512   0.512     0.512  47 aled      ag_km2:ppt              0.144    0.144   0.144   0.144     0.144  48 aled      ag_km2:whc              0.236    0.236   0.236   0.236     0.236  49 aled      ag_km2:sand             0.142    0.142   0.142   0.142     0.142  50 aled      ag_km2:silt             0.183    0.183   0.183   0.183     0.183  51 aled      ag_km2:clay             0.150    0.150   0.150   0.150     0.150  52 aled      ag_km2:om               0.191    0.191   0.191   0.191     0.191  53 aled      ag_km2:kwfactor         0.122    0.122   0.122   0.122     0.122  54 aled      ag_km2:kffactor         0.220    0.220   0.220   0.220     0.220  55 aled      ag_km2:spH              0.205    0.205   0.205   0.205     0.205  56 aled      ag_km2:slope            0.128    0.128   0.128   0.128     0.128  57 aled      ag_km2:tfactor          0.186    0.186   0.186   0.186     0.186  58 aled      temp_lt_00:temp_00_10   0.200    0.200   0.200   0.200     0.200  59 aled      temp_lt_00:temp_11_20   0.240    0.240   0.240   0.240     0.240  60 aled      temp_lt_00:temp_21_30   0.317    0.317   0.317   0.317     0.317  61 aled      temp_lt_00:temp_31_35   0.120    0.120   0.120   0.120     0.120  62 aled      temp_lt_00:temp_36_45   0.173    0.173   0.173   0.173     0.173  63 aled      temp_lt_00:temp_gt_45   0.546    0.546   0.546   0.546     0.546  64 aled      temp_lt_00:ppt          0.324    0.324   0.324   0.324     0.324  65 aled      temp_lt_00:whc          0.106    0.106   0.106   0.106     0.106  66 aled      temp_lt_00:sand         0.0843   0.0843  0.0843  0.0843    0.0843  67 aled      temp_lt_00:silt         0.0951   0.0951  0.0951  0.0951    0.0951  68 aled      temp_lt_00:clay         0.155    0.155   0.155   0.155     0.155  69 aled      temp_lt_00:om           0.125    0.125   0.125   0.125     0.125  70 aled      temp_lt_00:kwfactor     0.123    0.123   0.123   0.123     0.123  71 aled      temp_lt_00:kffactor     0.101    0.101   0.101   0.101     0.101  72 aled      temp_lt_00:spH          0.228    0.228   0.228   0.228     0.228  73 aled      temp_lt_00:slope        0.0907   0.0907  0.0907  0.0907    0.0907  74 aled      temp_lt_00:tfactor      0.0978   0.0978  0.0978  0.0978    0.0978  75 aled      temp_00_10:temp_11_20   0.160    0.160   0.160   0.160     0.160  76 aled      temp_00_10:temp_21_30   0.261    0.261   0.261   0.261     0.261  77 aled      temp_00_10:temp_31_35   0.168    0.168   0.168   0.168     0.168  78 aled      temp_00_10:temp_36_45   0.274    0.274   0.274   0.274     0.274  79 aled      temp_00_10:temp_gt_45   1.68     1.68    1.68    1.68      1.68  80 aled      temp_00_10:ppt          0.224    0.224   0.224   0.224     0.224  81 aled      temp_00_10:whc          0.0818   0.0818  0.0818  0.0818    0.0818  82 aled      temp_00_10:sand         0.135    0.135   0.135   0.135     0.135  83 aled      temp_00_10:silt         0.226    0.226   0.226   0.226     0.226  84 aled      temp_00_10:clay         0.205    0.205   0.205   0.205     0.205  85 aled      temp_00_10:om           0.0836   0.0836  0.0836  0.0836    0.0836  86 aled      temp_00_10:kwfactor     0.177    0.177   0.177   0.177     0.177  87 aled      temp_00_10:kffactor     0.125    0.125   0.125   0.125     0.125  88 aled      temp_00_10:spH          0.151    0.151   0.151   0.151     0.151  89 aled      temp_00_10:slope        0.106    0.106   0.106   0.106     0.106  90 aled      temp_00_10:tfactor      0.105    0.105   0.105   0.105     0.105  91 aled      temp_11_20:temp_21_30   0.304    0.304   0.304   0.304     0.304  92 aled      temp_11_20:temp_31_35   0.208    0.208   0.208   0.208     0.208  93 aled      temp_11_20:temp_36_45   0.193    0.193   0.193   0.193     0.193  94 aled      temp_11_20:temp_gt_45   0.419    0.419   0.419   0.419     0.419  95 aled      temp_11_20:ppt          0.162    0.162   0.162   0.162     0.162  96 aled      temp_11_20:whc          0.204    0.204   0.204   0.204     0.204  97 aled      temp_11_20:sand         0.123    0.123   0.123   0.123     0.123  98 aled      temp_11_20:silt         0.098    0.098   0.098   0.098     0.098  99 aled      temp_11_20:clay         0.0908   0.0908  0.0908  0.0908    0.0908 100 aled      temp_11_20:om           0.297    0.297   0.297   0.297     0.297 # ℹ 320 more rows # A tibble: 0 × 0 # SLOW: uncomment to run yourself; load the saved object for rapid execution  # # p-value distribution # # Default 1000 iterations for exact p-values # tic() # pd_rf_corn <- ALEpDist( #   rf_corn, corn_data,  #   rand_it = 1000, #   parallel = 0 # ) # toc() # # My timing here is inaccurate because my computer kept on going to sleep. # # 33482.34 sec elapsed (558 minutes = 9.3 hours) # # It should probably have taken around 3 hours on my computer. # # saveRDS(pd_rf_corn, file.choose())  pd_rf_corn <- serialized_objects_site |>    file.path(\"pd_rf_corn.rds\") |>   url() |>    readRDS() lsd_rf <-  pd_rf_corn@rand_stats$corn |>    ale:::p_to_random_value('aled', 0.05) |>   unname()  lsd_vars <- ale_single_rf_corn |>    get(stats = 'estimate') |>    bind_rows() |>    filter(aled >= lsd_rf) |>    pull(term) # Create variable lists to focus on vars_aled_1 <- ale_single_rf_corn |>    get(stats = 'estimate') |>    bind_rows() |>    filter(aled >= 1) |>    pull(term) # SLOW: uncomment to run yourself; load the saved object for rapid execution  # # Data-only bootstrapping for a slow-training, cross-validated model. # # ALE only for focal variables # tic() # ale_boot_rf_corn <- ALE( #   rf_corn, #   # Compute ALE for terms (1D and 2D) with ALED >= 1 #   x_cols = vars_aled_1, #   data = corn_data, #   p_values = pd_rf_corn, #   boot_it = 100,  # bootstrap iterations #   silent = FALSE, #   parallel = 0 # ) # toc()  # 6021.25 sec elapsed (100 minutes) # # saveRDS(ale_boot_rf_corn, file.choose())  ale_boot_rf_corn <- serialized_objects_site |>    file.path(\"ale_boot_rf_corn.rds\") |>   url() |>    readRDS()  summary(ale_boot_rf_corn) # A tibble: 16 × 7    term                   aled aler_min aler_max naled naler_min naler_max    <chr>                 <dbl>    <dbl>    <dbl> <dbl>     <dbl>     <dbl>  1 year                  10.9   -15.2      27.3  11.1    -16.5       25.5  2 ag_km2                 2.02   -5.85      2.68  2.41    -6.41       2.91  3 temp_lt_00             1.36   -6.99      2.66  1.75    -7.61       2.89  4 temp_00_10             1.28   -4.39      1.86  1.70    -4.58       2.12  5 temp_21_30             4.19  -17.7       8.37  4.59   -18.5        8.63  6 temp_31_35             4.57  -11.1       6.33  4.94   -11.9        6.84  7 temp_36_45             4.75  -14.7       5.31  5.31   -15.2        5.92  8 ppt                    1.06   -3.00      1.35  1.48    -3.32       1.86  9 whc                    2.15   -3.55      5.99  2.56    -3.79       6.43 10 silt                   1.27   -2.17      2.40  1.64    -2.68       2.80 11 clay                   1.10   -2.13      1.14  1.53    -2.64       1.79 12 kwfactor               2.11   -2.80      4.69  2.49    -2.99       4.77 13 spH                    2.08   -3.70      4.71  2.43    -3.85       4.83 14 tfactor                1.92   -3.15     10.6   2.32    -3.61      10.8 15 year:temp_gt_45        1.62   -2.00      1.93  2.04    -2.39       2.27 16 temp_00_10:temp_gt_45  1.65   -0.236     2.46  2.03    -0.838      2.79 # A tibble: 32 × 8    statistic term               estimate p.value conf.low  mean median conf.high    <ord>     <chr>                 <dbl>   <dbl>    <dbl> <dbl>  <dbl>     <dbl>  1 aled      year                  10.9        0   10.8   10.9   10.9      11.0  2 aled      ag_km2                 2.02       0    1.95   2.02   2.01      2.07  3 aled      temp_lt_00             1.36       0    1.31   1.36   1.36      1.42  4 aled      temp_00_10             1.28       0    1.24   1.28   1.28      1.31  5 aled      temp_21_30             4.19       0    4.09   4.19   4.20      4.28  6 aled      temp_31_35             4.57       0    4.51   4.57   4.57      4.63  7 aled      temp_36_45             4.75       0    4.69   4.75   4.75      4.80  8 aled      ppt                    1.06       0    1.01   1.06   1.06      1.11  9 aled      whc                    2.15       0    2.12   2.15   2.16      2.19 10 aled      silt                   1.27       0    1.23   1.27   1.27      1.32 11 aled      clay                   1.10       0    1.07   1.10   1.10      1.13 12 aled      kwfactor               2.11       0    2.08   2.11   2.12      2.15 13 aled      spH                    2.08       0    1.99   2.08   2.08      2.19 14 aled      tfactor                1.92       0    1.89   1.92   1.92      1.95 15 aled      year:temp_gt_45        1.62       0    1.26   1.62   1.62      1.99 16 aled      temp_00_10:temp_g…     1.65       0    0.612  1.65   1.67      2.48 17 naled     year                  11.1        0   11.0   11.1   11.2      11.3 18 naled     ag_km2                 2.41       0    2.38   2.41   2.41      2.43 19 naled     temp_lt_00             1.75       0    1.67   1.75   1.75      1.89 20 naled     temp_00_10             1.70       0    1.60   1.70   1.72      1.73 21 naled     temp_21_30             4.59       0    4.37   4.59   4.61      4.74 22 naled     temp_31_35             4.94       0    4.83   4.94   4.91      5.08 23 naled     temp_36_45             5.31       0    5.07   5.31   5.37      5.40 24 naled     ppt                    1.48       0    1.40   1.48   1.50      1.56 25 naled     whc                    2.56       0    2.55   2.56   2.56      2.58 26 naled     silt                   1.64       0    1.55   1.64   1.63      1.76 27 naled     clay                   1.53       0    1.43   1.53   1.50      1.65 28 naled     kwfactor               2.49       0    2.43   2.49   2.50      2.57 29 naled     spH                    2.43       0    2.37   2.43   2.41      2.54 30 naled     tfactor                2.32       0    2.28   2.32   2.31      2.37 31 naled     year:temp_gt_45        2.04       0    1.69   2.04   2.02      2.41 32 naled     temp_00_10:temp_g…     2.03       0    0.959  2.03   2.03      2.78 # A tibble: 46 × 10    term          start_x   end_x x_span_pct     n     pct start_y end_y    trend    <chr>           <dbl>   <dbl>      <dbl> <int>   <dbl>   <dbl> <dbl>    <dbl>  1 year          1.98e+3 1.99e+3     32.4   41855 4.65e+1    89.8  99.1  0.172  2 year          1.99e+3 2.02e+3     61.8   48155 5.35e+1   106.  132.   0.253  3 ag_km2        4.81e-1 4.09e+2      7.79  30006 3.33e+1    99.2 104.   0.387  4 ag_km2        5.71e+2 5.71e+2      0     10000 1.11e+1   105.  105.   0  5 ag_km2        7.55e+2 5.24e+3     85.6   50004 5.56e+1   106.  107.   0.00465  6 temp_lt_00    0       7.47e+0     14.2   60007 6.67e+1   108.  106.  -0.0744  7 temp_lt_00    1.06e+1 1.06e+1      0     10001 1.11e+1   105.  105.   0  8 temp_lt_00    1.50e+1 5.27e+1     71.6   20002 2.22e+1   103.   98.0 -0.0378  9 temp_00_10    5.76e-4 5.76e-4      0         1 1.11e-3   105.  105.   0 10 temp_00_10    1.03e+1 1.76e+1     10.6   20002 2.22e+1   103.  104.   0.0835 11 temp_00_10    2.31e+1 3.46e+1     16.8   40004 4.44e+1   106.  106.   0.00787 12 temp_00_10    3.81e+1 3.81e+1      0     10001 1.11e+1   105.  105.   0 13 temp_00_10    4.21e+1 6.88e+1     38.9   20002 2.22e+1   104.  101.  -0.0543 14 temp_21_30    1.08e+1 6.45e+1     45.6   20003 2.22e+1    87.3 102.   0.198 15 temp_21_30    7.00e+1 7.00e+1      0     10001 1.11e+1   104.  104.   0 16 temp_21_30    7.52e+1 1.29e+2     45.3   60006 6.67e+1   106.  113.   0.0999 17 temp_31_35    0       1.19e+1     17.0   40005 4.44e+1   110.  107.  -0.104 18 temp_31_35    1.59e+1 6.98e+1     77.2   50005 5.56e+1   104.   93.9 -0.0799 19 temp_36_45    0       4.77e-1      0.750 50007 5.56e+1   110.  106.  -3.55 20 temp_36_45    1.17e+0 6.36e+1     98.2   40003 4.44e+1   103.   90.3 -0.0762 21 ppt           9.43e-1 9.43e-1      0         1 1.11e-3   106.  106.   0 22 ppt           3.91e+2 4.90e+2      6.20  20002 2.22e+1   102.  104.   0.149 23 ppt           5.52e+2 5.52e+2      0     10001 1.11e+1   105.  105.   0 24 ppt           6.04e+2 8.70e+2     16.6   50005 5.56e+1   106.  106.   0.0255 25 ppt           1.60e+3 1.60e+3      0     10001 1.11e+1   102.  102.   0 26 whc           9.70e+0 2.56e+1     46.6   50008 5.56e+1   101.  104.   0.0358 27 whc           2.71e+1 2.71e+1      0     10001 1.11e+1   105.  105.   0 28 whc           2.92e+1 4.38e+1     42.6   30001 3.33e+1   107.  111.   0.0569 29 silt          2.63e+0 3.41e+1     43.1   30006 3.33e+1   103.  104.   0.0113 30 silt          3.86e+1 3.86e+1      0     10005 1.11e+1   105.  105.   0 31 silt          4.33e+1 7.55e+1     44.3   49999 5.55e+1   105.  107.   0.0212 32 clay          1.17e+0 2.76e+1     45.9   50018 5.56e+1   106.  106.  -0.00514 33 clay          3.00e+1 3.00e+1      0      9990 1.11e+1   105.  105.   0 34 clay          3.38e+1 5.87e+1     43.4   30002 3.33e+1   103.  103.   0.00284 35 kwfactor      4.58e-2 2.71e-1     44.0   30010 3.33e+1   103.  103.   0.00150 36 kwfactor      2.97e-1 2.97e-1      0     10000 1.11e+1   104.  104.   0 37 kwfactor      3.17e-1 3.17e-1      0     10001 1.11e+1   104.  104.   0 38 kwfactor      3.41e-1 3.41e-1      0      9998 1.11e+1   104.  104.   0 39 kwfactor      3.75e-1 5.58e-1     35.8   30001 3.33e+1   108.  109.   0.0154 40 spH           4.63e+0 5.33e+0     17.5   20009 2.22e+1   102.  101.  -0.00902 41 spH           5.67e+0 5.67e+0      0      9995 1.11e+1   105.  105.   0 42 spH           6.12e+0 7.33e+0     30.5   40008 4.44e+1   106.  109.   0.0608 43 spH           7.69e+0 7.69e+0      0      9999 1.11e+1   103.  103.   0 44 spH           8.60e+0 8.60e+0      0      9999 1.11e+1   110.  110.   0 45 tfactor       2.26e+0 4.60e+0     85.4   50020 5.56e+1   102.  104.   0.0164 46 tfactor       4.73e+0 5   e+0      9.71  39990 4.44e+1   105.  116.   0.637 # ℹ 1 more variable: aler_band <ord> ale_boot_rf_corn |>    plot() |>  # create ALEPlots object   subset(list(d1 = TRUE)) |>  # subset only for 1D plots   customize(zoom_y = c(85, 135)) |>   # zoom on the y-axis   print(ncol = 2) ale_boot_rf_corn |>    plot() |>  # create ALEPlots object   subset(list(d2 = TRUE)) |>   # subset only for 2D plots   print(ncol = 1)"},{"path":"https://tripartio.github.io/ale/articles/ale-acdc-corn.html","id":"full-ale-results-all-main-effects-and-interactions","dir":"Articles","previous_headings":"","what":"Full ALE results: all main effects and interactions","title":"Analyzing a Large Corn Yield Dataset with ALE-Based Inference","text":"First, estimate 20 main effects, one predictor. part straightforward. computational weight comes interactions. 20 predictors, number unique pairwise combinations 190, giving total 210 ALE calculations. takes random forest around 17 minutes. worth emphasizing works practice. default ranger settings (500 trees), task take roughly ten times longer; reduction 50 trees (feasible large dataset) renders type comprehensive interaction analysis feasible. initial ALE run produces large set results (210 terms), immediate practical problem triage: effects large enough justify deeper inspection bootstrapping? dataset big, non-bootstrapped results often close bootstrapped ones, analysis want stand behind, still need bootstrapping. catch compute time. Even 100 bootstrap iterations (bare minimum stable inference, still modest publication) multiplies runtime roughly 100. single pass takes order minutes, blindly bootstrapping every term practical, especially many effects visibly tiny. ALE summary statistics earn keep. Instead paging 210 plots guessing matters, use effect-size summaries ALE deviation (ALED) identify small number terms plausibly meaningful. explain ALE statistics detail another article.","code":"# SLOW: uncomment to run yourself; load the saved object for rapid execution  # # ALE for all 1D and 2D variables # tic() # ale_single_rf_corn <- ALE( #   rf_corn, #   # d1=TRUE: all 1D variables (main effects): d2=TRUE: all 2D interactions #   x_cols = list(d1 = TRUE, d2 = TRUE), #   data = corn_data, #   parallel = 0 # ) # toc()   # # 21 1D ALE + 210 2D ALE: 1032.01 sec elapsed (17.2 minutes) # # saveRDS(ale_single_rf_corn, file.choose())  ale_single_rf_corn <- serialized_objects_site |>    file.path(\"ale_single_rf_corn.rds\") |>   url() |>    readRDS()  summary(ale_single_rf_corn) # A tibble: 210 × 7     term                     aled aler_min aler_max  naled naler_min naler_max     <chr>                   <dbl>    <dbl>    <dbl>  <dbl>     <dbl>     <dbl>   1 year                  10.9     -15.2     27.4   11.2     -16.5      25.5   2 ag_km2                 2.01     -5.85     2.68   2.40     -6.41      2.89   3 temp_lt_00             1.36     -7.00     2.66   1.69     -7.37      2.89   4 temp_00_10             1.28     -4.40     1.86   1.72     -4.56      2.09   5 temp_11_20             0.750    -4.49     1.73   1.12     -4.60      2.04   6 temp_21_30             4.20    -17.7      8.39   4.61    -18.5       8.63   7 temp_31_35             4.57    -11.1      6.33   4.91    -12.0       6.85   8 temp_36_45             4.75    -14.7      5.31   5.38    -15.2       5.92   9 temp_gt_45             0        -1.74     1.74   0        -2.03      2.04  10 ppt                    1.05     -3.00     1.31   1.50     -3.05      1.87  11 whc                    2.15     -3.55     5.99   2.56     -3.79      6.20  12 sand                   0.166    -0.751    1.21   0.583    -1.09      1.83  13 silt                   1.27     -2.18     2.39   1.57     -2.67      2.78  14 clay                   1.10     -2.13     1.14   1.49     -2.67      1.80  15 om                     0.786    -2.20     1.56   1.27     -2.67      1.93  16 kwfactor               2.12     -2.80     4.69   2.51     -3.01      4.75  17 kffactor               0.292    -0.746    1.08   0.817    -1.09      1.74  18 spH                    2.07     -3.70     4.69   2.40     -3.84      4.75  19 slope                  0.825    -1.36     2.63   1.30     -1.85      2.89  20 tfactor                1.92     -3.15    10.6    2.30     -3.61     10.8  21 year:ag_km2            0.484    -1.40     1.30   0.957    -1.85      1.83  22 year:temp_lt_00        0.707    -4.07     2.90   1.10     -4.45      3.04  23 year:temp_00_10        0.484    -1.24     1.20   0.955    -1.82      1.80  24 year:temp_11_20        0.616    -4.26     2.13   1.07     -4.53      2.70  25 year:temp_21_30        0.443    -1.20     2.04   0.897    -1.75      2.65  26 year:temp_31_35        0.824    -3.10     2.05   1.26     -3.56      2.65  27 year:temp_36_45        0.602    -4.72     1.73   1.07     -4.75      2.04  28 year:temp_gt_45        1.63     -1.99     1.93   1.99     -2.11      2.15  29 year:ppt               0.581    -3.49     1.52   1.01     -3.74      1.93  30 year:whc               0.254    -1.20     0.612  0.699    -1.82      1.06  31 year:sand              0.348    -2.08     1.12   0.765    -2.61      1.80  32 year:silt              0.140    -0.583    0.416  0.532    -1.01      0.965  33 year:clay              0.139    -0.573    0.349  0.486    -1.01      0.930  34 year:om                0.290    -0.958    1.07   0.746    -1.16      1.74  35 year:kwfactor          0.265    -0.733    0.946  0.672    -1.09      1.20  36 year:kffactor          0.195    -0.760    0.554  0.602    -1.09      1.01  37 year:spH               0.578    -2.94     1.57   1.00     -3.05      1.93  38 year:slope             0.518    -2.48     2.18   0.915    -2.81      2.70  39 year:tfactor           0.336    -1.09     1.03   0.797    -1.70      1.74  40 ag_km2:temp_lt_00      0.207    -0.535    1.88   0.627    -1.01      2.09  41 ag_km2:temp_00_10      0.152    -0.592    0.55   0.496    -1.01      1.01  42 ag_km2:temp_11_20      0.195    -1.23     0.736  0.534    -1.82      1.10  43 ag_km2:temp_21_30      0.199    -1.08     1.59   0.555    -1.70      1.93  44 ag_km2:temp_31_35      0.236    -1.08     0.679  0.655    -1.70      1.06  45 ag_km2:temp_36_45      0.203    -0.545    0.985  0.649    -1.01      1.20  46 ag_km2:temp_gt_45      0.512    -0.940    0.514  0.985    -1.16      1.01  47 ag_km2:ppt             0.144    -1.25     0.473  0.27     -1.82      0.965  48 ag_km2:whc             0.236    -0.832    1.15   0.631    -1.11      1.80  49 ag_km2:sand            0.142    -0.393    0.551  0.484    -0.921     1.01  50 ag_km2:silt            0.183    -0.462    0.834  0.533    -0.957     1.15  51 ag_km2:clay            0.150    -0.484    0.604  0.488    -0.957     1.06  52 ag_km2:om              0.191    -0.416    2.42   0.551    -0.957     2.81  53 ag_km2:kwfactor        0.122    -0.564    0.394  0.494    -1.01      0.930  54 ag_km2:kffactor        0.220    -0.709    1.18   0.610    -1.09      1.80  55 ag_km2:spH             0.205    -0.527    1.46   0.613    -1.01      1.89  56 ag_km2:slope           0.128    -0.739    0.657  0.352    -1.09      1.06  57 ag_km2:tfactor         0.186    -0.846    0.903  0.545    -1.11      1.20  58 temp_lt_00:temp_00_10  0.200    -1.37     2.93   0.668    -1.85      3.04  59 temp_lt_00:temp_11_20  0.240    -0.431    1.75   0.699    -0.957     2.04  60 temp_lt_00:temp_21_30  0.317    -0.620    1.88   0.788    -1.05      2.09  61 temp_lt_00:temp_31_35  0.120    -2.34     2.52   0.426    -2.77      2.86  62 temp_lt_00:temp_36_45  0.173    -0.555    1.88   0.546    -1.01      2.09  63 temp_lt_00:temp_gt_45  0.546    -0.496    1.32   1.06     -0.957     1.87  64 temp_lt_00:ppt         0.324    -1.54     2.46   0.722    -1.93      2.81  65 temp_lt_00:whc         0.106    -0.676    0.362  0.359    -1.05      0.930  66 temp_lt_00:sand        0.0843   -0.455    0.622  0.233    -0.957     1.06  67 temp_lt_00:silt        0.0951   -0.204    0.724  0.259    -0.876     1.10  68 temp_lt_00:clay        0.155    -0.551    0.878  0.445    -1.01      1.15  69 temp_lt_00:om          0.125    -0.349    1.90   0.417    -0.921     2.15  70 temp_lt_00:kwfactor    0.123    -0.262    0.612  0.424    -0.876     1.06  71 temp_lt_00:kffactor    0.101    -0.360    0.585  0.258    -0.921     1.01  72 temp_lt_00:spH         0.228    -0.567    1.96   0.662    -1.01      2.15  73 temp_lt_00:slope       0.0907   -0.271    0.405  0.266    -0.876     0.965  74 temp_lt_00:tfactor     0.0978   -0.551    0.345  0.353    -1.01      0.930  75 temp_00_10:temp_11_20  0.160    -0.404    2.48   0.442    -0.957     2.81  76 temp_00_10:temp_21_30  0.261    -1.05     3.11   0.760    -1.70      3.62  77 temp_00_10:temp_31_35  0.168    -0.662    2.37   0.598    -1.05      2.78  78 temp_00_10:temp_36_45  0.274    -1.45     2.02   0.739    -1.90      2.65  79 temp_00_10:temp_gt_45  1.68     -0.255    2.50   2.03     -0.876     2.86  80 temp_00_10:ppt         0.224    -0.616    2.20   0.616    -1.05      2.75  81 temp_00_10:whc         0.0818   -0.371    0.468  0.245    -0.921     0.965  82 temp_00_10:sand        0.135    -0.495    1.01   0.415    -0.957     1.74  83 temp_00_10:silt        0.226    -0.970    1.02   0.527    -1.16      1.74  84 temp_00_10:clay        0.205    -1.12     0.704  0.630    -1.75      1.10  85 temp_00_10:om          0.0836   -0.565    0.508  0.245    -1.01      1.01  86 temp_00_10:kwfactor    0.177    -0.604    0.714  0.616    -1.05      1.10  87 temp_00_10:kffactor    0.125    -0.565    0.728  0.302    -1.01      1.10  88 temp_00_10:spH         0.151    -0.352    0.771  0.554    -0.921     1.10  89 temp_00_10:slope       0.106    -0.362    0.393  0.311    -0.921     0.930  90 temp_00_10:tfactor     0.105    -0.91     0.435  0.286    -1.16      0.965  91 temp_11_20:temp_21_30  0.304    -1.87     1.21   0.745    -2.06      1.83  92 temp_11_20:temp_31_35  0.208    -1.52     3.38   0.629    -1.93      3.69  93 temp_11_20:temp_36_45  0.193    -1.22     2.83   0.598    -1.82      2.99  94 temp_11_20:temp_gt_45  0.419    -0.797    0.546  0.869    -1.09      1.01  95 temp_11_20:ppt         0.162    -1.31     0.577  0.428    -1.85      1.01  96 temp_11_20:whc         0.204    -0.934    2.04   0.537    -1.16      2.65  97 temp_11_20:sand        0.123    -0.385    0.358  0.426    -0.921     0.930  98 temp_11_20:silt        0.098    -0.382    0.551  0.297    -0.921     1.01  99 temp_11_20:clay        0.0908   -0.604    0.361  0.295    -1.05      0.930 100 temp_11_20:om          0.297    -1.38     0.831  0.774    -1.85      1.15 # ℹ 110 more rows # A tibble: 420 × 7     statistic term                  estimate conf.low    mean  median conf.high     <ord>     <chr>                    <dbl>    <dbl>   <dbl>   <dbl>     <dbl>   1 aled      year                   10.9     10.9    10.9    10.9      10.9   2 aled      ag_km2                  2.01     2.01    2.01    2.01      2.01   3 aled      temp_lt_00              1.36     1.36    1.36    1.36      1.36   4 aled      temp_00_10              1.28     1.28    1.28    1.28      1.28   5 aled      temp_11_20              0.750    0.750   0.750   0.750     0.750   6 aled      temp_21_30              4.20     4.20    4.20    4.20      4.20   7 aled      temp_31_35              4.57     4.57    4.57    4.57      4.57   8 aled      temp_36_45              4.75     4.75    4.75    4.75      4.75   9 aled      temp_gt_45              0        0       0       0         0  10 aled      ppt                     1.05     1.05    1.05    1.05      1.05  11 aled      whc                     2.15     2.15    2.15    2.15      2.15  12 aled      sand                    0.166    0.166   0.166   0.166     0.166  13 aled      silt                    1.27     1.27    1.27    1.27      1.27  14 aled      clay                    1.10     1.10    1.10    1.10      1.10  15 aled      om                      0.786    0.786   0.786   0.786     0.786  16 aled      kwfactor                2.12     2.12    2.12    2.12      2.12  17 aled      kffactor                0.292    0.292   0.292   0.292     0.292  18 aled      spH                     2.07     2.07    2.07    2.07      2.07  19 aled      slope                   0.825    0.825   0.825   0.825     0.825  20 aled      tfactor                 1.92     1.92    1.92    1.92      1.92  21 aled      year:ag_km2             0.484    0.484   0.484   0.484     0.484  22 aled      year:temp_lt_00         0.707    0.707   0.707   0.707     0.707  23 aled      year:temp_00_10         0.484    0.484   0.484   0.484     0.484  24 aled      year:temp_11_20         0.616    0.616   0.616   0.616     0.616  25 aled      year:temp_21_30         0.443    0.443   0.443   0.443     0.443  26 aled      year:temp_31_35         0.824    0.824   0.824   0.824     0.824  27 aled      year:temp_36_45         0.602    0.602   0.602   0.602     0.602  28 aled      year:temp_gt_45         1.63     1.63    1.63    1.63      1.63  29 aled      year:ppt                0.581    0.581   0.581   0.581     0.581  30 aled      year:whc                0.254    0.254   0.254   0.254     0.254  31 aled      year:sand               0.348    0.348   0.348   0.348     0.348  32 aled      year:silt               0.140    0.140   0.140   0.140     0.140  33 aled      year:clay               0.139    0.139   0.139   0.139     0.139  34 aled      year:om                 0.290    0.290   0.290   0.290     0.290  35 aled      year:kwfactor           0.265    0.265   0.265   0.265     0.265  36 aled      year:kffactor           0.195    0.195   0.195   0.195     0.195  37 aled      year:spH                0.578    0.578   0.578   0.578     0.578  38 aled      year:slope              0.518    0.518   0.518   0.518     0.518  39 aled      year:tfactor            0.336    0.336   0.336   0.336     0.336  40 aled      ag_km2:temp_lt_00       0.207    0.207   0.207   0.207     0.207  41 aled      ag_km2:temp_00_10       0.152    0.152   0.152   0.152     0.152  42 aled      ag_km2:temp_11_20       0.195    0.195   0.195   0.195     0.195  43 aled      ag_km2:temp_21_30       0.199    0.199   0.199   0.199     0.199  44 aled      ag_km2:temp_31_35       0.236    0.236   0.236   0.236     0.236  45 aled      ag_km2:temp_36_45       0.203    0.203   0.203   0.203     0.203  46 aled      ag_km2:temp_gt_45       0.512    0.512   0.512   0.512     0.512  47 aled      ag_km2:ppt              0.144    0.144   0.144   0.144     0.144  48 aled      ag_km2:whc              0.236    0.236   0.236   0.236     0.236  49 aled      ag_km2:sand             0.142    0.142   0.142   0.142     0.142  50 aled      ag_km2:silt             0.183    0.183   0.183   0.183     0.183  51 aled      ag_km2:clay             0.150    0.150   0.150   0.150     0.150  52 aled      ag_km2:om               0.191    0.191   0.191   0.191     0.191  53 aled      ag_km2:kwfactor         0.122    0.122   0.122   0.122     0.122  54 aled      ag_km2:kffactor         0.220    0.220   0.220   0.220     0.220  55 aled      ag_km2:spH              0.205    0.205   0.205   0.205     0.205  56 aled      ag_km2:slope            0.128    0.128   0.128   0.128     0.128  57 aled      ag_km2:tfactor          0.186    0.186   0.186   0.186     0.186  58 aled      temp_lt_00:temp_00_10   0.200    0.200   0.200   0.200     0.200  59 aled      temp_lt_00:temp_11_20   0.240    0.240   0.240   0.240     0.240  60 aled      temp_lt_00:temp_21_30   0.317    0.317   0.317   0.317     0.317  61 aled      temp_lt_00:temp_31_35   0.120    0.120   0.120   0.120     0.120  62 aled      temp_lt_00:temp_36_45   0.173    0.173   0.173   0.173     0.173  63 aled      temp_lt_00:temp_gt_45   0.546    0.546   0.546   0.546     0.546  64 aled      temp_lt_00:ppt          0.324    0.324   0.324   0.324     0.324  65 aled      temp_lt_00:whc          0.106    0.106   0.106   0.106     0.106  66 aled      temp_lt_00:sand         0.0843   0.0843  0.0843  0.0843    0.0843  67 aled      temp_lt_00:silt         0.0951   0.0951  0.0951  0.0951    0.0951  68 aled      temp_lt_00:clay         0.155    0.155   0.155   0.155     0.155  69 aled      temp_lt_00:om           0.125    0.125   0.125   0.125     0.125  70 aled      temp_lt_00:kwfactor     0.123    0.123   0.123   0.123     0.123  71 aled      temp_lt_00:kffactor     0.101    0.101   0.101   0.101     0.101  72 aled      temp_lt_00:spH          0.228    0.228   0.228   0.228     0.228  73 aled      temp_lt_00:slope        0.0907   0.0907  0.0907  0.0907    0.0907  74 aled      temp_lt_00:tfactor      0.0978   0.0978  0.0978  0.0978    0.0978  75 aled      temp_00_10:temp_11_20   0.160    0.160   0.160   0.160     0.160  76 aled      temp_00_10:temp_21_30   0.261    0.261   0.261   0.261     0.261  77 aled      temp_00_10:temp_31_35   0.168    0.168   0.168   0.168     0.168  78 aled      temp_00_10:temp_36_45   0.274    0.274   0.274   0.274     0.274  79 aled      temp_00_10:temp_gt_45   1.68     1.68    1.68    1.68      1.68  80 aled      temp_00_10:ppt          0.224    0.224   0.224   0.224     0.224  81 aled      temp_00_10:whc          0.0818   0.0818  0.0818  0.0818    0.0818  82 aled      temp_00_10:sand         0.135    0.135   0.135   0.135     0.135  83 aled      temp_00_10:silt         0.226    0.226   0.226   0.226     0.226  84 aled      temp_00_10:clay         0.205    0.205   0.205   0.205     0.205  85 aled      temp_00_10:om           0.0836   0.0836  0.0836  0.0836    0.0836  86 aled      temp_00_10:kwfactor     0.177    0.177   0.177   0.177     0.177  87 aled      temp_00_10:kffactor     0.125    0.125   0.125   0.125     0.125  88 aled      temp_00_10:spH          0.151    0.151   0.151   0.151     0.151  89 aled      temp_00_10:slope        0.106    0.106   0.106   0.106     0.106  90 aled      temp_00_10:tfactor      0.105    0.105   0.105   0.105     0.105  91 aled      temp_11_20:temp_21_30   0.304    0.304   0.304   0.304     0.304  92 aled      temp_11_20:temp_31_35   0.208    0.208   0.208   0.208     0.208  93 aled      temp_11_20:temp_36_45   0.193    0.193   0.193   0.193     0.193  94 aled      temp_11_20:temp_gt_45   0.419    0.419   0.419   0.419     0.419  95 aled      temp_11_20:ppt          0.162    0.162   0.162   0.162     0.162  96 aled      temp_11_20:whc          0.204    0.204   0.204   0.204     0.204  97 aled      temp_11_20:sand         0.123    0.123   0.123   0.123     0.123  98 aled      temp_11_20:silt         0.098    0.098   0.098   0.098     0.098  99 aled      temp_11_20:clay         0.0908   0.0908  0.0908  0.0908    0.0908 100 aled      temp_11_20:om           0.297    0.297   0.297   0.297     0.297 # ℹ 320 more rows # A tibble: 0 × 0"},{"path":"https://tripartio.github.io/ale/articles/ale-acdc-corn.html","id":"statistical-reliability-vs-practical-importance","dir":"Articles","previous_headings":"","what":"Statistical reliability vs practical importance","title":"Analyzing a Large Corn Yield Dataset with ALE-Based Inference","text":"stage, usual “statistically significant?” question wrong tool. roughly 90,000 observations, estimated effects statistically reliable (therefore often statistically significant) whether matter real world. Reliability tells us estimate stable; tell us important. actually need effect-size yardstick. corn yield, managerial question simple stubborn: large change yield (bushels per acre) care? 1 bushel/acre swing meaningful, need something like 5 bushels/acre rises noise real decisions? something p-value can answer. common attempt dodge decision “least significant difference” (LSD) idea: translate p-value threshold (often 0.05) equivalent difference y-scale. large samples, typically produces vanishingly small threshold, mathematically consistent practically useless. example, LSD 90,000-row corn_data dataset rf_corn model 0.05 p-value level piddling 0.07 bu/ac. words, re-labels statistical reliability “importance” without solving real problem. Using LSD criterion dataset result selecting 205out 210 variables. end, domain expertise set practical threshold. role provide effect-size estimates interpretable original scale (bushels per acre), experts can decide counts meaningful. case, somewhat arbitrarily assume threshold 2 bu/ac (125.5 kg/ha) practically meaningful threshold. Since non-bootstrapped ALE results precise, use cut-half value (, 1 bu/ac) ALED variables select analysis. cutoff focuses 14 main effects 2 interactions.","code":"# SLOW: uncomment to run yourself; load the saved object for rapid execution  # # p-value distribution # # Default 1000 iterations for exact p-values # tic() # pd_rf_corn <- ALEpDist( #   rf_corn, corn_data,  #   rand_it = 1000, #   parallel = 0 # ) # toc() # # My timing here is inaccurate because my computer kept on going to sleep. # # 33482.34 sec elapsed (558 minutes = 9.3 hours) # # It should probably have taken around 3 hours on my computer. # # saveRDS(pd_rf_corn, file.choose())  pd_rf_corn <- serialized_objects_site |>    file.path(\"pd_rf_corn.rds\") |>   url() |>    readRDS() lsd_rf <-  pd_rf_corn@rand_stats$corn |>    ale:::p_to_random_value('aled', 0.05) |>   unname()  lsd_vars <- ale_single_rf_corn |>    get(stats = 'estimate') |>    bind_rows() |>    filter(aled >= lsd_rf) |>    pull(term)"},{"path":"https://tripartio.github.io/ale/articles/ale-acdc-corn.html","id":"data-only-bootstrapped-ale-results-on-focal-variables","dir":"Articles","previous_headings":"","what":"Data-only bootstrapped ALE results on focal variables","title":"Analyzing a Large Corn Yield Dataset with ALE-Based Inference","text":"Statistical results (ALE otherwise) generally reliable bootstrap . dataset large training ALE calculation times lengthy, use data-bootstrapping, faster approach resamples ALE calculation data without retraining model. appropriate approach large datasets slow models already validated cross-validation, case. explain difference bootstrap approaches article ALE statistics inference. default, use 100 bootstrap iterations. publication, increase number, analysis, 100 iterations typically sufficient lead conclusions, especially large dataset. bootstrapping, let’s first generate ALE p-value distribution. slowest step ALE analysis relies simulation rather parametric assumptions. can use p-value distribution data-bootstrapping procedure {ale} package, specifying boot_it argument ALE() constructor. specifically request ALE filtered set variables meet 1 bu/ac threshold ALED. bootstrap process ALE results become reliable. bootstrapped ALED results closely match non-bootstrapped results, expect dataset size: even single ALE computation usually quite reliable. Bootstrapping mainly serves two purposes . First, confirms ranking larger effects stable. Second, reassures us small ALED values really small, rather artifacts single run. confirmation, interpretation fairly direct. Year far strongest effect: across roughly 35-year span study, average range 11 bushels per acre. Next, several temperature ranges show largest climate effects, notably 21–30°C, 31–35°C, 36–45°C, exceeding 4 bushels per acre effect size. Agricultural land area (ag_km2) also practically important. Among soil variables, water holding capacity (whc), K/W factor (kwfactor), soil pH (spH) clear practical-importance threshold 2. interactions, neither two bootstrapped interactions exceeds practical threshold 2. matters means can interpret main-effect ALE plots largely terms: interactions exist model, appear strong enough (scale) meaningfully distort main-effect conclusions.","code":"# Create variable lists to focus on vars_aled_1 <- ale_single_rf_corn |>    get(stats = 'estimate') |>    bind_rows() |>    filter(aled >= 1) |>    pull(term) # SLOW: uncomment to run yourself; load the saved object for rapid execution  # # Data-only bootstrapping for a slow-training, cross-validated model. # # ALE only for focal variables # tic() # ale_boot_rf_corn <- ALE( #   rf_corn, #   # Compute ALE for terms (1D and 2D) with ALED >= 1 #   x_cols = vars_aled_1, #   data = corn_data, #   p_values = pd_rf_corn, #   boot_it = 100,  # bootstrap iterations #   silent = FALSE, #   parallel = 0 # ) # toc()  # 6021.25 sec elapsed (100 minutes) # # saveRDS(ale_boot_rf_corn, file.choose())  ale_boot_rf_corn <- serialized_objects_site |>    file.path(\"ale_boot_rf_corn.rds\") |>   url() |>    readRDS()  summary(ale_boot_rf_corn) # A tibble: 16 × 7    term                   aled aler_min aler_max naled naler_min naler_max    <chr>                 <dbl>    <dbl>    <dbl> <dbl>     <dbl>     <dbl>  1 year                  10.9   -15.2      27.3  11.1    -16.5       25.5  2 ag_km2                 2.02   -5.85      2.68  2.41    -6.41       2.91  3 temp_lt_00             1.36   -6.99      2.66  1.75    -7.61       2.89  4 temp_00_10             1.28   -4.39      1.86  1.70    -4.58       2.12  5 temp_21_30             4.19  -17.7       8.37  4.59   -18.5        8.63  6 temp_31_35             4.57  -11.1       6.33  4.94   -11.9        6.84  7 temp_36_45             4.75  -14.7       5.31  5.31   -15.2        5.92  8 ppt                    1.06   -3.00      1.35  1.48    -3.32       1.86  9 whc                    2.15   -3.55      5.99  2.56    -3.79       6.43 10 silt                   1.27   -2.17      2.40  1.64    -2.68       2.80 11 clay                   1.10   -2.13      1.14  1.53    -2.64       1.79 12 kwfactor               2.11   -2.80      4.69  2.49    -2.99       4.77 13 spH                    2.08   -3.70      4.71  2.43    -3.85       4.83 14 tfactor                1.92   -3.15     10.6   2.32    -3.61      10.8 15 year:temp_gt_45        1.62   -2.00      1.93  2.04    -2.39       2.27 16 temp_00_10:temp_gt_45  1.65   -0.236     2.46  2.03    -0.838      2.79 # A tibble: 32 × 8    statistic term               estimate p.value conf.low  mean median conf.high    <ord>     <chr>                 <dbl>   <dbl>    <dbl> <dbl>  <dbl>     <dbl>  1 aled      year                  10.9        0   10.8   10.9   10.9      11.0  2 aled      ag_km2                 2.02       0    1.95   2.02   2.01      2.07  3 aled      temp_lt_00             1.36       0    1.31   1.36   1.36      1.42  4 aled      temp_00_10             1.28       0    1.24   1.28   1.28      1.31  5 aled      temp_21_30             4.19       0    4.09   4.19   4.20      4.28  6 aled      temp_31_35             4.57       0    4.51   4.57   4.57      4.63  7 aled      temp_36_45             4.75       0    4.69   4.75   4.75      4.80  8 aled      ppt                    1.06       0    1.01   1.06   1.06      1.11  9 aled      whc                    2.15       0    2.12   2.15   2.16      2.19 10 aled      silt                   1.27       0    1.23   1.27   1.27      1.32 11 aled      clay                   1.10       0    1.07   1.10   1.10      1.13 12 aled      kwfactor               2.11       0    2.08   2.11   2.12      2.15 13 aled      spH                    2.08       0    1.99   2.08   2.08      2.19 14 aled      tfactor                1.92       0    1.89   1.92   1.92      1.95 15 aled      year:temp_gt_45        1.62       0    1.26   1.62   1.62      1.99 16 aled      temp_00_10:temp_g…     1.65       0    0.612  1.65   1.67      2.48 17 naled     year                  11.1        0   11.0   11.1   11.2      11.3 18 naled     ag_km2                 2.41       0    2.38   2.41   2.41      2.43 19 naled     temp_lt_00             1.75       0    1.67   1.75   1.75      1.89 20 naled     temp_00_10             1.70       0    1.60   1.70   1.72      1.73 21 naled     temp_21_30             4.59       0    4.37   4.59   4.61      4.74 22 naled     temp_31_35             4.94       0    4.83   4.94   4.91      5.08 23 naled     temp_36_45             5.31       0    5.07   5.31   5.37      5.40 24 naled     ppt                    1.48       0    1.40   1.48   1.50      1.56 25 naled     whc                    2.56       0    2.55   2.56   2.56      2.58 26 naled     silt                   1.64       0    1.55   1.64   1.63      1.76 27 naled     clay                   1.53       0    1.43   1.53   1.50      1.65 28 naled     kwfactor               2.49       0    2.43   2.49   2.50      2.57 29 naled     spH                    2.43       0    2.37   2.43   2.41      2.54 30 naled     tfactor                2.32       0    2.28   2.32   2.31      2.37 31 naled     year:temp_gt_45        2.04       0    1.69   2.04   2.02      2.41 32 naled     temp_00_10:temp_g…     2.03       0    0.959  2.03   2.03      2.78 # A tibble: 46 × 10    term          start_x   end_x x_span_pct     n     pct start_y end_y    trend    <chr>           <dbl>   <dbl>      <dbl> <int>   <dbl>   <dbl> <dbl>    <dbl>  1 year          1.98e+3 1.99e+3     32.4   41855 4.65e+1    89.8  99.1  0.172  2 year          1.99e+3 2.02e+3     61.8   48155 5.35e+1   106.  132.   0.253  3 ag_km2        4.81e-1 4.09e+2      7.79  30006 3.33e+1    99.2 104.   0.387  4 ag_km2        5.71e+2 5.71e+2      0     10000 1.11e+1   105.  105.   0  5 ag_km2        7.55e+2 5.24e+3     85.6   50004 5.56e+1   106.  107.   0.00465  6 temp_lt_00    0       7.47e+0     14.2   60007 6.67e+1   108.  106.  -0.0744  7 temp_lt_00    1.06e+1 1.06e+1      0     10001 1.11e+1   105.  105.   0  8 temp_lt_00    1.50e+1 5.27e+1     71.6   20002 2.22e+1   103.   98.0 -0.0378  9 temp_00_10    5.76e-4 5.76e-4      0         1 1.11e-3   105.  105.   0 10 temp_00_10    1.03e+1 1.76e+1     10.6   20002 2.22e+1   103.  104.   0.0835 11 temp_00_10    2.31e+1 3.46e+1     16.8   40004 4.44e+1   106.  106.   0.00787 12 temp_00_10    3.81e+1 3.81e+1      0     10001 1.11e+1   105.  105.   0 13 temp_00_10    4.21e+1 6.88e+1     38.9   20002 2.22e+1   104.  101.  -0.0543 14 temp_21_30    1.08e+1 6.45e+1     45.6   20003 2.22e+1    87.3 102.   0.198 15 temp_21_30    7.00e+1 7.00e+1      0     10001 1.11e+1   104.  104.   0 16 temp_21_30    7.52e+1 1.29e+2     45.3   60006 6.67e+1   106.  113.   0.0999 17 temp_31_35    0       1.19e+1     17.0   40005 4.44e+1   110.  107.  -0.104 18 temp_31_35    1.59e+1 6.98e+1     77.2   50005 5.56e+1   104.   93.9 -0.0799 19 temp_36_45    0       4.77e-1      0.750 50007 5.56e+1   110.  106.  -3.55 20 temp_36_45    1.17e+0 6.36e+1     98.2   40003 4.44e+1   103.   90.3 -0.0762 21 ppt           9.43e-1 9.43e-1      0         1 1.11e-3   106.  106.   0 22 ppt           3.91e+2 4.90e+2      6.20  20002 2.22e+1   102.  104.   0.149 23 ppt           5.52e+2 5.52e+2      0     10001 1.11e+1   105.  105.   0 24 ppt           6.04e+2 8.70e+2     16.6   50005 5.56e+1   106.  106.   0.0255 25 ppt           1.60e+3 1.60e+3      0     10001 1.11e+1   102.  102.   0 26 whc           9.70e+0 2.56e+1     46.6   50008 5.56e+1   101.  104.   0.0358 27 whc           2.71e+1 2.71e+1      0     10001 1.11e+1   105.  105.   0 28 whc           2.92e+1 4.38e+1     42.6   30001 3.33e+1   107.  111.   0.0569 29 silt          2.63e+0 3.41e+1     43.1   30006 3.33e+1   103.  104.   0.0113 30 silt          3.86e+1 3.86e+1      0     10005 1.11e+1   105.  105.   0 31 silt          4.33e+1 7.55e+1     44.3   49999 5.55e+1   105.  107.   0.0212 32 clay          1.17e+0 2.76e+1     45.9   50018 5.56e+1   106.  106.  -0.00514 33 clay          3.00e+1 3.00e+1      0      9990 1.11e+1   105.  105.   0 34 clay          3.38e+1 5.87e+1     43.4   30002 3.33e+1   103.  103.   0.00284 35 kwfactor      4.58e-2 2.71e-1     44.0   30010 3.33e+1   103.  103.   0.00150 36 kwfactor      2.97e-1 2.97e-1      0     10000 1.11e+1   104.  104.   0 37 kwfactor      3.17e-1 3.17e-1      0     10001 1.11e+1   104.  104.   0 38 kwfactor      3.41e-1 3.41e-1      0      9998 1.11e+1   104.  104.   0 39 kwfactor      3.75e-1 5.58e-1     35.8   30001 3.33e+1   108.  109.   0.0154 40 spH           4.63e+0 5.33e+0     17.5   20009 2.22e+1   102.  101.  -0.00902 41 spH           5.67e+0 5.67e+0      0      9995 1.11e+1   105.  105.   0 42 spH           6.12e+0 7.33e+0     30.5   40008 4.44e+1   106.  109.   0.0608 43 spH           7.69e+0 7.69e+0      0      9999 1.11e+1   103.  103.   0 44 spH           8.60e+0 8.60e+0      0      9999 1.11e+1   110.  110.   0 45 tfactor       2.26e+0 4.60e+0     85.4   50020 5.56e+1   102.  104.   0.0164 46 tfactor       4.73e+0 5   e+0      9.71  39990 4.44e+1   105.  116.   0.637 # ℹ 1 more variable: aler_band <ord>"},{"path":"https://tripartio.github.io/ale/articles/ale-acdc-corn.html","id":"ale-plots","dir":"Articles","previous_headings":"","what":"ALE plots","title":"Analyzing a Large Corn Yield Dataset with ALE-Based Inference","text":"make ALE plots readable, adjust default output. print 1D 2D plots separately subsetting plot objects, apply customization step zoom y-axis 1D ALE plots. y-axis limits chosen improve visibility keeping plots common scale, makes relative effect sizes easier compare across variables.  view, plots align cleanly ALED rankings: year shows largest range, followed key temperature ranges (especially 21–30°C 31–35°C). also interpret plots rug marks mind. Extreme x-values often sparse support, put interpretive weight regions predictor data dense ALE curve well supported.  Looking interaction plots, visible pattern involves year number days temperatures 45°C. appears small regime shift: roughly 1–2 days, earlier years associated higher yield, later years associated lower yield. However, interaction heatmaps also display fraction observations cell (size little grey squares within cells). “statistically significant” regions, squares tiny, often representing less 1% data. practice, county-years days 45°C, interaction, real statistically significant, supported little data. similar caution applies interaction days 45°C days 0–10°C range. visual suggests conditional effects, relevant cells sparsely populated, treat interaction signals weak practically decisive.","code":"ale_boot_rf_corn |>    plot() |>  # create ALEPlots object   subset(list(d1 = TRUE)) |>  # subset only for 1D plots   customize(zoom_y = c(85, 135)) |>   # zoom on the y-axis   print(ncol = 2) ale_boot_rf_corn |>    plot() |>  # create ALEPlots object   subset(list(d2 = TRUE)) |>   # subset only for 2D plots   print(ncol = 1)"},{"path":"https://tripartio.github.io/ale/articles/ale-acdc-corn.html","id":"conclusion","dir":"Articles","previous_headings":"","what":"Conclusion","title":"Analyzing a Large Corn Yield Dataset with ALE-Based Inference","text":"Methodologically, lessons stand . First, constrain relationships linear allow automatic detection even small interactions, standard OLS performs moderately, SA 64.6%. limitation structural rather incidental. OLS can capture explicitly specify, setting restriction costs predictive accuracy. contrast, machine learning models random forests well suited datasets size complexity. Using ranger, obtain excellent performance minimal tuning. model handles nonlinearities potential interactions automatically, precisely need . Given performance gap, focus interpretation random forest model. second important methodological result concerns interactions. Although computed pairwise ALE interactions, none practically important. interaction effects small, none exceed threshold two bushels per acre. matters. interactions meaningfully distort marginal relationships, can interpret main effects directly without worrying strong interaction structure hiding underneath. dataset size, statistical significance almost guaranteed. Indeed, effects statistically significant. interesting part. matters magnitude. eight variables exhibit ALED effects least two bushels per acre. effects clear threshold practical importance, display ALE plots accordingly.  None relationships observe strictly linear. Still, overall directions clear. Corn yield positively associated later years, larger agricultural land area county (ag_km2), days “ideal” 21–30°C range, favourable soil characteristics including water holding capacity (whc), kwfactor, soil pH (spH). contrast, days 31–35°C 36–46°C ranges associated lower yields. Although ALE computationally demanding, gives us way interpret complex, high-performing machine-learning model keeping results meaningful scale attaching statistical confidence appropriate. Nothing main-effect patterns especially shocking, largely expected. analyze well-known, preassembled dataset, “headline” relationships usually explored already. can realistically expect novel insights merging rich panel like ACDC (corn, wheat, soybean, cotton, etc.) compatible datasets, example additional county-, state-, year-indexed measures different kinds data might normally expected related corn, weather, soil characteristics. surprises emerge merges, likely come unexpected interactions rather main effects already embedded original sources. said, interactions also raise interpretability challenges, development ALE-based tools interaction explanation make future studies easier unpack.","code":"# Create variable lists to focus on vars_aled_2 <- ale_boot_rf_corn |>    get(stats = 'estimate') |>    bind_rows() |>    filter(aled >= 2) |>    pull(term)  ale_boot_rf_corn |>    plot() |>  # create ALEPlots object   subset(vars_aled_2) |>  # subset only for 1D plots   customize(zoom_y = c(85, 135)) |>   # zoom on the y-axis   print(ncol = 2)"},{"path":"https://tripartio.github.io/ale/articles/ale-acdc-corn.html","id":"methodological-comments","dir":"Articles","previous_headings":"","what":"Methodological comments","title":"Analyzing a Large Corn Yield Dataset with ALE-Based Inference","text":"Methodologically, lessons stand . First, constrain relationships linear allow automatic detection even small interactions, standard OLS performs moderately, SA 64.6%. limitation structural rather incidental. OLS can capture explicitly specify, setting restriction costs predictive accuracy. contrast, machine learning models random forests well suited datasets size complexity. Using ranger, obtain excellent performance minimal tuning. model handles nonlinearities potential interactions automatically, precisely need . Given performance gap, focus interpretation random forest model. second important methodological result concerns interactions. Although computed pairwise ALE interactions, none practically important. interaction effects small, none exceed threshold two bushels per acre. matters. interactions meaningfully distort marginal relationships, can interpret main effects directly without worrying strong interaction structure hiding underneath.","code":""},{"path":"https://tripartio.github.io/ale/articles/ale-acdc-corn.html","id":"key-findings","dir":"Articles","previous_headings":"","what":"Key findings","title":"Analyzing a Large Corn Yield Dataset with ALE-Based Inference","text":"dataset size, statistical significance almost guaranteed. Indeed, effects statistically significant. interesting part. matters magnitude. eight variables exhibit ALED effects least two bushels per acre. effects clear threshold practical importance, display ALE plots accordingly.  None relationships observe strictly linear. Still, overall directions clear. Corn yield positively associated later years, larger agricultural land area county (ag_km2), days “ideal” 21–30°C range, favourable soil characteristics including water holding capacity (whc), kwfactor, soil pH (spH). contrast, days 31–35°C 36–46°C ranges associated lower yields. Although ALE computationally demanding, gives us way interpret complex, high-performing machine-learning model keeping results meaningful scale attaching statistical confidence appropriate.","code":"# Create variable lists to focus on vars_aled_2 <- ale_boot_rf_corn |>    get(stats = 'estimate') |>    bind_rows() |>    filter(aled >= 2) |>    pull(term)  ale_boot_rf_corn |>    plot() |>  # create ALEPlots object   subset(vars_aled_2) |>  # subset only for 1D plots   customize(zoom_y = c(85, 135)) |>   # zoom on the y-axis   print(ncol = 2)"},{"path":"https://tripartio.github.io/ale/articles/ale-acdc-corn.html","id":"a-note-on-unsurprising-results","dir":"Articles","previous_headings":"","what":"A note on unsurprising results","title":"Analyzing a Large Corn Yield Dataset with ALE-Based Inference","text":"Nothing main-effect patterns especially shocking, largely expected. analyze well-known, preassembled dataset, “headline” relationships usually explored already. can realistically expect novel insights merging rich panel like ACDC (corn, wheat, soybean, cotton, etc.) compatible datasets, example additional county-, state-, year-indexed measures different kinds data might normally expected related corn, weather, soil characteristics. surprises emerge merges, likely come unexpected interactions rather main effects already embedded original sources. said, interactions also raise interpretability challenges, development ALE-based tools interaction explanation make future studies easier unpack.","code":""},{"path":"https://tripartio.github.io/ale/articles/ale-acdc-corn.html","id":"references","dir":"Articles","previous_headings":"","what":"References","title":"Analyzing a Large Corn Yield Dataset with ALE-Based Inference","text":"Yun, Seong , Benjamin M. Gramig. 2017. Agro-Climatic Data County, 1981-2015. Dataset. Purdue University. https://doi.org/10.4231/R72F7KK2.","code":""},{"path":"https://tripartio.github.io/ale/articles/ale-gomez-rice.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Analyzing a Small Rice Yield Dataset with ALE-Based Inference","text":"’re working tiny, expensive kind dataset: sort get data point costs fieldwork, fertilizer, patience. rice data come International Rice Research Institute (IRRI) discussed Gomez & Gomez (1984). goal simple: figure rice yield responds nitrogen fertilizer dry versus wet seasons, whether “best” nitrogen level differ season. ’ll analyze data three model families: OLS regression (classic linear regression). Random forest (mostly cautionary tale tiny data). Generalized additive model (GAM), usually best fit “small data + nonlinearity”.","code":""},{"path":"https://tripartio.github.io/ale/articles/ale-gomez-rice.html","id":"set-up-r-environment","dir":"Articles","previous_headings":"","what":"Set up R environment","title":"Analyzing a Small Rice Yield Dataset with ALE-Based Inference","text":"First, let’s set R environment. begin loading packages ’ll use. Two quick notes: dataset comes {agridat} package (doesn’t loaded, installed). {ale} package CRAN, features used install current development version GitHub (code shows , via {pak}).","code":"library(dplyr)  # data manipulation library(staccuracy)  # performance metrics library(tictoc)  # performance timing library(mgcv)  # Generalized Additive Models library(ranger)  # random forest library(kableExtra)  # table formatting  # Other packages that must be installed # Uncomment the following lines as needed.  # # If needed, first install the pak advanced package manager (needed to easily install a package directly from GitHub): # install.packages('pak') #  # pak::pak('agridat')  # agricultural datasets #  # # Accumulated Local Effects: ale package # # Install the development version of ale for this workshop, which is more recent than the current CRAN version. # pak::pak('tripartio/ale') library(ale)  # load the ale package only after installing the development version # For speed, these examples use retrieve_rds() to load precreated objects  # from an online repository. # To run the code yourself, execute the code blocks directly.   serialized_objects_site <- \"https://github.com/tripartio/ale/raw/main/download/rice_objects\""},{"path":"https://tripartio.github.io/ale/articles/ale-gomez-rice.html","id":"data-preparation-and-description","dir":"Articles","previous_headings":"","what":"Data preparation and description","title":"Analyzing a Small Rice Yield Dataset with ALE-Based Inference","text":"data come IRRI Philippines. Unfortunately, book describes (Gomez & Gomez, 1984) give much context (country/year/site details) beyond description: “give procedures analyzing data experiments crop seasons using fertilizer trial five nitrogen rates tested rice two seasons, using RCB design three replications” (p. 317). Preparation straightforward: pull gomez.wetdry convert tibble. also drop rep column ’s usable replication ID . uses labels like R1/R2/R3, R1 one row experimental block R1 another row, treating factor invite nonsense, especially dataset small. ’ll add commentary later. now, ’s full dataset. printing data, summarize . Three replications five nitrogen rates run dry wet seasons, total 30 plots. season (factor): wet dry season. nitrogen (numeric): five nitrogen fertilizer rates applied agricultural plot, kilograms per hectare (kg/ha). yield (numeric): rice grain yield, tonnes per hectare (t/ha), , 1,000 kg/ha. Notably, outcome variable, rice yield mean 5.5 t/ha mean absolute deviation (mad) 0.982.","code":"data('gomez.wetdry', package = 'agridat')  rice <- gomez.wetdry |>    as_tibble() |>    # rep is a false factor; it should be a unique ID:   # Each R1 has nothing to do with each other; likewise for R2 or R3.   select(-rep)  # help('gomez.wetdry', package = 'agridat') rice |> print(n = 50) # A tibble: 30 × 3    season nitrogen yield    <fct>     <int> <dbl>  1 dry           0  4.89  2 dry           0  2.58  3 dry           0  4.54  4 dry          60  6.01  5 dry          60  6.62  6 dry          60  5.67  7 dry          90  6.71  8 dry          90  6.69  9 dry          90  6.80 10 dry         120  6.46 11 dry         120  6.68 12 dry         120  6.64 13 dry         150  5.68 14 dry         150  6.87 15 dry         150  5.69 16 wet           0  5.00 17 wet           0  3.50 18 wet           0  5.36 19 wet          60  6.35 20 wet          60  6.32 21 wet          60  6.58 22 wet          90  6.07 23 wet          90  5.97 24 wet          90  5.89 25 wet         120  4.82 26 wet         120  4.02 27 wet         120  5.81 28 wet         150  3.44 29 wet         150  4.05 30 wet         150  3.74 rice |> summary() season      nitrogen       yield  dry:15   Min.   :  0   Min.   :2.577  wet:15   1st Qu.: 60   1st Qu.:4.836           Median : 90   Median :5.853           Mean   : 84   Mean   :5.515           3rd Qu.:120   3rd Qu.:6.551           Max.   :150   Max.   :6.868 rice$nitrogen |> table() 0  60  90 120 150   6   6   6   6   6"},{"path":"https://tripartio.github.io/ale/articles/ale-gomez-rice.html","id":"model-evaluation","dir":"Articles","previous_headings":"","what":"Model evaluation","title":"Analyzing a Small Rice Yield Dataset with ALE-Based Inference","text":"train anything, need clear evaluate models. two particular principles evaluation approach: appropriate metrics practical alignment predictive analysis. Classic statistics leans heavily R² adjusted R². measure explained variance. ’s fine far goes, want deliberate metrics. outcome numeric, ratio, continuous variable: yield t/ha. tasks like , appropriate metric usually mean absolute error (MAE). problem MAE–metrics–interpretation. Smaller better, yes—small good? standard comparison MAE mean absolute deviation (MAD). dataset, MAD rice yield 0.982. Thus, “good” model MAE smaller threshold simplify comparisons, also use standardized accuracy (staccuracy SA), {staccuracy} package. rescales performance 0–100% range. value 100% means perfect prediction. value 50% corresponds predicting mean every time. , MAE staccuracy, 50% score MAD. staccuracy 50% beats mean; anything 50% worse simply guessing mean. report MAE standardized accuracy. Descriptive metrics computed full dataset used train model. tell us well model reproduces data already saw. useful, still -sample performance. Predictive metrics realistic. train model part data evaluate data used fitting. Common approaches include cross-validation bootstrapping. Cross-validation often used large datasets slow models. Bootstrapping works well small datasets faster models. dataset small, use bootstrapping—specifically full-model bootstrapping. explain difference bootstrap approaches article ALE statistics inference. eventual results analyses. Note lower MAE better, higher staccuracy (SA) better. Descriptive metrics usually look better predictive metrics tend misleadingly overfit data. evaluation clarified, can now move models .","code":""},{"path":"https://tripartio.github.io/ale/articles/ale-gomez-rice.html","id":"metrics-for-numeric-prediction","dir":"Articles","previous_headings":"","what":"Metrics for numeric prediction","title":"Analyzing a Small Rice Yield Dataset with ALE-Based Inference","text":"Classic statistics leans heavily R² adjusted R². measure explained variance. ’s fine far goes, want deliberate metrics. outcome numeric, ratio, continuous variable: yield t/ha. tasks like , appropriate metric usually mean absolute error (MAE). problem MAE–metrics–interpretation. Smaller better, yes—small good? standard comparison MAE mean absolute deviation (MAD). dataset, MAD rice yield 0.982. Thus, “good” model MAE smaller threshold simplify comparisons, also use standardized accuracy (staccuracy SA), {staccuracy} package. rescales performance 0–100% range. value 100% means perfect prediction. value 50% corresponds predicting mean every time. , MAE staccuracy, 50% score MAD. staccuracy 50% beats mean; anything 50% worse simply guessing mean. report MAE standardized accuracy.","code":""},{"path":"https://tripartio.github.io/ale/articles/ale-gomez-rice.html","id":"descriptive-versus-predictive-metrics","dir":"Articles","previous_headings":"","what":"Descriptive versus predictive metrics","title":"Analyzing a Small Rice Yield Dataset with ALE-Based Inference","text":"Descriptive metrics computed full dataset used train model. tell us well model reproduces data already saw. useful, still -sample performance. Predictive metrics realistic. train model part data evaluate data used fitting. Common approaches include cross-validation bootstrapping. Cross-validation often used large datasets slow models. Bootstrapping works well small datasets faster models. dataset small, use bootstrapping—specifically full-model bootstrapping. explain difference bootstrap approaches article ALE statistics inference. eventual results analyses. Note lower MAE better, higher staccuracy (SA) better. Descriptive metrics usually look better predictive metrics tend misleadingly overfit data. evaluation clarified, can now move models .","code":""},{"path":"https://tripartio.github.io/ale/articles/ale-gomez-rice.html","id":"ols-regression","dir":"Articles","previous_headings":"","what":"OLS regression","title":"Analyzing a Small Rice Yield Dataset with ALE-Based Inference","text":"start familiar tool toolbox: ordinary least squares (OLS) linear regression. fit model using predictors, season nitrogen, also include interaction. means allow effect nitrogen differ wet dry seasons rather forcing one shared slope. fitting model, print summary inspect coefficients, standard errors, overall fit. interpreting OLS coefficients, check whether model anything useful. adjusted R2 0.284 (1.0 perfect), … inspiring, ’s also metric clean “good/bad” cutoff. coefficient table, season effect statistically significant. Nitrogen statistically significant (p ⩽ 0.05), estimated slope (0.015) tiny, season × nitrogen interaction also significant tiny -0.021. Using preferred metrics, OLS model descriptive MAE 0.772 t/ha standardized accuracy 60.7%. staccuracy better coin-flip territory, still descriptive metrics can look deceptively good small data. move ALE understand model actually implying. start single ALE explanation (fast two predictors one interaction). ’ll focus ALED (ALE deviation) main effect-size summary. explain ALE statistics detail another article. ALE summary, season ALED effect 0.387 t/ha (≈ 387 kg/ha) nitrogen 153 kg/ha. season × nitrogen interaction ALED 391 kg/ha. However, note without bootstrapping, results shouldn’t considered reliable. Next look ALE plots. three terms, ’ll inspect (bigger studies, ’d pickier).   ALE analysis OLS model, begin statistics turning plots. Since ALE run , relying p-values alone informative. obtain ALED estimates, already defined elsewhere. Looking plots , pattern consistent: dry-season yield appears higher wet-season yield, OLS model implies nitrogen increases yield overall. interaction suggests nitrogen may reduce yield wet season, ’ll hold interpreting interaction plots come GAM . However, statistical results (ALE otherwise) generally reliable bootstrap .dataset tiny models train quickly, use full model bootstrapping. two ways bootstrap ALE. faster approach resamples ALE calculation data without retraining model. approach appropriate large datasets slow models already validated cross-validation. situation. small dataset fast models. must retrain entire model bootstrap iteration. default, use 100 bootstrap iterations. publication, increase number, analysis, 100 iterations typically sufficient lead conclusions. ALE relatively stable compared interpretability methods. bootstrapping, let’s first generate ALE p-value distribution. slowest step ALE analysis relies simulation rather parametric assumptions. Whenever procedures slow demonstration, code blocks commented presaved objects loaded instead, document runs quickly. can use p-value distribution full-model bootstrapping procedure {ale} package, create ModelBoot object. explicitly request ALE season, nitrogen, season × nitrogen interaction. full bootstrap process ALE results become reliable Bootstrapping gives us predictive metrics based bootstrap validation 100 hold-samples. OLS model predictive MAE 0.918 t/ha standardized accuracy 48.8%. staccuracy less 50% counts “bad” model–’s worse simply predicting mean every time. , OLS model pretty much useless. least, ’ve learnt can’t trust . reinforced complete absence statistically significant confidence regions–ALE-based inference telling us can’t trust anything model says.   Plotting bootstrapped ALE reinforces scepticism: results fall within middle grey ALER band, indicates random results live. Although 2D interaction plot regions outside ALER band, statistics indicate bootstrapped ranges nonetheless overlap ALER band, shown plot.","code":"lm_rice <- lm(   yield ~ season + nitrogen + season:nitrogen,   data = rice ) sa_lm_rice  <- sa_wmae_mad(rice$yield, predict(lm_rice))  # 0.60739 mae_lm_rice <- mae(rice$yield, predict(lm_rice))  # 0.7719829 summary(lm_rice) Call: lm(formula = yield ~ season + nitrogen + season:nitrogen, data = rice)  Residuals:     Min      1Q  Median      3Q     Max -2.1507 -0.6644  0.1648  0.8069  1.3039  Coefficients:                     Estimate Std. Error t value Pr(>|t|) (Intercept)         4.664225   0.497790   9.370 8.08e-10 *** seasonwet           0.989486   0.703982   1.406  0.17169 nitrogen            0.014739   0.005049   2.919  0.00716 ** seasonwet:nitrogen -0.020999   0.007140  -2.941  0.00679 ** --- Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1  Residual standard error: 1.009 on 26 degrees of freedom Multiple R-squared:  0.3576,    Adjusted R-squared:  0.2835 F-statistic: 4.824 on 3 and 26 DF,  p-value: 0.008423 # Single ALE description ale_lm_rice <- ALE(   lm_rice,    x_cols = list(d1 = TRUE, d2 = TRUE),   data = rice,   # p_values = pd_lm_rice,   parallel = 0 )  summary(ale_lm_rice) # A tibble: 3 × 7   term             aled aler_min aler_max naled naler_min naler_max   <chr>           <dbl>    <dbl>    <dbl> <dbl>     <dbl>     <dbl> 1 season          0.387   -0.387    0.387 13.3      -13.3      13.3 2 nitrogen        0.153   -0.318    0.318  9.33     -13.3      13.3 3 season:nitrogen 0.391   -1.04     0.614 14.3      -26.7      23.3 # A tibble: 6 × 7   statistic term            estimate conf.low   mean median conf.high   <ord>     <chr>              <dbl>    <dbl>  <dbl>  <dbl>     <dbl> 1 aled      season             0.387    0.387  0.387  0.387     0.387 2 aled      nitrogen           0.153    0.153  0.153  0.153     0.153 3 aled      season:nitrogen    0.391    0.391  0.391  0.391     0.391 4 naled     season            13.3     13.3   13.3   13.3      13.3 5 naled     nitrogen           9.33     9.33   9.33   9.33      9.33 6 naled     season:nitrogen   14.3     14.3   14.3   14.3      14.3 # A tibble: 0 × 0 ale_lm_rice |>    plot() |>    subset(list(d1 = TRUE)) ale_lm_rice |>    plot() |>    subset(list(d2 = TRUE)) # SLOW: uncomment to run yourself; load the saved object for rapid execution  # # p-value distribution # # Default 1000 iterations for exact p-values # tic() # pd_lm_rice <- ALEpDist(lm_rice, rice, parallel = 0) # toc()  # 542.13 sec elapsed # # saveRDS(pd_lm_rice, file.choose())  pd_lm_rice <- serialized_objects_site |>    file.path(\"pd_lm_rice.rds\") |>   url() |>    readRDS()   # SLOW: uncomment to run yourself; load the saved object for rapid execution  # # Full-model bootstrapped ALE explanation # # Default 100 bootstrap iterations # tic() # mb_lm_rice <- ModelBoot( #   lm_rice, rice, #   ale_options = list(x_cols = c('season', 'nitrogen', 'season:nitrogen')), #   ale_p = pd_lm_rice, #   parallel = 0 # ) # toc()  # 113.02 sec elapsed # # saveRDS(mb_lm_rice, file.choose())  mb_lm_rice <- serialized_objects_site |>    file.path(\"mb_lm_rice.rds\") |>   url() |>    readRDS() summary(mb_lm_rice)  # boot_valid SA 48.8%: MAE 0.918 # A tibble: 12 × 7    name          boot_valid conf.low  median    mean conf.high     sd    <chr>              <dbl>    <dbl>   <dbl>   <dbl>     <dbl>  <dbl>  1 r.squared         NA       0.193   0.444   0.449      0.715 0.134  2 adj.r.squared     NA       0.100   0.380   0.385      0.682 0.150  3 sigma             NA       0.621   0.907   0.907      1.13  0.137  4 statistic         NA       2.08    6.92    8.25      21.8   5.34  5 p.value           NA       0       0.0014  0.0129     0.130 0.0323  6 df                NA       3       3       3          3     0  7 df.residual       NA      26      26      26         26     0  8 nobs              NA      30      30      30         30     0  9 mae                0.918   0.634  NA      NA          1.45  0.232 10 sa_mae             0.488  -0.0793 NA      NA          0.649 0.191 11 rmse               1.14    0.770  NA      NA          2.12  0.354 12 sa_rmse            0.498   0.0366 NA      NA          0.652 0.176 # A tibble: 4 × 6   term               conf.low  median    mean conf.high std.error   <chr>                 <dbl>   <dbl>   <dbl>     <dbl>     <dbl> 1 (Intercept)          3.56    4.68    4.71      6.34      0.697 2 seasonwet           -0.550   1.16    1.27      4.18      1.20 3 nitrogen             0.0005  0.0149  0.0148    0.0273    0.007 4 seasonwet:nitrogen  -0.0483 -0.0236 -0.0236   -0.0063    0.0114 # A tibble: 3 × 7   term             aled aler_min aler_max naled naler_min naler_max   <fct>           <dbl>    <dbl>    <dbl> <dbl>     <dbl>     <dbl> 1 season          0.405   -0.416    0.421 14.9      -13.4      17.2 2 nitrogen        0.200   -0.391    0.463  8.69     -13.3      21.5 3 season:nitrogen 0.409   -1.06     0.793 15.0      -24.2      31.3 # A tibble: 6 × 8   statistic term            estimate p.value conf.low median   mean conf.high   <ord>     <fct>              <dbl>   <dbl>    <dbl>  <dbl>  <dbl>     <dbl> 1 aled      season             0.405   0.006   0.0483  0.445  0.405     0.860 2 aled      nitrogen           0.200   0.212   0.0245  0.184  0.200     0.463 3 aled      season:nitrogen    0.409   0.005   0.113   0.392  0.409     0.789 4 naled     season            14.9     0.053   0.581  14.9   14.9      33.1 5 naled     nitrogen           8.69    0.235   0       8.33   8.69     20.7 6 naled     season:nitrogen   15.0     0.049   1.32   14.6   15.0      28.6 # A tibble: 0 × 0 mb_lm_rice |>    plot() |>    subset(list(d1 = TRUE)) mb_lm_rice |>    plot() |>    subset(list(d2 = TRUE))"},{"path":"https://tripartio.github.io/ale/articles/ale-gomez-rice.html","id":"model-training","dir":"Articles","previous_headings":"","what":"Model training","title":"Analyzing a Small Rice Yield Dataset with ALE-Based Inference","text":"start familiar tool toolbox: ordinary least squares (OLS) linear regression. fit model using predictors, season nitrogen, also include interaction. means allow effect nitrogen differ wet dry seasons rather forcing one shared slope. fitting model, print summary inspect coefficients, standard errors, overall fit. interpreting OLS coefficients, check whether model anything useful. adjusted R2 0.284 (1.0 perfect), … inspiring, ’s also metric clean “good/bad” cutoff. coefficient table, season effect statistically significant. Nitrogen statistically significant (p ⩽ 0.05), estimated slope (0.015) tiny, season × nitrogen interaction also significant tiny -0.021. Using preferred metrics, OLS model descriptive MAE 0.772 t/ha standardized accuracy 60.7%. staccuracy better coin-flip territory, still descriptive metrics can look deceptively good small data. move ALE understand model actually implying.","code":"lm_rice <- lm(   yield ~ season + nitrogen + season:nitrogen,   data = rice ) sa_lm_rice  <- sa_wmae_mad(rice$yield, predict(lm_rice))  # 0.60739 mae_lm_rice <- mae(rice$yield, predict(lm_rice))  # 0.7719829 summary(lm_rice) Call: lm(formula = yield ~ season + nitrogen + season:nitrogen, data = rice)  Residuals:     Min      1Q  Median      3Q     Max -2.1507 -0.6644  0.1648  0.8069  1.3039  Coefficients:                     Estimate Std. Error t value Pr(>|t|) (Intercept)         4.664225   0.497790   9.370 8.08e-10 *** seasonwet           0.989486   0.703982   1.406  0.17169 nitrogen            0.014739   0.005049   2.919  0.00716 ** seasonwet:nitrogen -0.020999   0.007140  -2.941  0.00679 ** --- Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1  Residual standard error: 1.009 on 26 degrees of freedom Multiple R-squared:  0.3576,    Adjusted R-squared:  0.2835 F-statistic: 4.824 on 3 and 26 DF,  p-value: 0.008423"},{"path":"https://tripartio.github.io/ale/articles/ale-gomez-rice.html","id":"ale-analysis","dir":"Articles","previous_headings":"","what":"ALE analysis","title":"Analyzing a Small Rice Yield Dataset with ALE-Based Inference","text":"start single ALE explanation (fast two predictors one interaction). ’ll focus ALED (ALE deviation) main effect-size summary. explain ALE statistics detail another article. ALE summary, season ALED effect 0.387 t/ha (≈ 387 kg/ha) nitrogen 153 kg/ha. season × nitrogen interaction ALED 391 kg/ha. However, note without bootstrapping, results shouldn’t considered reliable. Next look ALE plots. three terms, ’ll inspect (bigger studies, ’d pickier).   ALE analysis OLS model, begin statistics turning plots. Since ALE run , relying p-values alone informative. obtain ALED estimates, already defined elsewhere. Looking plots , pattern consistent: dry-season yield appears higher wet-season yield, OLS model implies nitrogen increases yield overall. interaction suggests nitrogen may reduce yield wet season, ’ll hold interpreting interaction plots come GAM . However, statistical results (ALE otherwise) generally reliable bootstrap .dataset tiny models train quickly, use full model bootstrapping. two ways bootstrap ALE. faster approach resamples ALE calculation data without retraining model. approach appropriate large datasets slow models already validated cross-validation. situation. small dataset fast models. must retrain entire model bootstrap iteration. default, use 100 bootstrap iterations. publication, increase number, analysis, 100 iterations typically sufficient lead conclusions. ALE relatively stable compared interpretability methods. bootstrapping, let’s first generate ALE p-value distribution. slowest step ALE analysis relies simulation rather parametric assumptions. Whenever procedures slow demonstration, code blocks commented presaved objects loaded instead, document runs quickly. can use p-value distribution full-model bootstrapping procedure {ale} package, create ModelBoot object. explicitly request ALE season, nitrogen, season × nitrogen interaction. full bootstrap process ALE results become reliable Bootstrapping gives us predictive metrics based bootstrap validation 100 hold-samples. OLS model predictive MAE 0.918 t/ha standardized accuracy 48.8%. staccuracy less 50% counts “bad” model–’s worse simply predicting mean every time. , OLS model pretty much useless. least, ’ve learnt can’t trust . reinforced complete absence statistically significant confidence regions–ALE-based inference telling us can’t trust anything model says.   Plotting bootstrapped ALE reinforces scepticism: results fall within middle grey ALER band, indicates random results live. Although 2D interaction plot regions outside ALER band, statistics indicate bootstrapped ranges nonetheless overlap ALER band, shown plot.","code":"# Single ALE description ale_lm_rice <- ALE(   lm_rice,    x_cols = list(d1 = TRUE, d2 = TRUE),   data = rice,   # p_values = pd_lm_rice,   parallel = 0 )  summary(ale_lm_rice) # A tibble: 3 × 7   term             aled aler_min aler_max naled naler_min naler_max   <chr>           <dbl>    <dbl>    <dbl> <dbl>     <dbl>     <dbl> 1 season          0.387   -0.387    0.387 13.3      -13.3      13.3 2 nitrogen        0.153   -0.318    0.318  9.33     -13.3      13.3 3 season:nitrogen 0.391   -1.04     0.614 14.3      -26.7      23.3 # A tibble: 6 × 7   statistic term            estimate conf.low   mean median conf.high   <ord>     <chr>              <dbl>    <dbl>  <dbl>  <dbl>     <dbl> 1 aled      season             0.387    0.387  0.387  0.387     0.387 2 aled      nitrogen           0.153    0.153  0.153  0.153     0.153 3 aled      season:nitrogen    0.391    0.391  0.391  0.391     0.391 4 naled     season            13.3     13.3   13.3   13.3      13.3 5 naled     nitrogen           9.33     9.33   9.33   9.33      9.33 6 naled     season:nitrogen   14.3     14.3   14.3   14.3      14.3 # A tibble: 0 × 0 ale_lm_rice |>    plot() |>    subset(list(d1 = TRUE)) ale_lm_rice |>    plot() |>    subset(list(d2 = TRUE)) # SLOW: uncomment to run yourself; load the saved object for rapid execution  # # p-value distribution # # Default 1000 iterations for exact p-values # tic() # pd_lm_rice <- ALEpDist(lm_rice, rice, parallel = 0) # toc()  # 542.13 sec elapsed # # saveRDS(pd_lm_rice, file.choose())  pd_lm_rice <- serialized_objects_site |>    file.path(\"pd_lm_rice.rds\") |>   url() |>    readRDS()   # SLOW: uncomment to run yourself; load the saved object for rapid execution  # # Full-model bootstrapped ALE explanation # # Default 100 bootstrap iterations # tic() # mb_lm_rice <- ModelBoot( #   lm_rice, rice, #   ale_options = list(x_cols = c('season', 'nitrogen', 'season:nitrogen')), #   ale_p = pd_lm_rice, #   parallel = 0 # ) # toc()  # 113.02 sec elapsed # # saveRDS(mb_lm_rice, file.choose())  mb_lm_rice <- serialized_objects_site |>    file.path(\"mb_lm_rice.rds\") |>   url() |>    readRDS() summary(mb_lm_rice)  # boot_valid SA 48.8%: MAE 0.918 # A tibble: 12 × 7    name          boot_valid conf.low  median    mean conf.high     sd    <chr>              <dbl>    <dbl>   <dbl>   <dbl>     <dbl>  <dbl>  1 r.squared         NA       0.193   0.444   0.449      0.715 0.134  2 adj.r.squared     NA       0.100   0.380   0.385      0.682 0.150  3 sigma             NA       0.621   0.907   0.907      1.13  0.137  4 statistic         NA       2.08    6.92    8.25      21.8   5.34  5 p.value           NA       0       0.0014  0.0129     0.130 0.0323  6 df                NA       3       3       3          3     0  7 df.residual       NA      26      26      26         26     0  8 nobs              NA      30      30      30         30     0  9 mae                0.918   0.634  NA      NA          1.45  0.232 10 sa_mae             0.488  -0.0793 NA      NA          0.649 0.191 11 rmse               1.14    0.770  NA      NA          2.12  0.354 12 sa_rmse            0.498   0.0366 NA      NA          0.652 0.176 # A tibble: 4 × 6   term               conf.low  median    mean conf.high std.error   <chr>                 <dbl>   <dbl>   <dbl>     <dbl>     <dbl> 1 (Intercept)          3.56    4.68    4.71      6.34      0.697 2 seasonwet           -0.550   1.16    1.27      4.18      1.20 3 nitrogen             0.0005  0.0149  0.0148    0.0273    0.007 4 seasonwet:nitrogen  -0.0483 -0.0236 -0.0236   -0.0063    0.0114 # A tibble: 3 × 7   term             aled aler_min aler_max naled naler_min naler_max   <fct>           <dbl>    <dbl>    <dbl> <dbl>     <dbl>     <dbl> 1 season          0.405   -0.416    0.421 14.9      -13.4      17.2 2 nitrogen        0.200   -0.391    0.463  8.69     -13.3      21.5 3 season:nitrogen 0.409   -1.06     0.793 15.0      -24.2      31.3 # A tibble: 6 × 8   statistic term            estimate p.value conf.low median   mean conf.high   <ord>     <fct>              <dbl>   <dbl>    <dbl>  <dbl>  <dbl>     <dbl> 1 aled      season             0.405   0.006   0.0483  0.445  0.405     0.860 2 aled      nitrogen           0.200   0.212   0.0245  0.184  0.200     0.463 3 aled      season:nitrogen    0.409   0.005   0.113   0.392  0.409     0.789 4 naled     season            14.9     0.053   0.581  14.9   14.9      33.1 5 naled     nitrogen           8.69    0.235   0       8.33   8.69     20.7 6 naled     season:nitrogen   15.0     0.049   1.32   14.6   15.0      28.6 # A tibble: 0 × 0 mb_lm_rice |>    plot() |>    subset(list(d1 = TRUE)) mb_lm_rice |>    plot() |>    subset(list(d2 = TRUE))"},{"path":"https://tripartio.github.io/ale/articles/ale-gomez-rice.html","id":"random-forest","dir":"Articles","previous_headings":"","what":"Random forest","title":"Analyzing a Small Rice Yield Dataset with ALE-Based Inference","text":"Next analyze data using random forest model. Let’s honest upfront: random forest well suited dataset small. include anyway demonstration purposes—show machine learning automatically best solution. Model choice match data, hype. use {ranger}, fast easy--use random forest implementation R. Tree-based models come three main varieties: Single decision trees. Random forests build many decision trees bootstrapped samples average bootstrap aggregation (bagging). Gradient boosted trees also builds multiple trees, sequentially, correcting previous one, though procedure called boosting. Gradient boosted trees often perform extremely well, use {ranger} random forests fast, simple, performs well default settings. random forest stochastic, set random seed. Otherwise, run produce slightly different results. Beyond , use default settings. random forest descriptive MAE 0.548 t/ha standardized accuracy 72.1%. Descriptively, looks much better OLS. descriptive performance easy part. {ale} package automatically recognizes {ranger} package, using default settings, easily creates ALE explanation.   random forest ALE plots, season effect similar ordinary least squares, nitrogen fertilizer effect quite different. , nitrogen shows inverted-U pattern (peaking around 60–90 kg/ha), interaction suggests different nitrogen behaviour across seasons. Still, shouldn’t get excited check predictive stability. bootstrap, performance less impressive purely descriptive metrics. random forest predictive MAE 0.641 t/ha standardized accuracy 64.6%. said, staccuracy 50% indicates least decent model. However, see can better, random forests don’t shine best small datasets like .   ’ll hold deeper interpretation random forest plots focus main interpretation GAM.","code":"# Precise performance metrics vary slightly for a random forest rf_rice <- ranger(   yield ~ .,    data = rice,   seed = 1  # ensure that the same random forest is generated each time ) sa_rf_rice  <- sa_wmae_mad(rice$yield, predict(rf_rice, rice)$predictions)  # 0.7222866 mae_rf_rice <- mae(rice$yield, predict(rf_rice, rice)$predictions)  # 0.5429936 rf_rice Ranger result  Call:  ranger(yield ~ ., data = rice, seed = 1)  Type:                             Regression Number of trees:                  500 Sample size:                      30 Number of independent variables:  2 Mtry:                             1 Target node size:                 5 Variable importance mode:         none Splitrule:                        variance OOB prediction error (MSE):       0.7410144 R squared (OOB):                  0.4787994 # Single ALE description ale_rf_rice <- ALE(   rf_rice,    x_cols = list(d1 = TRUE, d2 = TRUE),   data = rice,   # p_values = pd_rf_rice,   parallel = 0 )  summary(ale_rf_rice) # A tibble: 3 × 7   term             aled aler_min aler_max naled naler_min naler_max   <chr>           <dbl>    <dbl>    <dbl> <dbl>     <dbl>     <dbl> 1 season          0.358   -0.358    0.358 13.3      -13.3      13.3 2 nitrogen        0.255   -0.848    0.409 11.3      -16.7      13.3 3 season:nitrogen 0.185   -0.543    0.290  7.67     -16.7      13.3 # A tibble: 6 × 7   statistic term            estimate conf.low   mean median conf.high   <ord>     <chr>              <dbl>    <dbl>  <dbl>  <dbl>     <dbl> 1 aled      season             0.358    0.358  0.358  0.358     0.358 2 aled      nitrogen           0.255    0.255  0.255  0.255     0.255 3 aled      season:nitrogen    0.185    0.185  0.185  0.185     0.185 4 naled     season            13.3     13.3   13.3   13.3      13.3 5 naled     nitrogen          11.3     11.3   11.3   11.3      11.3 6 naled     season:nitrogen    7.67     7.67   7.67   7.67      7.67 # A tibble: 0 × 0 ale_rf_rice |>    plot() |>    subset(list(d1 = TRUE)) ale_rf_rice |>    plot() |>    subset(list(d2 = TRUE)) # SLOW: uncomment to run yourself; load the saved object for rapid execution  # # p-value distribution # # Default 1000 iterations for exact p-values # tic() # pd_rf_rice <- ALEpDist( #   rf_rice, rice, #   parallel = 0 # ) # toc()  # 560.64 sec elapsed # # saveRDS(pd_rf_rice, file.choose())  pd_rf_rice <- serialized_objects_site |>    file.path(\"pd_rf_rice.rds\") |>   url() |>    readRDS()   # SLOW: uncomment to run yourself; load the saved object for rapid execution  # # Full-model bootstrapped ALE explanation # # Default 100 bootstrap iterations # tic() # mb_rf_rice <- ModelBoot( #   rf_rice, rice, #   ale_options = list(x_cols = c('season', 'nitrogen', 'season:nitrogen')), #   ale_p = pd_rf_rice, #   parallel = 0 # ) # toc()  # 70.89 sec elapsed # # saveRDS(mb_rf_rice, file.choose())  mb_rf_rice <- serialized_objects_site |>    file.path(\"mb_rf_rice.rds\") |>   url() |>    readRDS() summary(mb_rf_rice)  # boot_valid SA 64.6%; MAE 0.6400844 # A tibble: 4 × 7   name    boot_valid conf.low median  mean conf.high     sd   <chr>        <dbl>    <dbl>  <dbl> <dbl>     <dbl>  <dbl> 1 mae          0.641    0.421     NA    NA     0.950 0.141 2 sa_mae       0.646    0.363     NA    NA     0.744 0.108 3 rmse         0.807    0.520     NA    NA     1.27  0.209 4 sa_rmse      0.647    0.404     NA    NA     0.735 0.0804 # A tibble: 3 × 7   term             aled aler_min aler_max naled naler_min naler_max   <fct>           <dbl>    <dbl>    <dbl> <dbl>     <dbl>     <dbl> 1 season          0.339   -0.349    0.350 13.6      -13.2      14.7 2 nitrogen        0.256   -0.868    0.433 11.6      -21.8      18.5 3 season:nitrogen 0.188   -0.523    0.331  8.17     -17.0      14.0 # A tibble: 6 × 8   statistic term            estimate p.value conf.low median   mean conf.high   <ord>     <fct>              <dbl>   <dbl>    <dbl>  <dbl>  <dbl>     <dbl> 1 aled      season             0.339   0.008   0.0813  0.352  0.339     0.580 2 aled      nitrogen           0.256   0.054   0.144   0.240  0.256     0.400 3 aled      season:nitrogen    0.188   0.205   0.0904  0.180  0.188     0.301 4 naled     season            13.6     0.059   1.59   13.8   13.6      24.7 5 naled     nitrogen          11.6     0.225   2.88   11.1   11.6      20.7 6 naled     season:nitrogen    8.17    0.835   2.17    7.67   8.17     15.2 # A tibble: 0 × 0 mb_rf_rice |>    plot() |>    subset(list(d1 = TRUE)) mb_rf_rice |>    plot() |>    subset(list(d2 = TRUE))"},{"path":"https://tripartio.github.io/ale/articles/ale-gomez-rice.html","id":"model-training-1","dir":"Articles","previous_headings":"","what":"Model training","title":"Analyzing a Small Rice Yield Dataset with ALE-Based Inference","text":"random forest stochastic, set random seed. Otherwise, run produce slightly different results. Beyond , use default settings. random forest descriptive MAE 0.548 t/ha standardized accuracy 72.1%. Descriptively, looks much better OLS. descriptive performance easy part.","code":"# Precise performance metrics vary slightly for a random forest rf_rice <- ranger(   yield ~ .,    data = rice,   seed = 1  # ensure that the same random forest is generated each time ) sa_rf_rice  <- sa_wmae_mad(rice$yield, predict(rf_rice, rice)$predictions)  # 0.7222866 mae_rf_rice <- mae(rice$yield, predict(rf_rice, rice)$predictions)  # 0.5429936 rf_rice Ranger result  Call:  ranger(yield ~ ., data = rice, seed = 1)  Type:                             Regression Number of trees:                  500 Sample size:                      30 Number of independent variables:  2 Mtry:                             1 Target node size:                 5 Variable importance mode:         none Splitrule:                        variance OOB prediction error (MSE):       0.7410144 R squared (OOB):                  0.4787994"},{"path":"https://tripartio.github.io/ale/articles/ale-gomez-rice.html","id":"ale-analysis-1","dir":"Articles","previous_headings":"","what":"ALE analysis","title":"Analyzing a Small Rice Yield Dataset with ALE-Based Inference","text":"{ale} package automatically recognizes {ranger} package, using default settings, easily creates ALE explanation.   random forest ALE plots, season effect similar ordinary least squares, nitrogen fertilizer effect quite different. , nitrogen shows inverted-U pattern (peaking around 60–90 kg/ha), interaction suggests different nitrogen behaviour across seasons. Still, shouldn’t get excited check predictive stability. bootstrap, performance less impressive purely descriptive metrics. random forest predictive MAE 0.641 t/ha standardized accuracy 64.6%. said, staccuracy 50% indicates least decent model. However, see can better, random forests don’t shine best small datasets like .   ’ll hold deeper interpretation random forest plots focus main interpretation GAM.","code":"# Single ALE description ale_rf_rice <- ALE(   rf_rice,    x_cols = list(d1 = TRUE, d2 = TRUE),   data = rice,   # p_values = pd_rf_rice,   parallel = 0 )  summary(ale_rf_rice) # A tibble: 3 × 7   term             aled aler_min aler_max naled naler_min naler_max   <chr>           <dbl>    <dbl>    <dbl> <dbl>     <dbl>     <dbl> 1 season          0.358   -0.358    0.358 13.3      -13.3      13.3 2 nitrogen        0.255   -0.848    0.409 11.3      -16.7      13.3 3 season:nitrogen 0.185   -0.543    0.290  7.67     -16.7      13.3 # A tibble: 6 × 7   statistic term            estimate conf.low   mean median conf.high   <ord>     <chr>              <dbl>    <dbl>  <dbl>  <dbl>     <dbl> 1 aled      season             0.358    0.358  0.358  0.358     0.358 2 aled      nitrogen           0.255    0.255  0.255  0.255     0.255 3 aled      season:nitrogen    0.185    0.185  0.185  0.185     0.185 4 naled     season            13.3     13.3   13.3   13.3      13.3 5 naled     nitrogen          11.3     11.3   11.3   11.3      11.3 6 naled     season:nitrogen    7.67     7.67   7.67   7.67      7.67 # A tibble: 0 × 0 ale_rf_rice |>    plot() |>    subset(list(d1 = TRUE)) ale_rf_rice |>    plot() |>    subset(list(d2 = TRUE)) # SLOW: uncomment to run yourself; load the saved object for rapid execution  # # p-value distribution # # Default 1000 iterations for exact p-values # tic() # pd_rf_rice <- ALEpDist( #   rf_rice, rice, #   parallel = 0 # ) # toc()  # 560.64 sec elapsed # # saveRDS(pd_rf_rice, file.choose())  pd_rf_rice <- serialized_objects_site |>    file.path(\"pd_rf_rice.rds\") |>   url() |>    readRDS()   # SLOW: uncomment to run yourself; load the saved object for rapid execution  # # Full-model bootstrapped ALE explanation # # Default 100 bootstrap iterations # tic() # mb_rf_rice <- ModelBoot( #   rf_rice, rice, #   ale_options = list(x_cols = c('season', 'nitrogen', 'season:nitrogen')), #   ale_p = pd_rf_rice, #   parallel = 0 # ) # toc()  # 70.89 sec elapsed # # saveRDS(mb_rf_rice, file.choose())  mb_rf_rice <- serialized_objects_site |>    file.path(\"mb_rf_rice.rds\") |>   url() |>    readRDS() summary(mb_rf_rice)  # boot_valid SA 64.6%; MAE 0.6400844 # A tibble: 4 × 7   name    boot_valid conf.low median  mean conf.high     sd   <chr>        <dbl>    <dbl>  <dbl> <dbl>     <dbl>  <dbl> 1 mae          0.641    0.421     NA    NA     0.950 0.141 2 sa_mae       0.646    0.363     NA    NA     0.744 0.108 3 rmse         0.807    0.520     NA    NA     1.27  0.209 4 sa_rmse      0.647    0.404     NA    NA     0.735 0.0804 # A tibble: 3 × 7   term             aled aler_min aler_max naled naler_min naler_max   <fct>           <dbl>    <dbl>    <dbl> <dbl>     <dbl>     <dbl> 1 season          0.339   -0.349    0.350 13.6      -13.2      14.7 2 nitrogen        0.256   -0.868    0.433 11.6      -21.8      18.5 3 season:nitrogen 0.188   -0.523    0.331  8.17     -17.0      14.0 # A tibble: 6 × 8   statistic term            estimate p.value conf.low median   mean conf.high   <ord>     <fct>              <dbl>   <dbl>    <dbl>  <dbl>  <dbl>     <dbl> 1 aled      season             0.339   0.008   0.0813  0.352  0.339     0.580 2 aled      nitrogen           0.256   0.054   0.144   0.240  0.256     0.400 3 aled      season:nitrogen    0.188   0.205   0.0904  0.180  0.188     0.301 4 naled     season            13.6     0.059   1.59   13.8   13.6      24.7 5 naled     nitrogen          11.6     0.225   2.88   11.1   11.6      20.7 6 naled     season:nitrogen    8.17    0.835   2.17    7.67   8.17     15.2 # A tibble: 0 × 0 mb_rf_rice |>    plot() |>    subset(list(d1 = TRUE)) mb_rf_rice |>    plot() |>    subset(list(d2 = TRUE))"},{"path":"https://tripartio.github.io/ale/articles/ale-gomez-rice.html","id":"gam","dir":"Articles","previous_headings":"","what":"GAM","title":"Analyzing a Small Rice Yield Dataset with ALE-Based Inference","text":"Now move generalized additive models (GAMs). GAM sits within broader generalized linear model (GLM) family, unlike standard linear regression (OLS), allows nonlinear relationships. Instead forcing straight lines, lets data determine shape relationship. properly configured, GAMs work especially well small datasets like . offer flexibility without giving structure. Appropriately configuring GAMs much art science, won’t get arrived specific configuration use . However, key structure straightforward. model yield function season, include nitrogen interaction season. means nitrogen entered simple main effect; instead, relationship yield allowed differ season. way, nitrogen fully incorporated model. use {mgcv} package GAM. won’t -interpret GAM coefficients; useful story comes performance ALE surfaces. adjusted R-squared 0.745, don’t compare number directly OLS random forest, different model classes compute “R-squared” different ways. MAE standardized accuracy comparable across models, though. Using preferred, comparable metrics, GAM descriptive MAE 0.39 t/ha standardized accuracy 80.2%. far, best descriptive performance. emphasize, though, prescriptive metrics reliable. parametric part GAM summary, season shows negative shift going dry wet (lower yield wet), statistically significant. Nitrogen included via season-specific smooth interaction, effect isn’t summarized single tidy coefficient. interpretable coefficient interaction season nitrogen. see instead estimated degrees freedom (EDF), tell us extent interaction nonlinear. statistically significant EDFs confirm nonlinearity, describe direction shape effect. GAM requires plots interpretive step. exactly turn ALE. ALE incorporates full structure model allows us visualize quantify effect nitrogen even though specified simple parametric term. Next, use ALE examine shape fitted relationships give us model-agnostic statistics. ALE summary, GAM shows larger ALED effects (roughly 400 kg/ha scale) season, nitrogen, interaction earlier models. ’ll interpret carefully look plots.   season main-effect plot identical saw OLS, can expected, since GAM treats simple factor variables way OLS . Nitrogen different story. OLS, effect looked roughly linear increasing. GAM, see something realistic. Yield lowest zero nitrogen, rises sharply, peaks around 60–75 kg/ha, declines higher levels. 120 150 kg/ha, yield drops relative peak. words, see inverted U-shape. consistent observed {ranger} model. Now turn nitrogen × season interaction. first glance, plot appears suggest less fertilizer gives better yields wet season, fertilizer benefits dry season. interpretation misleading. fact, ALE structural quirk interactions present. interactions, 1D ALE plots reflect intuitive main effects. interactions exist: 1D ALE (main effects) represent total effect variable, including interaction effects. 2D ALE interaction plots represent additional interaction component, subtracting composite main effects. case: season ALE plot reflects total season effect, including interaction nitrogen. nitrogen ALE plot reflects total nitrogen effect, including interaction season. season × nitrogen plot shows extra interaction effect beyond two main effects. means interaction surface saying nitrogen reduces yield wet season overall. Instead, given inverted U-shape, tells us dry season tolerates higher nitrogen better, wet season declines sharply past peak. extremes low high nitrogen behave differently across seasons shared nonlinear pattern removed. Admittedly, decomposition especially intuitive. known limitation ALE formulation area interpretation requires care. far, preliminary patterns. assess reliability, now generate p-value distribution perform full model bootstrapping GAM. GAM predictive MAE 0.531 t/ha standardized accuracy 70.1%. represents drop 10% staccuracy descriptive predictive model, can expected small dataset, nonetheless represents accurate model. Thus, interpret bootstrapped results earnest, since ’s best . bootstrapped ALE results, three relationships (season nitrogen main effects season × nitrogen interaction effect) come highly significant p-values (p < 0.001), effect sizes around 400 kg/ha. Notably, compared OLS random forest results, accurate GAM model produce statistically significant confident regions, season × nitrogen interaction. can better interpret implications examining bootstrapped plots.   One caution: ALE “main effects” include interaction contributions design. season main effect includes season–nitrogen interaction (excluding nitrogen-effects), nitrogen main effect includes interaction (excluding season-effects). 2D interaction surface part beyond two main effects. ’s slightly awkward, ’s standard ALE definition, must carefully interpret results accordingly. Let’s look first main-effect plots. every model, dry-season yield appears higher wet-season yield. random forest model, see inverted U-shape nitrogen. However, cases, ALER band wide. tells us uncertainty high. ALER band represents range variation plausibly random. main effects, bootstrap confidence regions clearly exceed band. words, even though curves look different, differences beyond random fluctuation produce. 30 observations, surprising. necessarily relationships exist; likely borne replications experiment. Turning interaction plot, surface overlaps ALER band, much appears grey. extremes, however, strong indications structure. dry season, highest nitrogen level (150 kg/ha) slightly exceeds ALER band, suggesting stronger response high nitrogen. contrast, wet season, lowest yields occur highest nitrogen levels, strongest yields occur lower nitrogen–boundaries exceed ALER band randomness. ALE statistics confirm interaction effect meets significance criterion ALE-based inference, based least 10% surface falling outside two-dimensional ALER band. main effects remain within band therefore statistically significant.","code":"gam_rice <- gam(   yield ~ season + ti(nitrogen, by = season, bs = \"ps\"),   data = rice,   # REML is recommended for more accurate estimation, though slightly slower   method = 'REML'   ) # workaround a pgkdown bug (probably temporary) gam_preds <- predict(gam_rice) |> as.numeric()  sa_gam_rice  <- sa_wmae_mad(rice$yield, gam_preds)  # 0.8015714 mae_gam_rice <- mae(rice$yield, gam_preds)  # 0.3898126 summary(gam_rice) Family: gaussian Link function: identity  Formula: yield ~ season + ti(nitrogen, by = season, bs = \"ps\")  Parametric coefficients:             Estimate Std. Error t value Pr(>|t|) (Intercept)   5.9023     0.1556  37.931   <2e-16 *** seasonwet    -0.7744     0.2201  -3.519   0.0018 ** --- Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1  Approximate significance of smooth terms:                          edf Ref.df     F  p-value ti(nitrogen):seasondry 2.141  2.387 16.01 2.07e-05 *** ti(nitrogen):seasonwet 2.346  2.636 14.55 4.57e-05 *** --- Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1  R-sq.(adj) =  0.745   Deviance explained = 79.3% -REML = 30.862  Scale est. = 0.36319   n = 30 # Single ALE description ale_gam_rice <- ALE(   gam_rice,    x_cols = list(d1 = TRUE, d2 = TRUE),   data = rice,   # p_values = pd_gam_rice,   parallel = 0 )  summary(ale_gam_rice) # A tibble: 3 × 7   term             aled aler_min aler_max naled naler_min naler_max   <chr>           <dbl>    <dbl>    <dbl> <dbl>     <dbl>     <dbl> 1 season          0.387   -0.387    0.387  13.3     -13.3      13.3 2 nitrogen        0.400   -1.28     0.648  15.3     -26.7      23.3 3 season:nitrogen 0.408   -1.16     0.636  15       -26.7      23.3 # A tibble: 6 × 7   statistic term            estimate conf.low   mean median conf.high   <ord>     <chr>              <dbl>    <dbl>  <dbl>  <dbl>     <dbl> 1 aled      season             0.387    0.387  0.387  0.387     0.387 2 aled      nitrogen           0.400    0.400  0.400  0.400     0.400 3 aled      season:nitrogen    0.408    0.408  0.408  0.408     0.408 4 naled     season            13.3     13.3   13.3   13.3      13.3 5 naled     nitrogen          15.3     15.3   15.3   15.3      15.3 6 naled     season:nitrogen   15       15     15     15        15 # A tibble: 0 × 0 ale_gam_rice |>    plot() |>    subset(list(d1 = TRUE)) ale_gam_rice |>    plot() |>    subset(list(d2 = TRUE)) # SLOW: uncomment to run yourself; load the saved object for rapid execution  # # p-value distribution # # Default 1000 iterations for exact p-values # tic() # pd_gam_rice <- ALEpDist(gam_rice, rice, parallel = 0) # toc()  # 612.22 sec elapsed # # saveRDS(pd_gam_rice, file.choose())  pd_gam_rice <- serialized_objects_site |>    file.path(\"pd_gam_rice.rds\") |>   url() |>    readRDS()   # SLOW: uncomment to run yourself; load the saved object for rapid execution  # # Full-model bootstrapped ALE explanation # # Default 100 bootstrap iterations # tic() # mb_gam_rice <- ModelBoot( #   gam_rice, rice, #   ale_options = list(x_cols = c('season', 'nitrogen', 'season:nitrogen')), #   ale_p = pd_gam_rice, #   parallel = 0 # ) # toc()  # 83.5 sec elapsed # # saveRDS(mb_gam_rice, file.choose())  mb_gam_rice <- serialized_objects_site |>    file.path(\"mb_gam_rice.rds\") |>   url() |>    readRDS() summary(mb_gam_rice)  # boot_valid SA 70.0%; MAE 0.531 # A tibble: 9 × 7   name          boot_valid conf.low median   mean conf.high     sd   <chr>              <dbl>    <dbl>  <dbl>  <dbl>     <dbl>  <dbl> 1 df                NA        5.63   6.57   6.64      7.50  0.478 2 df.residual       NA       22.5   23.4   23.4      24.4   0.478 3 nobs              NA       30     30     30        30     0 4 adj.r.squared     NA        0.691  0.817  0.817     0.953 0.0684 5 npar              NA       10     10     10        10     0 6 mae                0.531    0.311 NA     NA         1.21  0.216 7 sa_mae             0.700    0.295 NA     NA         0.835 0.159 8 rmse               0.732    0.427 NA     NA         1.88  0.324 9 sa_rmse            0.673    0.12  NA     NA         0.823 0.171 # A tibble: 2 × 6   term                   conf.low median  mean conf.high std.error   <chr>                     <dbl>  <dbl> <dbl>     <dbl>     <dbl> 1 ti(nitrogen):seasondry     1.70   2.19  2.20      2.73     0.261 2 ti(nitrogen):seasonwet     1.11   2.45  2.44      3.20     0.408 # A tibble: 3 × 7   term             aled aler_min aler_max naled naler_min naler_max   <fct>           <dbl>    <dbl>    <dbl> <dbl>     <dbl>     <dbl> 1 season          0.394   -0.406    0.409  14.7     -13.5      16.8 2 nitrogen        0.389   -1.31     0.687  15.6     -28.1      29.7 3 season:nitrogen 0.418   -1.15     0.769  15.7     -25.4      30.5 # A tibble: 6 × 8   statistic term            estimate p.value conf.low median   mean conf.high   <ord>     <fct>              <dbl>   <dbl>    <dbl>  <dbl>  <dbl>     <dbl> 1 aled      season             0.394   0       0.0529  0.404  0.394     0.708 2 aled      nitrogen           0.389   0       0.207   0.382  0.389     0.604 3 aled      season:nitrogen    0.418   0       0.236   0.404  0.418     0.678 4 naled     season            14.7     0.006   0.581  14.8   14.7      29.9 5 naled     nitrogen          15.6     0.003   5.21   14.9   15.6      26.8 6 naled     season:nitrogen   15.7     0.003   6.76   15.2   15.7      26.4 # A tibble: 6 × 8   term1  x1    term2    x2        aler_band     n   pct     y   <chr>  <chr> <chr>    <chr>     <ord>     <int> <dbl> <dbl> 1 season dry   nitrogen [0,60]    overlap       6    20  5.61 2 season wet   nitrogen [0,60]    overlap       6    20  6.59 3 season dry   nitrogen (60,120]  overlap       6    20  6.04 4 season wet   nitrogen (60,120]  overlap       6    20  5.33 5 season dry   nitrogen (120,150] overlap       3    10  6.35 6 season wet   nitrogen (120,150] below         3    10  4.44 mb_gam_rice |>    plot() |>    subset(list(d1 = TRUE)) mb_gam_rice |>    plot() |>    subset(list(d2 = TRUE))"},{"path":"https://tripartio.github.io/ale/articles/ale-gomez-rice.html","id":"model-training-2","dir":"Articles","previous_headings":"","what":"Model training","title":"Analyzing a Small Rice Yield Dataset with ALE-Based Inference","text":"Appropriately configuring GAMs much art science, won’t get arrived specific configuration use . However, key structure straightforward. model yield function season, include nitrogen interaction season. means nitrogen entered simple main effect; instead, relationship yield allowed differ season. way, nitrogen fully incorporated model. use {mgcv} package GAM. won’t -interpret GAM coefficients; useful story comes performance ALE surfaces. adjusted R-squared 0.745, don’t compare number directly OLS random forest, different model classes compute “R-squared” different ways. MAE standardized accuracy comparable across models, though. Using preferred, comparable metrics, GAM descriptive MAE 0.39 t/ha standardized accuracy 80.2%. far, best descriptive performance. emphasize, though, prescriptive metrics reliable. parametric part GAM summary, season shows negative shift going dry wet (lower yield wet), statistically significant. Nitrogen included via season-specific smooth interaction, effect isn’t summarized single tidy coefficient. interpretable coefficient interaction season nitrogen. see instead estimated degrees freedom (EDF), tell us extent interaction nonlinear. statistically significant EDFs confirm nonlinearity, describe direction shape effect. GAM requires plots interpretive step. exactly turn ALE. ALE incorporates full structure model allows us visualize quantify effect nitrogen even though specified simple parametric term.","code":"gam_rice <- gam(   yield ~ season + ti(nitrogen, by = season, bs = \"ps\"),   data = rice,   # REML is recommended for more accurate estimation, though slightly slower   method = 'REML'   ) # workaround a pgkdown bug (probably temporary) gam_preds <- predict(gam_rice) |> as.numeric()  sa_gam_rice  <- sa_wmae_mad(rice$yield, gam_preds)  # 0.8015714 mae_gam_rice <- mae(rice$yield, gam_preds)  # 0.3898126 summary(gam_rice) Family: gaussian Link function: identity  Formula: yield ~ season + ti(nitrogen, by = season, bs = \"ps\")  Parametric coefficients:             Estimate Std. Error t value Pr(>|t|) (Intercept)   5.9023     0.1556  37.931   <2e-16 *** seasonwet    -0.7744     0.2201  -3.519   0.0018 ** --- Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1  Approximate significance of smooth terms:                          edf Ref.df     F  p-value ti(nitrogen):seasondry 2.141  2.387 16.01 2.07e-05 *** ti(nitrogen):seasonwet 2.346  2.636 14.55 4.57e-05 *** --- Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1  R-sq.(adj) =  0.745   Deviance explained = 79.3% -REML = 30.862  Scale est. = 0.36319   n = 30"},{"path":"https://tripartio.github.io/ale/articles/ale-gomez-rice.html","id":"single-ale-on-entire-dataset","dir":"Articles","previous_headings":"","what":"Single ALE on entire dataset","title":"Analyzing a Small Rice Yield Dataset with ALE-Based Inference","text":"Next, use ALE examine shape fitted relationships give us model-agnostic statistics. ALE summary, GAM shows larger ALED effects (roughly 400 kg/ha scale) season, nitrogen, interaction earlier models. ’ll interpret carefully look plots.   season main-effect plot identical saw OLS, can expected, since GAM treats simple factor variables way OLS . Nitrogen different story. OLS, effect looked roughly linear increasing. GAM, see something realistic. Yield lowest zero nitrogen, rises sharply, peaks around 60–75 kg/ha, declines higher levels. 120 150 kg/ha, yield drops relative peak. words, see inverted U-shape. consistent observed {ranger} model. Now turn nitrogen × season interaction. first glance, plot appears suggest less fertilizer gives better yields wet season, fertilizer benefits dry season. interpretation misleading. fact, ALE structural quirk interactions present. interactions, 1D ALE plots reflect intuitive main effects. interactions exist: 1D ALE (main effects) represent total effect variable, including interaction effects. 2D ALE interaction plots represent additional interaction component, subtracting composite main effects. case: season ALE plot reflects total season effect, including interaction nitrogen. nitrogen ALE plot reflects total nitrogen effect, including interaction season. season × nitrogen plot shows extra interaction effect beyond two main effects. means interaction surface saying nitrogen reduces yield wet season overall. Instead, given inverted U-shape, tells us dry season tolerates higher nitrogen better, wet season declines sharply past peak. extremes low high nitrogen behave differently across seasons shared nonlinear pattern removed. Admittedly, decomposition especially intuitive. known limitation ALE formulation area interpretation requires care.","code":"# Single ALE description ale_gam_rice <- ALE(   gam_rice,    x_cols = list(d1 = TRUE, d2 = TRUE),   data = rice,   # p_values = pd_gam_rice,   parallel = 0 )  summary(ale_gam_rice) # A tibble: 3 × 7   term             aled aler_min aler_max naled naler_min naler_max   <chr>           <dbl>    <dbl>    <dbl> <dbl>     <dbl>     <dbl> 1 season          0.387   -0.387    0.387  13.3     -13.3      13.3 2 nitrogen        0.400   -1.28     0.648  15.3     -26.7      23.3 3 season:nitrogen 0.408   -1.16     0.636  15       -26.7      23.3 # A tibble: 6 × 7   statistic term            estimate conf.low   mean median conf.high   <ord>     <chr>              <dbl>    <dbl>  <dbl>  <dbl>     <dbl> 1 aled      season             0.387    0.387  0.387  0.387     0.387 2 aled      nitrogen           0.400    0.400  0.400  0.400     0.400 3 aled      season:nitrogen    0.408    0.408  0.408  0.408     0.408 4 naled     season            13.3     13.3   13.3   13.3      13.3 5 naled     nitrogen          15.3     15.3   15.3   15.3      15.3 6 naled     season:nitrogen   15       15     15     15        15 # A tibble: 0 × 0 ale_gam_rice |>    plot() |>    subset(list(d1 = TRUE)) ale_gam_rice |>    plot() |>    subset(list(d2 = TRUE))"},{"path":"https://tripartio.github.io/ale/articles/ale-gomez-rice.html","id":"ale-on-bootstrapped-models","dir":"Articles","previous_headings":"","what":"ALE on bootstrapped models","title":"Analyzing a Small Rice Yield Dataset with ALE-Based Inference","text":"far, preliminary patterns. assess reliability, now generate p-value distribution perform full model bootstrapping GAM. GAM predictive MAE 0.531 t/ha standardized accuracy 70.1%. represents drop 10% staccuracy descriptive predictive model, can expected small dataset, nonetheless represents accurate model. Thus, interpret bootstrapped results earnest, since ’s best . bootstrapped ALE results, three relationships (season nitrogen main effects season × nitrogen interaction effect) come highly significant p-values (p < 0.001), effect sizes around 400 kg/ha. Notably, compared OLS random forest results, accurate GAM model produce statistically significant confident regions, season × nitrogen interaction. can better interpret implications examining bootstrapped plots.   One caution: ALE “main effects” include interaction contributions design. season main effect includes season–nitrogen interaction (excluding nitrogen-effects), nitrogen main effect includes interaction (excluding season-effects). 2D interaction surface part beyond two main effects. ’s slightly awkward, ’s standard ALE definition, must carefully interpret results accordingly. Let’s look first main-effect plots. every model, dry-season yield appears higher wet-season yield. random forest model, see inverted U-shape nitrogen. However, cases, ALER band wide. tells us uncertainty high. ALER band represents range variation plausibly random. main effects, bootstrap confidence regions clearly exceed band. words, even though curves look different, differences beyond random fluctuation produce. 30 observations, surprising. necessarily relationships exist; likely borne replications experiment. Turning interaction plot, surface overlaps ALER band, much appears grey. extremes, however, strong indications structure. dry season, highest nitrogen level (150 kg/ha) slightly exceeds ALER band, suggesting stronger response high nitrogen. contrast, wet season, lowest yields occur highest nitrogen levels, strongest yields occur lower nitrogen–boundaries exceed ALER band randomness. ALE statistics confirm interaction effect meets significance criterion ALE-based inference, based least 10% surface falling outside two-dimensional ALER band. main effects remain within band therefore statistically significant.","code":"# SLOW: uncomment to run yourself; load the saved object for rapid execution  # # p-value distribution # # Default 1000 iterations for exact p-values # tic() # pd_gam_rice <- ALEpDist(gam_rice, rice, parallel = 0) # toc()  # 612.22 sec elapsed # # saveRDS(pd_gam_rice, file.choose())  pd_gam_rice <- serialized_objects_site |>    file.path(\"pd_gam_rice.rds\") |>   url() |>    readRDS()   # SLOW: uncomment to run yourself; load the saved object for rapid execution  # # Full-model bootstrapped ALE explanation # # Default 100 bootstrap iterations # tic() # mb_gam_rice <- ModelBoot( #   gam_rice, rice, #   ale_options = list(x_cols = c('season', 'nitrogen', 'season:nitrogen')), #   ale_p = pd_gam_rice, #   parallel = 0 # ) # toc()  # 83.5 sec elapsed # # saveRDS(mb_gam_rice, file.choose())  mb_gam_rice <- serialized_objects_site |>    file.path(\"mb_gam_rice.rds\") |>   url() |>    readRDS() summary(mb_gam_rice)  # boot_valid SA 70.0%; MAE 0.531 # A tibble: 9 × 7   name          boot_valid conf.low median   mean conf.high     sd   <chr>              <dbl>    <dbl>  <dbl>  <dbl>     <dbl>  <dbl> 1 df                NA        5.63   6.57   6.64      7.50  0.478 2 df.residual       NA       22.5   23.4   23.4      24.4   0.478 3 nobs              NA       30     30     30        30     0 4 adj.r.squared     NA        0.691  0.817  0.817     0.953 0.0684 5 npar              NA       10     10     10        10     0 6 mae                0.531    0.311 NA     NA         1.21  0.216 7 sa_mae             0.700    0.295 NA     NA         0.835 0.159 8 rmse               0.732    0.427 NA     NA         1.88  0.324 9 sa_rmse            0.673    0.12  NA     NA         0.823 0.171 # A tibble: 2 × 6   term                   conf.low median  mean conf.high std.error   <chr>                     <dbl>  <dbl> <dbl>     <dbl>     <dbl> 1 ti(nitrogen):seasondry     1.70   2.19  2.20      2.73     0.261 2 ti(nitrogen):seasonwet     1.11   2.45  2.44      3.20     0.408 # A tibble: 3 × 7   term             aled aler_min aler_max naled naler_min naler_max   <fct>           <dbl>    <dbl>    <dbl> <dbl>     <dbl>     <dbl> 1 season          0.394   -0.406    0.409  14.7     -13.5      16.8 2 nitrogen        0.389   -1.31     0.687  15.6     -28.1      29.7 3 season:nitrogen 0.418   -1.15     0.769  15.7     -25.4      30.5 # A tibble: 6 × 8   statistic term            estimate p.value conf.low median   mean conf.high   <ord>     <fct>              <dbl>   <dbl>    <dbl>  <dbl>  <dbl>     <dbl> 1 aled      season             0.394   0       0.0529  0.404  0.394     0.708 2 aled      nitrogen           0.389   0       0.207   0.382  0.389     0.604 3 aled      season:nitrogen    0.418   0       0.236   0.404  0.418     0.678 4 naled     season            14.7     0.006   0.581  14.8   14.7      29.9 5 naled     nitrogen          15.6     0.003   5.21   14.9   15.6      26.8 6 naled     season:nitrogen   15.7     0.003   6.76   15.2   15.7      26.4 # A tibble: 6 × 8   term1  x1    term2    x2        aler_band     n   pct     y   <chr>  <chr> <chr>    <chr>     <ord>     <int> <dbl> <dbl> 1 season dry   nitrogen [0,60]    overlap       6    20  5.61 2 season wet   nitrogen [0,60]    overlap       6    20  6.59 3 season dry   nitrogen (60,120]  overlap       6    20  6.04 4 season wet   nitrogen (60,120]  overlap       6    20  5.33 5 season dry   nitrogen (120,150] overlap       3    10  6.35 6 season wet   nitrogen (120,150] below         3    10  4.44 mb_gam_rice |>    plot() |>    subset(list(d1 = TRUE)) mb_gam_rice |>    plot() |>    subset(list(d2 = TRUE))"},{"path":"https://tripartio.github.io/ale/articles/ale-gomez-rice.html","id":"discussion","dir":"Articles","previous_headings":"","what":"Discussion","title":"Analyzing a Small Rice Yield Dataset with ALE-Based Inference","text":"Section 8.1.1, Gomez Gomez (1984) analyze dataset using randomized complete block design combined ANOVA seasons. conclude nitrogen significantly affects yield. season × nitrogen interaction highly significant. overall nitrogen response quadratic. seasonal difference lies mainly linear component quadratic curve. practical terms, conclude yield increases sharply nitrogen dry season compute separate yield-maximizing profit-maximizing nitrogen rates dry wet seasons. explicitly recommend different nitrogen applications season. note modelling approach directly comparable initial OLS specification. imposed quadratic structure nitrogen. requires prior knowledge expected response shape. avoided assumption using GAM, detects nonlinearities automatically defaults linear relationships appropriate. tradeoff flexibility reduces classical interpretability. GAM provides overall model reliability, direct parametric validation discovered curve. ALE fills gap providing confidence regions, p-values, interpretable uncertainty bands. analysis agrees Gomez Gomez several structural conclusions. Nonlinear nitrogen response. Across models, nitrogen shows inverted U-shape. matches finding quadratic component dominates nitrogen sum squares adequately fits data. Season-dependent nitrogen response. ALE interaction surfaces indicate nitrogen behaves differently wet dry seasons. aligns significant season × nitrogen interaction. Stronger nitrogen response dry season. GAM ALE suggest yield increases strongly nitrogen dry season, especially lower moderate range. supports interpretation linear component differs season. Structurally, analyses describe response surface: nonlinear nitrogen effects season-specific slopes. disagreement lies inference, shape. Strength statistical evidence. Gomez Gomez report highly significant nitrogen interaction effects pooled-error ANOVA. bootstrap-based ALE inference, main effects clearly exceed uncertainty bands, parts interaction surface appear significant. difference stems methodology: fixed-form ANOVA contrasts versus resampling-based stability assessment. 30 cases, fragility expected. Strength recommendation. Gomez Gomez compute optimal nitrogen rates recommend season-specific application levels. stop short firm recommendations bootstrap uncertainty remains large relative effect size. Classical ANOVA delivers decisive significance. ALE-based inference bootstrap resampling yields cautious conclusions. Without contradicting findings, analysis adds two perspectives. Predictive validation. Gomez Gomez emphasize inferential ANOVA significance. evaluate predictive performance using standardized accuracy MAE. GAM performs best bootstrap validation, suggesting flexible nonlinear modelling well suited dataset. Uncertainty visualization. ALE ALER bands explicitly show much variation plausibly random. Gomez Gomez rely high R² judge quadratic fit, bootstrap perspective highlights uncertain relationships may small samples.","code":""},{"path":"https://tripartio.github.io/ale/articles/ale-gomez-rice.html","id":"comparison-with-gomez-and-gomez-1984","dir":"Articles","previous_headings":"","what":"Comparison with Gomez and Gomez (1984)","title":"Analyzing a Small Rice Yield Dataset with ALE-Based Inference","text":"Section 8.1.1, Gomez Gomez (1984) analyze dataset using randomized complete block design combined ANOVA seasons. conclude nitrogen significantly affects yield. season × nitrogen interaction highly significant. overall nitrogen response quadratic. seasonal difference lies mainly linear component quadratic curve. practical terms, conclude yield increases sharply nitrogen dry season compute separate yield-maximizing profit-maximizing nitrogen rates dry wet seasons. explicitly recommend different nitrogen applications season. note modelling approach directly comparable initial OLS specification. imposed quadratic structure nitrogen. requires prior knowledge expected response shape. avoided assumption using GAM, detects nonlinearities automatically defaults linear relationships appropriate. tradeoff flexibility reduces classical interpretability. GAM provides overall model reliability, direct parametric validation discovered curve. ALE fills gap providing confidence regions, p-values, interpretable uncertainty bands.","code":""},{"path":"https://tripartio.github.io/ale/articles/ale-gomez-rice.html","id":"explicit-points-of-agreement","dir":"Articles","previous_headings":"","what":"Explicit Points of Agreement","title":"Analyzing a Small Rice Yield Dataset with ALE-Based Inference","text":"analysis agrees Gomez Gomez several structural conclusions. Nonlinear nitrogen response. Across models, nitrogen shows inverted U-shape. matches finding quadratic component dominates nitrogen sum squares adequately fits data. Season-dependent nitrogen response. ALE interaction surfaces indicate nitrogen behaves differently wet dry seasons. aligns significant season × nitrogen interaction. Stronger nitrogen response dry season. GAM ALE suggest yield increases strongly nitrogen dry season, especially lower moderate range. supports interpretation linear component differs season. Structurally, analyses describe response surface: nonlinear nitrogen effects season-specific slopes.","code":""},{"path":"https://tripartio.github.io/ale/articles/ale-gomez-rice.html","id":"direct-points-of-disagreement","dir":"Articles","previous_headings":"","what":"Direct Points of Disagreement","title":"Analyzing a Small Rice Yield Dataset with ALE-Based Inference","text":"disagreement lies inference, shape. Strength statistical evidence. Gomez Gomez report highly significant nitrogen interaction effects pooled-error ANOVA. bootstrap-based ALE inference, main effects clearly exceed uncertainty bands, parts interaction surface appear significant. difference stems methodology: fixed-form ANOVA contrasts versus resampling-based stability assessment. 30 cases, fragility expected. Strength recommendation. Gomez Gomez compute optimal nitrogen rates recommend season-specific application levels. stop short firm recommendations bootstrap uncertainty remains large relative effect size. Classical ANOVA delivers decisive significance. ALE-based inference bootstrap resampling yields cautious conclusions.","code":""},{"path":"https://tripartio.github.io/ale/articles/ale-gomez-rice.html","id":"additional-nuances-beyond-gomez-and-gomez","dir":"Articles","previous_headings":"","what":"Additional Nuances Beyond Gomez and Gomez","title":"Analyzing a Small Rice Yield Dataset with ALE-Based Inference","text":"Without contradicting findings, analysis adds two perspectives. Predictive validation. Gomez Gomez emphasize inferential ANOVA significance. evaluate predictive performance using standardized accuracy MAE. GAM performs best bootstrap validation, suggesting flexible nonlinear modelling well suited dataset. Uncertainty visualization. ALE ALER bands explicitly show much variation plausibly random. Gomez Gomez rely high R² judge quadratic fit, bootstrap perspective highlights uncertain relationships may small samples.","code":""},{"path":"https://tripartio.github.io/ale/articles/ale-gomez-rice.html","id":"conclusion","dir":"Articles","previous_headings":"","what":"Conclusion","title":"Analyzing a Small Rice Yield Dataset with ALE-Based Inference","text":"methodological standpoint, learn several things: nonlinear structure small datasets, standard OLS performs poorly (SA < 50%). Machine learning models like random forest offer advantage scale. GAM strikes balance flexibility accuracy. relationships linear, collapses linear regression; nonlinear, adapts. Since GAM achieves best bootstrap-validated accuracy, interpreted model. Main effects suggest higher yield dry season wet season, difference statistically significant ALE-based inference. Nitrogen shows inverted U-shape: lowest yield zero nitrogen, peak around 60–75 kg/ha, decline higher levels. However, main nitrogen effect statistically significant bootstrap uncertainty. interaction shows clearer structure, dry season showing increased yields, despite inverted-U shape, wet season attenuated inverted-U. interaction effect, contrast, statistically significant. Overall: Results broadly consistent across models, GAM provides strongest predictive performance. effects remain statistically fragile, conclusions tentative. ALE computationally slower classical techniques offers superior interpretability relative many interpretability methods.","code":""},{"path":"https://tripartio.github.io/ale/articles/ale-gomez-rice.html","id":"references","dir":"Articles","previous_headings":"","what":"References","title":"Analyzing a Small Rice Yield Dataset with ALE-Based Inference","text":"Gomez, Kwanchai ., Arturo . Gomez. 1984. Statistical Procedures Agricultural Research. 2nd ed. Wiley. https://www.wiley.com/en-us/Statistical+Procedures++Agricultural+Research%2C+2nd+Edition-p-9780471870920.","code":""},{"path":"https://tripartio.github.io/ale/articles/ale-intro.html","id":"diamonds-dataset","dir":"Articles","previous_headings":"","what":"diamonds dataset","title":"Introduction to the ale package","text":"introduction, use diamonds dataset, included ggplot2 graphics system. cleaned original version removing duplicates invalid entries length (x), width (y), depth (z) 0. description modified dataset. Interpretable machine learning (IML) techniques like ALE applied dataset used train model. explanation explanation trained model trained model intrinsically linked dataset trained. (dataset small feasibly split training test sets, ale package tools appropriately handle small datasets.","code":"# Clean up some invalid entries diamonds <- ggplot2::diamonds |>    filter(!(x == 0 | y == 0 | z == 0)) |>    # https://lorentzen.ch/index.php/2021/04/16/a-curious-fact-on-the-diamonds-dataset/   distinct(     price, carat, cut, color, clarity,     .keep_all = TRUE   ) |>    rename(     x_length = x,     y_width = y,     z_depth = z,     depth_pct = depth   )  summary(diamonds) #>      carat               cut        color       clarity       depth_pct     #>  Min.   :0.2000   Fair     : 1492   D:4658   SI1    :9857   Min.   :43.00   #>  1st Qu.:0.5200   Good     : 4173   E:6684   VS2    :8227   1st Qu.:61.00   #>  Median :0.8500   Very Good: 9714   F:6998   SI2    :7916   Median :61.80   #>  Mean   :0.9033   Premium  : 9657   G:7815   VS1    :6007   Mean   :61.74   #>  3rd Qu.:1.1500   Ideal    :14703   H:6443   VVS2   :3463   3rd Qu.:62.60   #>  Max.   :5.0100                     I:4556   VVS1   :2413   Max.   :79.00   #>                                     J:2585   (Other):1856                   #>      table           price          x_length         y_width       #>  Min.   :43.00   Min.   :  326   Min.   : 3.730   Min.   : 3.680   #>  1st Qu.:56.00   1st Qu.: 1410   1st Qu.: 5.160   1st Qu.: 5.170   #>  Median :57.00   Median : 3365   Median : 6.040   Median : 6.040   #>  Mean   :57.58   Mean   : 4686   Mean   : 6.009   Mean   : 6.012   #>  3rd Qu.:59.00   3rd Qu.: 6406   3rd Qu.: 6.730   3rd Qu.: 6.720   #>  Max.   :95.00   Max.   :18823   Max.   :10.740   Max.   :58.900   #>                                                                    #>     z_depth       #>  Min.   : 1.070   #>  1st Qu.: 3.190   #>  Median : 3.740   #>  Mean   : 3.711   #>  3rd Qu.: 4.150   #>  Max.   :31.800   #> str(diamonds) #> tibble [39,739 × 10] (S3: tbl_df/tbl/data.frame) #>  $ carat    : num [1:39739] 0.23 0.21 0.23 0.29 0.31 0.24 0.24 0.26 0.22 0.23 ... #>  $ cut      : Ord.factor w/ 5 levels \"Fair\"<\"Good\"<..: 5 4 2 4 2 3 3 3 1 3 ... #>  $ color    : Ord.factor w/ 7 levels \"D\"<\"E\"<\"F\"<\"G\"<..: 2 2 2 6 7 7 6 5 2 5 ... #>  $ clarity  : Ord.factor w/ 8 levels \"I1\"<\"SI2\"<\"SI1\"<..: 2 3 5 4 2 6 7 3 4 5 ... #>  $ depth_pct: num [1:39739] 61.5 59.8 56.9 62.4 63.3 62.8 62.3 61.9 65.1 59.4 ... #>  $ table    : num [1:39739] 55 61 65 58 58 57 57 55 61 61 ... #>  $ price    : int [1:39739] 326 326 327 334 335 336 336 337 337 338 ... #>  $ x_length : num [1:39739] 3.95 3.89 4.05 4.2 4.34 3.94 3.95 4.07 3.87 4 ... #>  $ y_width  : num [1:39739] 3.98 3.84 4.07 4.23 4.35 3.96 3.98 4.11 3.78 4.05 ... #>  $ z_depth  : num [1:39739] 2.43 2.31 2.31 2.63 2.75 2.48 2.47 2.53 2.49 2.39 ... summary(diamonds$price) #>    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.  #>     326    1410    3365    4686    6406   18823"},{"path":"https://tripartio.github.io/ale/articles/ale-intro.html","id":"modelling-with-generalized-additive-models-gam","dir":"Articles","previous_headings":"","what":"Modelling with generalized additive models (GAM)","title":"Introduction to the ale package","text":"ALE model-agnostic IML approach, , works kind machine learning model. , ale works R model condition can predict numeric outcomes (raw estimates regression probabilities odds ratios classification). demonstration, use generalized additive models (GAM), relatively fast algorithm models data flexibly ordinary least squares regression. beyond scope explain GAM works (can learn Noam Ross’s excellent tutorial), examples work statistical machine learning algorithm. train GAM model predict diamond prices:","code":"# Create a GAM model with flexible curves to predict diamond prices. # Smooth all numeric variables and include all other variables. gam_diamonds <- mgcv::gam(   price ~ s(carat) + s(depth_pct) + s(table) + s(x_length) + s(y_width) + s(z_depth) +     cut + color + clarity,   data = diamonds   ) summary(gam_diamonds) #>  #> Family: gaussian  #> Link function: identity  #>  #> Formula: #> price ~ s(carat) + s(depth_pct) + s(table) + s(x_length) + s(y_width) +  #>     s(z_depth) + cut + color + clarity #>  #> Parametric coefficients: #>              Estimate Std. Error  t value Pr(>|t|)     #> (Intercept)  4436.199     13.315  333.165  < 2e-16 *** #> cut.L         263.124     39.117    6.727 1.76e-11 *** #> cut.Q           1.792     27.558    0.065 0.948151     #> cut.C          74.074     20.169    3.673 0.000240 *** #> cut^4          27.694     14.373    1.927 0.054004 .   #> color.L     -2152.488     18.996 -113.313  < 2e-16 *** #> color.Q      -704.604     17.385  -40.528  < 2e-16 *** #> color.C       -66.839     16.366   -4.084 4.43e-05 *** #> color^4        80.376     15.289    5.257 1.47e-07 *** #> color^5      -110.164     14.484   -7.606 2.89e-14 *** #> color^6       -49.565     13.464   -3.681 0.000232 *** #> clarity.L    4111.691     33.499  122.742  < 2e-16 *** #> clarity.Q   -1539.959     31.211  -49.341  < 2e-16 *** #> clarity.C     762.680     27.013   28.234  < 2e-16 *** #> clarity^4    -232.214     21.977  -10.566  < 2e-16 *** #> clarity^5     193.854     18.324   10.579  < 2e-16 *** #> clarity^6      46.812     16.172    2.895 0.003799 **  #> clarity^7     132.621     14.274    9.291  < 2e-16 *** #> --- #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 #>  #> Approximate significance of smooth terms: #>                edf Ref.df       F  p-value     #> s(carat)     8.695  8.949  37.027  < 2e-16 *** #> s(depth_pct) 7.606  8.429   6.758  < 2e-16 *** #> s(table)     5.759  6.856   3.682 0.000736 *** #> s(x_length)  8.078  8.527  60.936  < 2e-16 *** #> s(y_width)   7.477  8.144 211.202  < 2e-16 *** #> s(z_depth)   9.000  9.000  16.266  < 2e-16 *** #> --- #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 #>  #> R-sq.(adj) =  0.929   Deviance explained = 92.9% #> GCV = 1.2602e+06  Scale est. = 1.2581e+06  n = 39739"},{"path":"https://tripartio.github.io/ale/articles/ale-intro.html","id":"ale-object-for-ale-data","dir":"Articles","previous_headings":"","what":"ALE object for ALE data","title":"Introduction to the ale package","text":"core object ale package S7 ALE object. effect stores ALE data , optionally, ALE statistics bootstrap data one categories. first argument ALE() constructor model object–R model object can generate numeric predictions acceptable. default, generates 1D (“first order”) ALE variables dataset used train model, dataset included model object. , dataset can specified data argument. can optionally create ALE specified variables interactions using x_cols argument. change options (e.g., calculate ALE subset variables; output data use custom predict function model), see details help file object: help(ALE). introduction, demonstrate basics retrieving plotting ALE data. details ALE statistics see dedicated vignette topic. faster demonstrations, vignette uses precreated ALE objects. full experience, can uncomment relevant lines code . core functions ale package support parallel processing. can enable parallelization globally options(ale.parallel = x), “x” number CPU cores want use. can also enabled specific function runs parallel argument. Parallelization disabled default parallel = 0. See documentation ALE() details. access plot specific variable, must first create ALEPlots object calling plot() method ALE object internally generates ggplot objects full flexibility {ggplot2}: retrieve specific variable plot, can use get() method ALEPlots object. example, access print carat ALE plot, can simply refer get(diamonds_plots, 'carat'):  display ALE plots ALEPlots object, can simply call print() plot() methods. Behind scenes, use patchwork package arrange multiple plots common plot grid using patchwork::wrap_plots(), can pass arguments function. example, can specify want two plots per row ncol argument:","code":"# For faster processing, you can enable parallel processing: set the number of CPU cores available. See help(ALE) for details. options(ale.parallel = 2) # For speed, these examples use retrieve_rds() to load pre-created objects  # from an online repository. # To run the code yourself, execute the code blocks directly.   serialized_objects_site <- \"https://github.com/tripartio/ale/raw/main/download\" # Simple ALE without bootstrapping  # Create ALE data  # # To run the slow code yourself, uncomment and execute this code block directly. # # For models like mgcv::gam that store their data, # # there is no need to specify the data argument. # ale_gam_diamonds <- ALE(gam_diamonds)  ale_gam_diamonds <- serialized_objects_site |>    file.path(\"ale_gam_diamonds.0.5.2.rds\") |>   url() |>    readRDS() # Print a plot by entering its reference diamonds_plots <- plot(ale_gam_diamonds) # Print a plot by entering its reference get(diamonds_plots, 'carat') # Print all plots plot(diamonds_plots, ncol = 2)"},{"path":"https://tripartio.github.io/ale/articles/ale-intro.html","id":"bootstrapped-ale","dir":"Articles","previous_headings":"","what":"Bootstrapped ALE","title":"Introduction to the ale package","text":"One key features ALE package bootstrapping ALE results ensure results reliable, , generalizable data beyond sample model trained. mentioned , assumes IML analysis carried model whose hyperparameters determined cross-validation. samples small cross-validation, provide different approach bootstrapping entire model ModelBoot object, explained vignette small datasets. Although ALE faster IML techniques global explanation partial dependence plots (PDP) SHAP, still requires time run. Bootstrapping multiplies much time number bootstrap iterations. create bootstrapped ALE data plots using boot_it argument. ALE relatively stable IML algorithm (compared others like PDP), 100 bootstrap samples sufficient relatively stable results, especially model development. Final results confirmed 1000 bootstrap samples , much difference results beyond 100 iterations.  case, bootstrapped results mostly similar single (non-bootstrapped) ALE results. principle, always bootstrap results trust bootstrapped results. unusual result values x_length (length diamond) 6.2 mm higher associated lower diamond prices. compare y_width value (width diamond), suspect length width (, size) diamond become increasingly large, price increases much rapidly width length width inordinately high effect tempered decreased effect length high values. worth exploration real analysis, just introducing key features package.","code":"# # To run the slow code yourself, uncomment and execute this code block directly. # # For models like mgcv::gam that store their data, # # there is no need to specify the data argument. # ale_gam_diamonds_boot <- ALE( #   gam_diamonds, #   boot_it = 100 # )  ale_gam_diamonds_boot <- serialized_objects_site |>    file.path('ale_gam_diamonds_boot.0.5.2.rds') |>   url() |>    readRDS()  # Bootstrapping produces confidence intervals plot(ale_gam_diamonds_boot) |>    print(ncol = 2)"},{"path":"https://tripartio.github.io/ale/articles/ale-intro.html","id":"ale-interactions","dir":"Articles","previous_headings":"","what":"ALE interactions","title":"Introduction to the ale package","text":"Another advantage ALE provides data 2D interactions variables. also implemented ALE() constructor. d2 element x_cols list argument set TRUE, ALE() generates ALE data possible 2D interactions input dataset. change default options (e.g., calculate interactions certain pairs variables), see details help file object: help(ALE). plot() method similarly creates 2D ALE plots ALE object. subset() method ALEPlots extracts new ALEPlots object selected variables interaction terms:  printing plots together, might appear vertically distorted plot forced height. fine-tuned presentation, need refer specific plot. ale package supports standard R formula notation specifying variables. example, can print interaction plot carat depth referring thus: get(diamonds_2D_plots, ~ carat:clarity).  best dataset use illustrate ALE interactions none . expressed graphs ALE y values grey, middle range data. plots, darker squares indicate relative percentage actual data interaction intersection. , little actual data 0.2 carats; much higher carat ranges. Note ALE interactions particular: ALE interaction means two variables composite effect separate independent effects. , course x_length y_width effects price, one-way ALE plots show, interaction additional composite effect.","code":"# ALE two-way interactions  # # To run the slow code yourself, uncomment and execute this code block directly. # ale_2D_gam_diamonds <- ALE( #   gam_diamonds, #   x_cols = list(d2 = TRUE) # )  ale_2D_gam_diamonds <- serialized_objects_site |>    file.path('ale_2D_gam_diamonds.0.5.2.rds') |>   url() |>    readRDS() diamonds_2D_plots <- plot(ale_2D_gam_diamonds)  diamonds_2D_plots |>   # Select all 2D interactions that involve 'carat'   subset(list(d2_all = 'carat')) |>    print(ncol = 2) get(diamonds_2D_plots, ~ carat:clarity)"},{"path":"https://tripartio.github.io/ale/articles/ale-small-datasets.html","id":"what-is-a-small-dataset","dir":"Articles","previous_headings":"","what":"What is a “small” dataset?","title":"Analyzing small datasets (fewer than 2000 rows) with ALE","text":"obvious question , “small ‘small’?” complex question way beyond scope vignette try answer rigorously. can simply say key issue stake applying training-test split common machine learning crucial technique increasing generalizability data analysis. , question becomes focused , “small small training-test split machine learning analysis?” rule thumb familiar machine learning requires least 200 rows data predictor variable. , example, five input variables, need least 1000 rows data. note refer size entire dataset minimum size training subset. , carry 80-20 split full dataset (, 80% training set), need least 1000 rows training set another 250 rows test set, minimum 1250 rows. (carry hyperparameter tuning cross validation training set, need even data.) see headed, might quickly realize datasets less 2000 rows probably “small”. can see even many datasets 2000 rows nonetheless “small”, probably need techniques mentioned vignette. begin loading necessary libraries.","code":"library(ale) #>  #> Attaching package: 'ale' #> The following object is masked from 'package:base': #>  #>     get"},{"path":"https://tripartio.github.io/ale/articles/ale-small-datasets.html","id":"attitude-dataset","dir":"Articles","previous_headings":"","what":"attitude dataset","title":"Analyzing small datasets (fewer than 2000 rows) with ALE","text":"analysis, use attitude dataset, built-R: “survey clerical employees large financial organization, data aggregated questionnaires approximately 35 employees 30 (randomly selected) departments.” numbers give percent proportion favourable responses seven questions department. Since ’re talking “small” datasets, figure might well demonstrate principles extremely small examples.","code":""},{"path":"https://tripartio.github.io/ale/articles/ale-small-datasets.html","id":"format","dir":"Articles","previous_headings":"attitude dataset","what":"Format","title":"Analyzing small datasets (fewer than 2000 rows) with ALE","text":"data frame 30 observations 7 variables. first column short names reference, second one variable names data frame:","code":""},{"path":"https://tripartio.github.io/ale/articles/ale-small-datasets.html","id":"source","dir":"Articles","previous_headings":"attitude dataset","what":"Source","title":"Analyzing small datasets (fewer than 2000 rows) with ALE","text":"Chatterjee, S. Price, B. (1977) Regression Analysis Example. New York: Wiley. (Section 3.7, p.68ff 2nd ed.(1991).) first run ALE analysis dataset valid regular dataset, even though small proper training-test split. small-scale demonstration mainly demonstrate ale package valid analyzing even small datasets, just large datasets typically used machine learning.","code":"str(attitude) #> 'data.frame':    30 obs. of  7 variables: #>  $ rating    : num  43 63 71 61 81 43 58 71 72 67 ... #>  $ complaints: num  51 64 70 63 78 55 67 75 82 61 ... #>  $ privileges: num  30 51 68 45 56 49 42 50 72 45 ... #>  $ learning  : num  39 54 69 47 66 44 56 55 67 47 ... #>  $ raises    : num  61 63 76 54 71 54 66 70 71 62 ... #>  $ critical  : num  92 73 86 84 83 49 68 66 83 80 ... #>  $ advance   : num  45 47 48 35 47 34 35 41 31 41 ... summary(attitude) #>      rating        complaints     privileges       learning         raises      #>  Min.   :40.00   Min.   :37.0   Min.   :30.00   Min.   :34.00   Min.   :43.00   #>  1st Qu.:58.75   1st Qu.:58.5   1st Qu.:45.00   1st Qu.:47.00   1st Qu.:58.25   #>  Median :65.50   Median :65.0   Median :51.50   Median :56.50   Median :63.50   #>  Mean   :64.63   Mean   :66.6   Mean   :53.13   Mean   :56.37   Mean   :64.63   #>  3rd Qu.:71.75   3rd Qu.:77.0   3rd Qu.:62.50   3rd Qu.:66.75   3rd Qu.:71.00   #>  Max.   :85.00   Max.   :90.0   Max.   :83.00   Max.   :75.00   Max.   :88.00   #>     critical        advance      #>  Min.   :49.00   Min.   :25.00   #>  1st Qu.:69.25   1st Qu.:35.00   #>  Median :77.50   Median :41.00   #>  Mean   :74.77   Mean   :42.93   #>  3rd Qu.:80.00   3rd Qu.:47.75   #>  Max.   :92.00   Max.   :72.00"},{"path":"https://tripartio.github.io/ale/articles/ale-small-datasets.html","id":"ale-for-ordinary-least-squares-regression-multiple-linear-regression","dir":"Articles","previous_headings":"","what":"ALE for ordinary least squares regression (multiple linear regression)","title":"Analyzing small datasets (fewer than 2000 rows) with ALE","text":"Ordinary least squares (OLS) regression generic multivariate statistical technique. Thus, use baseline illustration help motivate value ALE interpreting analysis small data samples. train OLS model predict average rating: least, ale package useful visualizing effects model variables. Note now, run ALE() bootstrapping (default) small samples require special bootstrap approach, explained . now, using ALE accurately visualize model estimates.  visualization confirms see model coefficients : complaints strong positive effect ratings learning moderate effect. However, ALE indicates stronger effect advance regression coefficients suggest. variables relatively little effect ratings. see shortly proper bootstrapping model can shed light discrepancies.","code":"lm_attitude <- lm(rating ~ ., data = attitude)  summary(lm_attitude) #>  #> Call: #> lm(formula = rating ~ ., data = attitude) #>  #> Residuals: #>      Min       1Q   Median       3Q      Max  #> -10.9418  -4.3555   0.3158   5.5425  11.5990  #>  #> Coefficients: #>             Estimate Std. Error t value Pr(>|t|)     #> (Intercept) 10.78708   11.58926   0.931 0.361634     #> complaints   0.61319    0.16098   3.809 0.000903 *** #> privileges  -0.07305    0.13572  -0.538 0.595594     #> learning     0.32033    0.16852   1.901 0.069925 .   #> raises       0.08173    0.22148   0.369 0.715480     #> critical     0.03838    0.14700   0.261 0.796334     #> advance     -0.21706    0.17821  -1.218 0.235577     #> --- #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 #>  #> Residual standard error: 7.068 on 23 degrees of freedom #> Multiple R-squared:  0.7326, Adjusted R-squared:  0.6628  #> F-statistic:  10.5 on 6 and 23 DF,  p-value: 1.24e-05 # For faster processing, you can enable parallel processing: set the number of CPU cores available. See help(ALE) for details. options(ale.parallel = 2) # For speed, these examples use retrieve_rds() to load pre-created objects  # from an online repository. # To run the code yourself, execute the code blocks directly.   serialized_objects_site <- \"https://github.com/tripartio/ale/raw/main/download\" # # To run the slow code yourself, uncomment and execute this code block directly. # # For models like lm that store their data, # # there is no need to specify the data argument. # ale_lm_attitude_simple <- ALE(lm_attitude)  ale_lm_attitude_simple <- serialized_objects_site |>    file.path(\"ale_lm_attitude_simple.0.5.2.rds\") |>   url() |>    readRDS() # Print all plots plot(ale_lm_attitude_simple) |>    print(ncol = 2)"},{"path":"https://tripartio.github.io/ale/articles/ale-small-datasets.html","id":"full-model-bootstrapping","dir":"Articles","previous_headings":"","what":"Full model bootstrapping","title":"Analyzing small datasets (fewer than 2000 rows) with ALE","text":"referred frequently importance bootstrapping. None model results, without ALE, considered reliable without bootstrapped. large datasets whose models properly trained evaluated separate subsets ALE analysis, ALE object can bootstrap ALE results model trained full dataset. However, dataset small subdivided training test sets, entire model bootstrapped, just ALE data single trained model. , multiple models trained, one bootstrap sample. reliable results average results bootstrap models, however many . ModelBoot object automatically carries full-model bootstrapping suitable relatively smaller datasets. Specifically, : Creates multiple bootstrap samples (default 100; user can specify number); Creates model bootstrap sample; Calculates model overall statistics, variable coefficients, ALE values model bootstrap sample; Calculates mean, median, lower upper confidence intervals values across bootstrap samples. constructor S7 ModelBoot object requires model object first argument–R model object can generate numeric predictions. second argument dataset. objects follow base R modelling conventions, ModelBoot() able automatically recognize parse model object, data object often optional. , creation ModelBoot object: default, ModelBoot object creates 100 bootstrap samples provided dataset creates 100 + 1 models data (one bootstrap sample original dataset). (However, illustration runs faster, demonstrate 10 iterations.) Beyond ALE data, also provides bootstrapped overall model statistics (provided broom::glance()) bootstrapped model coefficients (provided broom::tidy()). default options broom::glance(), broom::tidy(), ALE() can customized, along defaults ModelBoot constructor, number bootstrap iterations. can consult help file details help(ModelBoot). ModelBoot following properties (depending values requested output argument: model_stats: bootstrapped results broom::glance() model_coefs: bootstrapped results broom::tidy() ale: bootstrapped ALE data plots boot_data: full bootstrap data (returned default) bootstrapped overall model statistics: bootstrapped model coefficients: can visualize results ALE plots.  draw formal conclusions analysis, need formal statistical framework based ALE, describe vignette ALE-based statistics statistical inference. However, can generally infer : Complaints handled around 55% led -average overall ratings; complaints handled around 72% associated -average overall ratings. 95% bootstrapped confidence intervals every variable fully overlap almost entirety median. Thus, despite general trends data (particular learning’s positive trend advance’s negative trend), data seem support claims factor convincingly meaningful effect ratings. Although basic demonstration, readily shows crucial proper bootstrapping make meaningful inferences data analysis.","code":"# # To run the slow code yourself, uncomment and execute this code block directly. # # For models like lm that store their data, # # there is no need to specify the data argument. # mb_lm_attitude <- ModelBoot(lm_attitude) # 100 bootstrap iterations by default  mb_lm_attitude <- serialized_objects_site |>    file.path(\"mb_lm_attitude.0.5.2.rds\") |>   url() |>    readRDS() mb_lm_attitude@model_stats #> # A tibble: 12 × 7 #>    name          boot_valid conf.low       median       mean conf.high       sd #>    <chr>              <dbl>    <dbl>        <dbl>      <dbl>     <dbl>    <dbl> #>  1 r.squared         NA      6.12e-1  0.788        0.767      0.877    0.0726   #>  2 adj.r.squared     NA      5.11e-1  0.733        0.706      0.845    0.0915   #>  3 sigma             NA      4.59e+0  6.27         6.25       7.55     0.823    #>  4 statistic         NA      6.05e+0 14.2         14.3       27.3      5.86     #>  5 p.value           NA      2.35e-9  0.000000983  0.0000730  0.000651 0.000261 #>  6 df                NA      6   e+0  6            6          6        0        #>  7 df.residual       NA      2.3 e+1 23           23         23        0        #>  8 nobs              NA      3   e+1 30           30         30        0        #>  9 mae                6.77   5.35e+0 NA           NA         10.8      1.57     #> 10 sa_mae             0.629  3.17e-1 NA           NA          0.745    0.117    #> 11 rmse               8.09   6.16e+0 NA           NA         12.9      1.82     #> 12 sa_rmse            0.661  4.34e-1 NA           NA          0.759    0.0944 mb_lm_attitude@model_coefs #> # A tibble: 7 × 6 #>   term        conf.low  median    mean conf.high std.error #>   <chr>          <dbl>   <dbl>   <dbl>     <dbl>     <dbl> #> 1 (Intercept)  -17.8   11.2    11.7       44.8      15.4   #> 2 complaints     0.347  0.648   0.632      0.903     0.141 #> 3 privileges    -0.321 -0.0912 -0.0689     0.269     0.162 #> 4 learning      -0.110  0.272   0.260      0.624     0.196 #> 5 raises        -0.225  0.0958  0.114      0.508     0.203 #> 6 critical      -0.366  0.0397  0.0190     0.320     0.194 #> 7 advance       -0.683 -0.197  -0.205      0.193     0.219 plot(mb_lm_attitude) |>    print(ncol = 2)"},{"path":"https://tripartio.github.io/ale/articles/ale-small-datasets.html","id":"ale-for-generalized-additive-models-gam","dir":"Articles","previous_headings":"","what":"ALE for generalized additive models (GAM)","title":"Analyzing small datasets (fewer than 2000 rows) with ALE","text":"major limitation OLS regression models relationships x variables y straight lines. unlikely relationships truly linear. OLS accurately capture non-linear relationships. samples relatively small, use generalized additive models (GAM) modelling. grossly oversimplify things, GAM extension statistical regression analysis lets model fit flexible patterns data instead restricted best-fitting straight line. ideal approach samples small machine learning provides flexible curves unlike ordinary least squares regression yet overfit excessively machine learning techniques working small samples. GAM, variables want become flexible need wrapped s (smooth) function, e.g., s(complaints). example, smooth numerical input variables: comparing adjusted R2 OLS model (0.663) GAM model (0.776), can readily see GAM model provides superior fit data. understand variables responsible relationship, results smooth terms GAM readily interpretable. need visualized effective interpretation—ALE perfect purposes.  Compared OLS results , GAM results provide quite surprise concerning shape effect employees’ perceptions department critical–seems low criticism high criticism negatively affect ratings. However, trying interpret results, must remember results bootstrapped simply reliable. , let us see bootstrapping give us.  bootstrapped GAM results tell rather different story OLS results. case, bootstrap confidence bands variables (even complaints) fully overlap median. Even average slopes vanished variables except complaint, remains positive, yet insignificant wide confidence interval. , conclude? First, tempting retain OLS results tell interesting story. consider irresponsible since GAM model clearly superior terms adjusted R2: model far reliably tells us really going . tell us? seems positive effect handled complaints ratings (higher percentage complaints handled, higher average rating), data allow us sufficiently certain generalize results. insufficient evidence variables effect . doubt, inconclusive results dataset small (30 rows). dataset even double size might show significant effects least complaints, variables.","code":"gam_attitude <- mgcv::gam(   rating ~ complaints + privileges + s(learning) +     raises + s(critical) + advance,   data = attitude) summary(gam_attitude) #>  #> Family: gaussian  #> Link function: identity  #>  #> Formula: #> rating ~ complaints + privileges + s(learning) + raises + s(critical) +  #>     advance #>  #> Parametric coefficients: #>             Estimate Std. Error t value Pr(>|t|)     #> (Intercept) 36.97245   11.60967   3.185 0.004501 **  #> complaints   0.60933    0.13297   4.582 0.000165 *** #> privileges  -0.12662    0.11432  -1.108 0.280715     #> raises       0.06222    0.18900   0.329 0.745314     #> advance     -0.23790    0.14807  -1.607 0.123198     #> --- #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 #>  #> Approximate significance of smooth terms: #>               edf Ref.df     F p-value   #> s(learning) 1.923  2.369 3.761  0.0312 * #> s(critical) 2.296  2.862 3.272  0.0565 . #> --- #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 #>  #> R-sq.(adj) =  0.776   Deviance explained = 83.9% #> GCV = 47.947  Scale est. = 33.213    n = 30 # # To run the slow code yourself, uncomment and execute this code block directly. # # For models like mgcv::gam that store their data, # # there is no need to specify the data argument. # ale_gam_attitude_simple <- ALE(gam_attitude)  ale_gam_attitude_simple <- serialized_objects_site |>    file.path(\"ale_gam_attitude_simple.0.5.2.rds\") |>   url() |>    readRDS()  plot(ale_gam_attitude_simple) |>    print(ncol = 2) # # To run the slow code yourself, uncomment and execute this code block directly. # # For models like mgcv::gam that store their data, # # there is no need to specify the data argument. # mb_gam_attitude <- ModelBoot(gam_attitude) # 100 bootstrap iterations by default  mb_gam_attitude <- serialized_objects_site |>    file.path('mb_gam_attitude.0.5.2.rds') |>   url() |>    readRDS()  mb_gam_attitude@model_stats #> # A tibble: 9 × 7 #>   name          boot_valid conf.low median   mean conf.high      sd #>   <chr>              <dbl>    <dbl>  <dbl>  <dbl>     <dbl>   <dbl> #> 1 df                NA        8.36  17.0   15.8      21.0    4.08   #> 2 df.residual       NA        9.00  13.0   14.2      21.6    4.08   #> 3 nobs              NA       30     30     30        30      0      #> 4 adj.r.squared     NA        0.746  1.000  0.945     1      0.0832 #> 5 npar              NA       23     23     23        23      0      #> 6 mae               12.9      4.50  NA     NA        62.6   15.0    #> 7 sa_mae             0.307   -2.00  NA     NA         0.769  0.772  #> 8 rmse              16.3      5.51  NA     NA        79.4   19.5    #> 9 sa_rmse            0.332   -2.08  NA     NA         0.786  0.754 mb_gam_attitude@model_coefs #> # A tibble: 2 × 6 #>   term        conf.low median  mean conf.high std.error #>   <chr>          <dbl>  <dbl> <dbl>     <dbl>     <dbl> #> 1 s(learning)     1.00   7.94  6.10      9.00      3.12 #> 2 s(critical)     1.74   4.34  4.69      8.96      2.24 plot(mb_gam_attitude) |>    print(ncol = 2)"},{"path":"https://tripartio.github.io/ale/articles/ale-small-datasets.html","id":"model_call_string-argument-for-models-not-automatically-detected","dir":"Articles","previous_headings":"","what":"model_call_string argument for models not automatically detected","title":"Analyzing small datasets (fewer than 2000 rows) with ALE","text":"ModelBoot() constructor accesses model object internally modifies retrain model bootstrapped datasets. able automatically manipulate R model objects used statistical analysis. However, object follow base R conventions model objects, ModelBoot() might able manipulate . , function fail early appropriate error message. case, user must specify model_call_string argument character string full call model boot_data data argument call. (boot_data placeholder bootstrap datasets ModelBoot() constructor internally work .) show works, let’s pretend mgcv::gam object needs special treatment. construct, model_call_string, must first execute model make sure works. earlier repeat demonstration ’re sure model call works, model_call_string constructed three simple steps: Wrap entire call (everything right assignment operator <-) quotes. Replace dataset data argument boot_data. Pass quoted string ModelBoot() model_call_string argument (argument must explicitly named). , form constructing ModelBoot model object type automatically detected: Everything else works usual.","code":"gam_attitude_again <- mgcv::gam(   rating ~ complaints + privileges + s(learning) +     raises + s(critical) + advance,   data = attitude) summary(gam_attitude_again) #>  #> Family: gaussian  #> Link function: identity  #>  #> Formula: #> rating ~ complaints + privileges + s(learning) + raises + s(critical) +  #>     advance #>  #> Parametric coefficients: #>             Estimate Std. Error t value Pr(>|t|)     #> (Intercept) 36.97245   11.60967   3.185 0.004501 **  #> complaints   0.60933    0.13297   4.582 0.000165 *** #> privileges  -0.12662    0.11432  -1.108 0.280715     #> raises       0.06222    0.18900   0.329 0.745314     #> advance     -0.23790    0.14807  -1.607 0.123198     #> --- #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 #>  #> Approximate significance of smooth terms: #>               edf Ref.df     F p-value   #> s(learning) 1.923  2.369 3.761  0.0312 * #> s(critical) 2.296  2.862 3.272  0.0565 . #> --- #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 #>  #> R-sq.(adj) =  0.776   Deviance explained = 83.9% #> GCV = 47.947  Scale est. = 33.213    n = 30 # # To run the slow code yourself, uncomment and execute this code block directly. # # For models like mgcv::gam that store their data, # # there is no need to specify the data argument. # # 100 bootstrap iterations by default. # mb_gam_attitude_special <- ModelBoot( #   gam_attitude_again, #   model_call_string = 'mgcv::gam( #     rating ~ complaints + privileges + s(learning) + #       raises + s(critical) + advance, #     data = boot_data)' # )  mb_gam_attitude_special <- serialized_objects_site |>    file.path('mb_gam_attitude_special.0.5.2.rds') |>   url() |>    readRDS()  mb_gam_attitude_special@model_stats #> Warning in readRDS(url(paste0(it.attempt, collapse = \"/\"))): cannot open URL #> 'https://github.com/tripartio/ale/raw/main/download/mb_gam_attitude_special.0.5.2.rds': #> HTTP status was '404 Not Found' #> # A tibble: 9 × 7 #>   name          boot_valid conf.low median   mean conf.high      sd #>   <chr>              <dbl>    <dbl>  <dbl>  <dbl>     <dbl>   <dbl> #> 1 df                NA        8.36  17.0   15.8      21.0    4.08   #> 2 df.residual       NA        9.00  13.0   14.2      21.6    4.08   #> 3 nobs              NA       30     30     30        30      0      #> 4 adj.r.squared     NA        0.746  1.000  0.945     1      0.0832 #> 5 npar              NA       23     23     23        23      0      #> 6 mae               12.9      4.50  NA     NA        62.6   15.0    #> 7 sa_mae             0.308   -2.00  NA     NA         0.769  0.772  #> 8 rmse              16.3      5.51  NA     NA        79.4   19.5    #> 9 sa_rmse            0.332   -2.08  NA     NA         0.786  0.754"},{"path":"https://tripartio.github.io/ale/articles/ale-statistics.html","id":"example-dataset","dir":"Articles","previous_headings":"","what":"Example dataset","title":"ALE-based statistics for statistical inference and effect sizes","text":"demonstrate ALE statistics using dataset composed transformed mgcv package. package required create generalized additive model (GAM) use demonstration. (Strictly speaking, source datasets nlme package, loaded automatically load mgcv package.) code generate data work : structure 160 rows, refers school whose students taken mathematics achievement test. describe data based documentation nlme package details quite clear: particular note variable rand_norm. added completely random variable (normal distribution) demonstrate randomness looks like analysis. (However, selected specific random seed 6 highlights particularly interesting points.) outcome variable focus analysis math_avg, average mathematics achievement scores students school. descriptive statistics:","code":"# Create and prepare the data  # Specific seed chosen to illustrate the spuriousness of the random variable set.seed(6)    math <-    # Start with math achievement scores per student   MathAchieve |>    as_tibble() |>    mutate(     school = School |> as.character() |>  as.integer(),     minority = Minority == 'Yes',     female = Sex == 'Female'   ) |>    # summarize the scores to give per-school values   summarize(     .by = school,     minority_ratio = mean(minority),     female_ratio = mean(female),     math_avg = mean(MathAch),   ) |>    # merge the summarized student data with the school data   inner_join(     MathAchSchool |>        mutate(school = School |> as.character() |>  as.integer()),     by = c('school' = 'school')   ) |>    mutate(     public = Sector == 'Public',     high_minority = HIMINTY == 1,   ) |>    select(-School, -Sector, -HIMINTY) |>    rename(     size = Size,     academic_ratio = PRACAD,     discrim = DISCLIM,     mean_ses = MEANSES,   ) |>    # Remove ID column for analysis   select(-school) |>    select(     math_avg, size, public, academic_ratio,     female_ratio, mean_ses, minority_ratio, high_minority, discrim,     everything()   ) |>    mutate(     rand_norm = rnorm(nrow(MathAchSchool))    )  glimpse(math) #> Rows: 160 #> Columns: 10 #> $ math_avg       <dbl> 9.715447, 13.510800, 7.635958, 16.255500, 13.177687, 11… #> $ size           <dbl> 842, 1855, 1719, 716, 455, 1430, 2400, 899, 185, 1672, … #> $ public         <lgl> TRUE, TRUE, TRUE, FALSE, FALSE, TRUE, TRUE, FALSE, FALS… #> $ academic_ratio <dbl> 0.35, 0.27, 0.32, 0.96, 0.95, 0.25, 0.50, 0.96, 1.00, 0… #> $ female_ratio   <dbl> 0.5957447, 0.4400000, 0.6458333, 0.0000000, 1.0000000, … #> $ mean_ses       <dbl> -0.428, 0.128, -0.420, 0.534, 0.351, -0.014, -0.007, 0.… #> $ minority_ratio <dbl> 0.08510638, 0.12000000, 0.97916667, 0.40000000, 0.72916… #> $ high_minority  <lgl> FALSE, FALSE, TRUE, FALSE, TRUE, FALSE, FALSE, FALSE, F… #> $ discrim        <dbl> 1.597, 0.174, -0.137, -0.622, -1.694, 1.535, 2.016, -0.… #> $ rand_norm      <dbl> 0.26960598, -0.62998541, 0.86865983, 1.72719552, 0.0241… summary(math$math_avg) #>    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.  #>    4.24   10.47   12.90   12.62   14.65   19.72"},{"path":"https://tripartio.github.io/ale/articles/ale-statistics.html","id":"full-model-bootstrap","dir":"Articles","previous_headings":"","what":"Full model bootstrap","title":"ALE-based statistics for statistical inference and effect sizes","text":"Now create model compute statistics . relatively small dataset, carry full model bootstrapping ModelBoot object. First, create generalized additive model (GAM) can capture non-linear relationships data.","code":"gam_math <- gam(      math_avg ~ public + high_minority +      s(size) + s(academic_ratio) + s(female_ratio) + s(mean_ses) +       s(minority_ratio) + s(discrim) + s(rand_norm),      data = math    )  gam_math #>  #> Family: gaussian  #> Link function: identity  #>  #> Formula: #> math_avg ~ public + high_minority + s(size) + s(academic_ratio) +  #>     s(female_ratio) + s(mean_ses) + s(minority_ratio) + s(discrim) +  #>     s(rand_norm) #>  #> Estimated degrees of freedom: #> 1.00 6.34 2.74 8.66 5.27 1.00 1.38  #>  total = 29.39  #>  #> GCV score: 2.158011"},{"path":"https://tripartio.github.io/ale/articles/ale-statistics.html","id":"create-p-value-distribution-objects","dir":"Articles","previous_headings":"Full model bootstrap","what":"Create p-value distribution objects","title":"ALE-based statistics for statistical inference and effect sizes","text":"bootstrap model create ALE data, important preliminary step goal analyze ALE statistics. statistics calculated dataset, randomness statistic values procedure give us. quantify randomness, want obtain p-values statistics. P-values standard statistics based assumption statistics fit distribution another (e.g., Student’s t, χ2\\chi^2, etc.). distributional assumptions, p-values can calculated quickly. However, key characteristic ALE distributional assumptions: ALE data description model’s characterization data given . Accordingly, ALE statistics assume distribution, either. implication p-values distribution data must discovered simulation rather calculated based distributional assumptions. procedure calculating p-values following: random variable added dataset. model retrained variables including new random variable. ALE statistics calculated random variable. procedure repeated 1,000 times get 1,000 ALE statistic values 1,000 random variables. p-values calculated based frequency times random variables obtain specific statistic values. can imagine, procedure slow: involves retraining entire model full dataset 1,000 times. ale package can speed process significantly parallel processing, still involves speed retraining model hundreds times. avoid repeat procedure several times (case exploratory analyses), can create ALEpDist object can run given model-dataset pair. ALEpDist object used generate p-values based statistics variable model-dataset pair. generates p-values passed ALE() ModelBoot() constructors. large datasets, process generating ALEpDist object sped using subset data running fewer 1,000 random iterations setting rand_it argument. However, ALEpDist() constructor allow fewer 100 iterations, otherwise p-values thus generated meaningless.) now demonstrate create ALEpDist object case. can now proceed bootstrap model ALE analysis.","code":"# For faster processing, you can enable parallel processing: set the number of CPU cores available. See help(ALE) for details. options(ale.parallel = 2) # For speed, these examples use retrieve_rds() to load pre-created objects  # from an online repository. # To run the code yourself, execute the code blocks directly.   serialized_objects_site <- \"https://github.com/tripartio/ale/raw/main/download\"  # # To run the slow code yourself, uncomment and execute this code block directly. # # For models like mgcv::gam that store their data, # # there is no need to specify the data argument. # # Rather slow because it retrains the model 1000 times. # gam_math_p_dist <- ALEpDist(gam_math)  gam_math_p_dist <- serialized_objects_site |>    file.path('gam_math_p_dist.0.5.0.rds') |>   url() |>    readRDS()"},{"path":"https://tripartio.github.io/ale/articles/ale-statistics.html","id":"bootstrap-the-model-with-p-values","dir":"Articles","previous_headings":"Full model bootstrap","what":"Bootstrap the model with p-values","title":"ALE-based statistics for statistical inference and effect sizes","text":"default, ModelBoot object runs 100 bootstrap iterations; can controlled boot_it argument. Bootstrapping usually rather slow, even small datasets, since entire process repeated many times. ModelBoot() constructor can speed process significantly parallel processing, still involves retraining entire model dozens times. default 100 sufficiently stable model building, want run bootstrapped algorithm several times want slow time. definitive conclusions, run 1,000 bootstraps confirm results 100 bootstraps. can see bootstrapped values various overall model statistics printing model_stats property model bootstrap object: names columns follow broom package conventions: name specific overall model statistic described row. boot_valid bootstrap-validated value performance metric specified name column. available machine-learning–style performance metrics like MAE AUC; validated (bootstrap validation .632 correction)[https://www.jstor.org/stable/2288636]. conf.low conf.high lower upper confidence intervals respectively. ModelBoot defaults 95% confidence interval; can changed setting boot_alpha argument constructor (default 0.05 95% confidence interval). median mean average bootstrapped estimates statistic. relevant bootstrap-validated metrics values calculated .632 correction. sd standard deviation bootstrapped estimate. focus, however, vignette effects individual variables. available model_coefs element model bootstrap object: vignette, go details GAM models work (can learn Noam Ross’s excellent tutorial). However, model illustration , estimates parametric variables (non-numeric ones model) interpreted regular statistical regression coefficients whereas estimates non-parametric smoothed variables (whose variable names encapsulated smooth s() function) actually estimates expected degrees freedom (EDF GAM). smooth function s() lets GAM model numeric variables flexible curves might fit data better straight line. estimate values smooth variables straightforward interpret, suffice say completely different regular regression coefficients. ale package uses bootstrap-based confidence intervals, p-values assume predetermined distributions, determine statistical significance. Although quite simple interpret counting number stars next p-value, complicated, either. Based default 95% confidence intervals, coefficient statistically significant conf.low conf.high positive negative. can filter results criterion: statistical significance estimate (EDF) smooth terms meaningless EDF go 1.0. Thus, even random term s(rand_norm) appears “statistically significant”. values non-smooth (parametric terms) public high_minority considered . , find neither coefficient estimates public high_minority effect statistically significantly different zero. (intercept conceptually meaningful ; statistical artifact.) initial analysis highlights two limitations classical hypothesis-testing analysis. First, might work suitably well use models traditional linear regression coefficients. use advanced models like GAM flexibly fit data, interpret coefficients meaningfully clear reach inferential conclusions. Second, basic challenge models based general linear model (including GAM almost statistical analyses) coefficient significance compares estimates null hypothesis effect. However, even effect, might practically meaningful. see, ALE-based statistics explicitly tailored emphasize practical implications beyond notion mere “statistical significance”.","code":"# # To run the slow code yourself, uncomment and execute this code block directly. # # For models like mgcv::gam that store their data, # # there is no need to specify the data argument. # # 100 bootstrap iterations by default (rather slow). # mb_gam_math <- ModelBoot( #   gam_math, #   # Pass the ALEpDist object so that p-values will be generated #   ale_p = gam_math_p_dist, #   # For the GAM model coefficients, show details of all variables, parametric or not #   tidy_options = list(parametric = TRUE), #   # tidy_options = list(parametric = NULL), #   boot_it = 100  # default # )  mb_gam_math <- serialized_objects_site |>    file.path('mb_gam_math_stats_vignette.0.5.0.rds') |>   url() |>    readRDS() mb_gam_math@model_stats #> # A tibble: 9 × 7 #>   name          boot_valid conf.low  median    mean conf.high     sd #>   <chr>              <dbl>    <dbl>   <dbl>   <dbl>     <dbl>  <dbl> #> 1 df                NA       29.5    42.3    42.6      58.0   7.78   #> 2 df.residual       NA      102.    118.    117.      131.    7.78   #> 3 nobs              NA      160     160     160       160     0      #> 4 adj.r.squared     NA        0.844   0.896   0.895     0.938 0.0249 #> 5 npar              NA       66      66      66        66     0      #> 6 mae                1.35     1.25   NA      NA         2.13  0.211  #> 7 sa_mae             0.726    0.541  NA      NA         0.754 0.0512 #> 8 rmse               1.71     1.58   NA      NA         2.77  0.294  #> 9 sa_rmse            0.724    0.574  NA      NA         0.748 0.0528 mb_gam_math@model_coefs #> # A tibble: 3 × 6 #>   term              conf.low median   mean conf.high std.error #>   <chr>                <dbl>  <dbl>  <dbl>     <dbl>     <dbl> #> 1 (Intercept)         11.7   12.7   12.7      13.6       0.484 #> 2 publicTRUE          -2.02  -0.652 -0.689     0.415     0.637 #> 3 high_minorityTRUE   -0.318  1.05   1.03      2.32      0.676 mb_gam_math@model_coefs |>    # filter is TRUE if conf.low and conf.high are both positive or both negative because   # multiplying two numbers of the same sign results in a positive number.   filter((conf.low * conf.high) > 0) #> # A tibble: 1 × 6 #>   term        conf.low median  mean conf.high std.error #>   <chr>          <dbl>  <dbl> <dbl>     <dbl>     <dbl> #> 1 (Intercept)     11.7   12.7  12.7      13.6     0.484"},{"path":"https://tripartio.github.io/ale/articles/ale-statistics.html","id":"ale-effect-size-measures","dir":"Articles","previous_headings":"","what":"ALE effect size measures","title":"ALE-based statistics for statistical inference and effect sizes","text":"ALE developed graphically display relationship predictor variables model outcome regardless nature model. Thus, proceed describe extension effect size measures based ALE, let us first briefly examine ALE plots variable.","code":""},{"path":"https://tripartio.github.io/ale/articles/ale-statistics.html","id":"ale-plots-with-p-values","dir":"Articles","previous_headings":"ALE effect size measures","what":"ALE plots with p-values","title":"ALE-based statistics for statistical inference and effect sizes","text":"can see variables seem sort mean effect across various values. However, statistical inference, focus must bootstrap intervals. Crucial interpretation middle grey band indicates median ± 5% random values. , explain exactly ALE range (ALER) means, now, can say : approximate middle grey band median y outcome variables dataset (math_avg, case). middle tick right y-axis indicates exact median. (prefer, plot() function lets centre data mean zero ale_centre argument.) call grey band “ALER band”. 95% random variables ALE values fully lay within ALER band. dashed lines ALER band expand boundaries 99% random variables constrained. boundaries considered demarcating extended outer ALER band. idea ALE values predictor variable falls fully within ALER band, greater effect 95% purely random variables. Moreover, consider effect ALE plot statistically significant (, non-random), overlap bootstrapped confidence regions predictor variable ALER band. (threshold p-values, use conventional defaults 0.05 95% confidence 0.01 99% confidence, value can changed aler_alpha argument.) categorical variables (public high_minority ), confidence interval bars categories overlap ALER band. confidence interval bars indicate two useful pieces information us. compare ALER band, overlap lack thereof tells us practical significance category. compare confidence bars one category others, allows us assess category statistically significant effect different categories; equivalent regular interpretation coefficients GAM GLM models. cases, confidence interval bars TRUE FALSE categories overlap , indicating statistically significant difference categories. addition, confidence interval band overlaps ALER band, indicating none effects meaningfully different random results, either. numeric variables, confidence regions overlap ALER band domains predictor variables except regions examine . extreme points variable (except discrim female_ratio) usually either slightly slightly ALER band, indicating extreme values extreme effects: math achievement increases increasing school size, academic track ratio, mean socioeconomic status, whereas decreases increasing minority ratio. ratio females discrimination climate overlap ALER band entirety domains, data support apparent trends. particular interest random variable rand_norm, whose average ALE appears show sort pattern. However, note 95% confidence intervals use mean retry analysis 100 different random seeds, expect around five random variables partially escape bounds ALER band. return implications random variables ALE analysis.","code":"mb_gam_plots <- plot(mb_gam_math) print(mb_gam_plots, ncol = 2)"},{"path":"https://tripartio.github.io/ale/articles/ale-statistics.html","id":"ale-plots-without-p-values","dir":"Articles","previous_headings":"ALE effect size measures","what":"ALE plots without p-values","title":"ALE-based statistics for statistical inference and effect sizes","text":"continue, let us take brief detour see get create ModelBoot object without giving ALEpDist object. might forget , want see quick results without slow process first generating ALEpDist object. Let us create another ModelBoot object, time, one without p-values.  absence p-values, ale packages uses simpler visualizations offer meaningful results. ALER band; simply reference lines indicate interquartile range outcome values, , 25th 75th percentiles, median . references give us precise measure strength effects, give general, intuitive indication. rest article, analyze results ALER bands generated p-values, though briefly revisit ALE plots without p-values.","code":"# # To run the slow code yourself, uncomment and execute this code block directly. # For models like mgcv::gam that store their data, # there is no need to specify the data argument. mb_gam_no_p <- ModelBoot(   gam_math,   ale_p = NULL,  # disable ALE p-values   # For the GAM model coefficients, show details of all variables, parametric or not   tidy_options = list(parametric = TRUE),   # tidy_options = list(parametric = NULL),   boot_it = 40  # 100 by default but reduced here for a faster demonstration )  mb_gam_no_p <- serialized_objects_site |>    file.path('mb_gam_no_p_stats_vignette.0.5.0.rds') |>   url() |>    readRDS()  plot(mb_gam_no_p) |>    print(ncol = 2)"},{"path":"https://tripartio.github.io/ale/articles/ale-statistics.html","id":"ale-effect-size-measures-on-the-scale-of-the-y-outcome-variable","dir":"Articles","previous_headings":"ALE effect size measures","what":"ALE effect size measures on the scale of the y outcome variable","title":"ALE-based statistics for statistical inference and effect sizes","text":"Although ALE plots allow rapid intuitive conclusions statistical inference, often helpful summary numbers quantify average strengths effects variable. Thus, developed collection effect size measures based ALE tailored intuitive interpretation. understand intuition underlying various ALE effect size measures, useful first examine ALE effects plot, graphically summarizes effect sizes variables ALE analysis. generated get() method ALEPlots object type = 'effect':  plot unusual, requires explanation: y- (vertical) axis displays x variables, rather x-axis. consistent effect size plots list full names variables. readable list labels y-axis way around. x- (horizontal) axis thus displays y (outcome) variable. two representations axis, one bottom one top. bottom typical axis outcome variable, case, math_avg. scaled expected. case, axis breaks default four six units 5 20, evenly spaced. top, outcome variable expressed percentiles ranging -50‰ median (minimum outcome value dataset) +50‰ median (maximum). divided 10 deciles 10‰ . percentiles usually evenly distributed dataset, decile breaks evenly spaced. Thus, plot two x-axes, lower one units outcome variable upper one percentiles outcome variable. reduce confusion, major vertical gridlines slightly darker align units outcome (lower axis) minor vertical gridlines slightly lighter align percentiles (upper axis). vertical grey band middle NALED band. width 0.05 p-value NALED (explained ). , 95% random variables NALED equal smaller width. variables horizontal axis sorted decreasing ALED NALED value (explained ). Although somewhat confusing two axes, percentiles direct transformation raw outcome values. first two base ALE effect size measures units outcome variable normalized versions percentiles outcome. Thus, plot can display two kinds measures simultaneously. Referring plot can help understand measures, proceed explain detail. explain measures detail, must reiterate timeless reminder correlation causation. , none scores necessarily means x variable “predictor” causes certain effect y outcome; can say ALE effect size measures indicate associated related variations two variables.","code":"get(mb_gam_plots, type = 'effect') #> `height` was translated to `width`."},{"path":"https://tripartio.github.io/ale/articles/ale-statistics.html","id":"ale-range-aler","dir":"Articles","previous_headings":"ALE effect size measures > ALE effect size measures on the scale of the y outcome variable","what":"ALE range (ALER)","title":"ALE-based statistics for statistical inference and effect sizes","text":"easiest ALE statistic understand ALE range (ALER), begin . simply range minimum maximum ale_y value variable. Mathematically, ALER(ale_y)={min(ale_y),max(ale_y)}\\mathrm{ALER}(\\mathrm{ale\\_y}) = \\{ \\min(\\mathrm{ale\\_y}), \\max(\\mathrm{ale\\_y}) \\} ale_y\\mathrm{ale\\_y} vector ALE y values variable. ALE effect size measures centred zero consistent regardless user chooses centre plots zero, median, mean. Specifically, aler_min: minimum ale_y value variable. aler_max: maximum ale_y value variable. ALER shows extreme values variable’s effect outcome. effects plot , indicated extreme ends horizontal bars variable. can access ALE effect size measures ale$stats element bootstrap result object, multiple views. focus measures specific variable, can access ale$stats$by_term element. Let’s focus public. ALE plot:  effect size measures categorical public: see public ALER [-0.34, 0.42]. consider median math score dataset 12.9, ALER indicates minimum ALE y value public (public == TRUE) -0.34 median. shown 12.6 mark plot . maximum (public == FALSE) 0.42 median, shown 13.3 point . unit ALER unit outcome variable; case, math_avg ranging 2 20. matter average ALE values might , ALER quickly shows minimum maximum effects value x variable y variable. contrast, let us look numeric variable, academic_ratio:  ALE effect size measures: ALER academic_ratio considerably broader -4.09 2.09 median.","code":"get(mb_gam_plots, 'public') get(mb_gam_math, 'public', stats = 'all') #> # A tibble: 6 × 7 #>   term   statistic estimate conf.low median   mean conf.high #>   <fct>  <fct>        <dbl>    <dbl>  <dbl>  <dbl>     <dbl> #> 1 public aled         0.375   0.0184  0.332  0.375    0.968  #> 2 public aler_min    -0.344  -0.846  -0.320 -0.344   -0.0201 #> 3 public aler_max     0.421   0.0174  0.369  0.421    1.20   #> 4 public naled        5.03    0       4.72   5.03    11.7    #> 5 public naler_min   -4.26  -11.2    -3.41  -4.26     0      #> 6 public naler_max    6.07    0       5.62   6.07    17.8 get(mb_gam_plots, 'academic_ratio') get(mb_gam_math, 'academic_ratio', stats = 'all') #> # A tibble: 6 × 7 #>   term           statistic estimate conf.low  median    mean conf.high #>   <fct>          <fct>        <dbl>    <dbl>   <dbl>   <dbl>     <dbl> #> 1 academic_ratio aled         0.810    0.408   0.795   0.810     1.29  #> 2 academic_ratio aler_min    -4.09    -7.78   -4.41   -4.09     -0.568 #> 3 academic_ratio aler_max     2.09     0.895   2.08    2.09      3.43  #> 4 academic_ratio naled       10.2      4.39   10.2    10.2      15.9   #> 5 academic_ratio naler_min  -33.3    -48.1   -38.8   -33.3      -5.23  #> 6 academic_ratio naler_max   28.1     11.7    27.7    28.1      42.3"},{"path":"https://tripartio.github.io/ale/articles/ale-statistics.html","id":"ale-deviation-aled","dir":"Articles","previous_headings":"ALE effect size measures > ALE effect size measures on the scale of the y outcome variable","what":"ALE deviation (ALED)","title":"ALE-based statistics for statistical inference and effect sizes","text":"ALE range shows extreme effects variable might outcome, ALE deviation indicates average effect full domain values. Based zero-centred ALE values, ALED conceptually similar weighted mean absolute error (MAE) ALE y values. Mathematically, ALED(ale_y,ale_n)=∑=1k|ale_yi×ale_ni|∑=1kale_ni \\mathrm{ALED}(\\mathrm{ale\\_y}, \\mathrm{ale\\_n}) = \\frac{\\sum_{=1}^{k} \\left| \\mathrm{ale\\_y}_i \\times \\mathrm{ale\\_n}_i \\right|}{\\sum_{=1}^{k} \\mathrm{ale\\_n}_i} ii index kk ALE x intervals variable (categorical variable, number distinct categories), ale_yi\\mathrm{ale\\_y}_i ALE y value iith ALE x interval, ale_ni\\mathrm{ale\\_n}_i number rows iith ALE x interval. However, whereas equation describes ALED non-numeric values ALE x interval distinct x value corresponding ALE y value, requires adjustment numeric x values .ceil represents upper bound bin. Thus, numeric values, two adjustments needed. First, convert .ceil boundaries proper discrete bins, number rows (.n) first element (representing minimum) added second element. Second, rather .y values bin boundaries, .y bin recalculated midpoint consecutive .ceil boundaries. adjusted ALED formula numeric x variables given following equation: ALED(ale_y,ale_n)=∑=1k−1|12(ale_yi+ale_yi+1)×ale_ni′|∑=1k−1ale_ni′ \\mathrm{ALED}(\\mathrm{ale\\_y}, \\mathrm{ale\\_n}) = \\frac{\\sum_{=1}^{k-1} \\left|  \\frac{1}{2} \\left( \\mathrm{ale\\_y}_i + \\mathrm{ale\\_y}_{+1} \\right) \\times \\mathrm{ale\\_n}_i' \\right|}{\\sum_{=1}^{k-1} \\mathrm{ale\\_n}_i'}  : ale_ni′{ale\\_n}_i' adjusted number rows iith interval, first element adjusted include number rows minimum interval. ale_ni′={ale_ni+ale_ni+1if =1ale_niotherwise \\mathrm{ale\\_n}_i' =  \\begin{cases} \\mathrm{ale\\_n}_i + \\mathrm{ale\\_n}_{+1} & \\text{} = 1 \\\\ \\mathrm{ale\\_n}_i & \\text{otherwise} \\end{cases} 12(ale_yi+ale_yi+1)\\frac{1}{2} \\left( \\mathrm{ale\\_y}_i + \\mathrm{ale\\_y}_{+1} \\right) represents recalculated ALE yy value bin, taken midpoint consecutive ale_yale\\_y values. Based ALED, can say average effect math scores whether school public Catholic sector 0.38 (, range 2 20). effects plot , ALED indicated white box bounded parentheses ( ). centred median, can readily see average effect school sector barely exceeds limits ALER band, indicating barely exceeds threshold practical relevance. average effect ratio academic track students slightly higher 0.81. can see plot slightly exceeds ALER band sides, indicating slightly stronger effect. comment values variables discuss normalized versions scores, proceed next.","code":""},{"path":"https://tripartio.github.io/ale/articles/ale-statistics.html","id":"normalized-ale-effect-size-measures","dir":"Articles","previous_headings":"ALE effect size measures","what":"Normalized ALE effect size measures","title":"ALE-based statistics for statistical inference and effect sizes","text":"Since ALER ALED scores scaled range y given dataset, scores compared across datasets. Thus, present normalized versions intuitive, comparable values. intuitive interpretation, normalize scores minimum, median, maximum dataset. principle, divide zero-centred y values dataset two halves: lower half 0th 50th percentile (median) upper half 50th 100th percentile. (Note median included halves). zero-centred ALE y values, negative zero values converted percentile score relative lower half original y values positive ALE y values converted percentile score relative upper half. (Technically, percentile assignment called empirical cumulative distribution function (ECDF) half.) half divided two scale 0 50 together can represent 100 percentiles. (Note: centred ALE y value exactly 0 occurs, choose include score zero ALE y lower half analogous 50th percentile values, intuitively belongs lower half 100 percentiles.) transformed maximum ALE y scaled percentile 0 100%. notable complication. normalization smoothly distributes ALE y values many distinct values, distinct ALE y values, even minimal ALE y deviation can relatively large percentile difference. ALE y value less difference median data value either immediately median, consider virtually effect. Thus, normalization sets minimal ALE y values zero. formula : norm_ale_y=100×{0if max(centred_y<0)≤ale_y≤min(centred_y>0),−ECDFy≤0(ale_y)2if ale_y<0ECDFy≥0(ale_y)2if ale_y>0 norm\\_ale\\_y = 100 \\times \\begin{cases}  0 & \\text{} \\max(centred\\_y < 0) \\leq ale\\_y \\leq \\min(centred\\_y > 0), \\\\ \\frac{-ECDF_{y_{\\leq 0}}(ale\\_y)}{2} & \\text{}ale\\_y < 0 \\\\ \\frac{ECDF_{y_{\\geq 0}}(ale\\_y)}{2} & \\text{}ale\\_y > 0 \\\\ \\end{cases}   - centred_ycentred\\_y vector y values centred median (, median subtracted values). - ECDFy≥0ECDF_{y_{\\geq 0}} ECDF non-negative values y. - −ECDFy≤0-ECDF_{y_{\\leq 0}} ECDF negative values y inverted (multiplied -1). course, formula simplified multiplying 50 instead 100 dividing ECDFs two . prefer form given explicit ECDF represents half percentile range result scored 100 percentiles.","code":""},{"path":"https://tripartio.github.io/ale/articles/ale-statistics.html","id":"normalized-aler-naler","dir":"Articles","previous_headings":"ALE effect size measures > Normalized ALE effect size measures","what":"Normalized ALER (NALER)","title":"ALE-based statistics for statistical inference and effect sizes","text":"Based normalization, first normalized ALER (NALER), scales minimum maximum ALE y values -50% +50%, centred 0%, represents median: NALER(y,ale_y)={min(norm_ale_y)+50,max(norm_ale_y)+50} \\mathrm{NALER}(\\mathrm{y, ale\\_y}) =  \\{\\min(\\mathrm{norm\\_ale\\_y}) + 50,  \\max(\\mathrm{norm\\_ale\\_y}) + 50 \\} yy full vector y values original dataset, required calculate norm_ale_y\\mathrm{norm\\_ale\\_y}. ALER shows extreme values variable’s effect outcome. effects plot , indicated extreme ends horizontal bars variable. see public ALER -0.34, 0.42. consider median math score dataset 12.9, ALER indicates minimum ALE y value public (public == TRUE) -0.34 median. shown 12.6 mark plot . maximum (public == FALSE) 0.42 median, shown 13.3 point . ALER academic_ratio considerably broader -4.09 2.09 median. result transformation NALER values can interpreted percentile effects y median, centred 0%. numbers represent limits effect x variable units percentile scores y. effects plot , percentile scale top corresponds exactly raw scale , NALER limits represented exactly points ALER limits; scale changes. scale ALER ALED lower scale raw outcomes; scale NALER NALED upper scale percentiles. , NALER -4.26, 6.07, minimum ALE value public (public == TRUE) shifts math scores -4 percentile y points whereas maximum (public == FALSE) shifts math scores 6 percentile points. Academic track ratio NALER -33.32, 28.08, ranging -33 28 percentile points math scores.","code":""},{"path":"https://tripartio.github.io/ale/articles/ale-statistics.html","id":"normalized-aled-naled","dir":"Articles","previous_headings":"ALE effect size measures > Normalized ALE effect size measures","what":"Normalized ALED (NALED)","title":"ALE-based statistics for statistical inference and effect sizes","text":"normalization ALED scores applies ALED formula normalized ALE values instead original ALE y values: NALED(y,ale_y,ale_n)=ALED(norm_ale_y,ale_n) \\mathrm{NALED}(y, \\mathrm{ale\\_y}, \\mathrm{ale\\_n}) = \\mathrm{ALED}(\\mathrm{norm\\_ale\\_y}, \\mathrm{ale\\_n}) NALED produces score ranges 0 100%. essentially ALED expressed percentiles, , average effect variable full domain values. , NALED public school status 5 indicates average effect math scores spans middle 5 percent scores. Academic ratio average effect expressed NALED 10.2% scores.","code":""},{"path":"https://tripartio.github.io/ale/articles/ale-statistics.html","id":"the-aler-band-and-random-variables","dir":"Articles","previous_headings":"ALE effect size measures","what":"The ALER band and random variables","title":"ALE-based statistics for statistical inference and effect sizes","text":"particularly striking note ALE effect size measures random rand_norm:  rand_norm NALED 4. might surprising purely random value “effect size” speak statistically, must numeric value . informal tests several different random seeds, random variables dataset exceed threshold 5%. , p-values, NALED particularly helpful comparing practical relevance variables. rule thumb, suggest variable needs shift outcome average least 5% median values considered meaningful. threshold scale NALED. , can tell public school status NALED 5 just barely crosses threshold.","code":"get(mb_gam_plots, 'rand_norm') get(mb_gam_math, 'rand_norm', stats = 'all') #> # A tibble: 6 × 7 #>   term      statistic estimate conf.low  median    mean conf.high #>   <fct>     <fct>        <dbl>    <dbl>   <dbl>   <dbl>     <dbl> #> 1 rand_norm aled         0.295    0.107   0.282   0.295     0.631 #> 2 rand_norm aler_min    -1.26    -3.98   -1.01   -1.26     -0.180 #> 3 rand_norm aler_max     0.978    0.287   0.788   0.978     2.63  #> 4 rand_norm naled        4.00     1.31    3.65    4.00      7.93  #> 5 rand_norm naler_min  -13.7    -37.5   -11.2   -13.7      -3.75  #> 6 rand_norm naler_max   13.4      2.5    11.2    13.4      35.5"},{"path":"https://tripartio.github.io/ale/articles/ale-statistics.html","id":"interpretation-of-normalized-ale-effect-sizes","dir":"Articles","previous_headings":"ALE effect size measures","what":"Interpretation of normalized ALE effect sizes","title":"ALE-based statistics for statistical inference and effect sizes","text":"summarize general principles interpreting normalized ALE effect sizes. 0% means effect . 100% means maximum possible effect variable : binary variable, one value (50% data) sets outcome minimum value value (50% data) sets outcome maximum value. Larger NALED means stronger effects. NALER minimum ranges –50% 0%; NALER maximum ranges 0% +50%: 0% means effect . indicates effect input variable keep outcome median range values. NALER minimum n means , regardless effect size NALED, minimum effect input value shifts outcome n percentile points outcome range. Lower values (closer –50%) mean stronger extreme effect. NALER maximum x means , regardless effect size NALED, maximum effect input value shifts outcome x percentile points outcome range. Greater values (closer +50%) mean stronger extreme effect. However, NALER values normalized even actual effect variable exceeds ±50%, normalized value capped ±50%. general, regardless values ALE statistics, visually inspect ALE plots identify interpret patterns relationships inputs outcome. However, NALER values quite low (< ±5%), probably much see plot. common question interpreting effect sizes , “strong effect need considered ‘strong’ ‘weak’?” one hand, decline offer general guidelines “strong” “strong”. simple answer depends entirely applied context. meaningful try propose numerical values statistics supposed useful applied contexts. hand, consider important delineate threshold random effects non-random effects. always important distinguish weak real effect one just statistical artifact due random chance. , can offer general guidelines based whether p-values. p-values ALE statistics, boundaries ALER generally used determine acceptable risk considering statistic meaningful. Statistically significant ALE effects less 0.05 p-value ALER minimum random variable greater 0.05 p-value ALER maximum random variable. explained introducing ALER band, precisely ale package , especially plots highlight ALER band confidence region tables use specified ALER p-value threshold. absence p-values, suggest NALED can general guide non-random values. informal tests, find NALED values 5% average effect random variable. , average effect reliable; might random. However, regardless average effect indicated NALED, large NALER effects indicate ALE plot inspected interpret exceptional cases. caveat important; unlike GLM coefficients, ALE analysis sufficiently sensitive detect exceptions overall trend. precisely makes valuable detecting non-linear effects. general, NALED < 5%, NALER minimum > –5%, NALER maximum < +5%, input variable meaningful effect. cases worth inspecting ALE plots careful interpretation: - NALED > 5% means meaningful average effect. - NALER minimum < –5% means might least one input value significantly lowers outcome values. - NALER maximum > +5% means might least one input value significantly increases outcome values.","code":""},{"path":"https://tripartio.github.io/ale/articles/ale-statistics.html","id":"statistical-inference-with-ale","dir":"Articles","previous_headings":"","what":"Statistical inference with ALE","title":"ALE-based statistics for statistical inference and effect sizes","text":"Although effect sizes valuable summarizing global effects variable, mask much nuance since variable varies effect along domain values. Thus, ALE particularly powerful ability make fine-grained inferences variable’s effect depending specific value.","code":""},{"path":"https://tripartio.github.io/ale/articles/ale-statistics.html","id":"ale-data-structures-for-categorical-and-numeric-variables","dir":"Articles","previous_headings":"Statistical inference with ALE","what":"ALE data structures for categorical and numeric variables","title":"ALE-based statistics for statistical inference and effect sizes","text":"understand bootstrapped ALE can used statistical inference, must understand structure ALE data. Let’s begin simple binary variable just two categories, public: meaning column ale$data categorical variable: x.bin: different categories exist categorical variable. .n: number rows category dataset provided function. .y: ALE function value calculated category. bootstrapped ALE, .y_mean default .y_median boot_centre = 'median' argument specified. .y_lo .y_hi: lower upper confidence intervals bootstrapped .y value. ale package internally centres ALE values zero, outputs plots get() method centres displayed values median outcome variable; can changed mean- zero-centring ale_centre argument plot() get(). dataset, median schools’ average mathematics achievement scores 12.9. ALE centred median, weighted sum ALE y values (weighted .n) median approximately equal weighted sum median. , ALE plots , consider number instances indicated rug plots category percentages, average weighted ALE y approximately equals median. ALE data structure numeric variable, academic_ratio: columns categorical variable, instead x.bin, x.ceil since categories. calculate ALE numeric variables, range x values divided bins (default 10, customizable max_num_bins argument). numeric variables often multiple values bin, ALE data stores ceilings (upper bounds) bins. x values fewer 10 distinct values data, distinct value becomes bin record value ceiling bin. 10 distinct values, range divided 10 decile groups. first bin includes rows value exactly equal minimum value variable, thus often elements—sometimes one. columns mean thing categorical variables: .n number rows data bin .y calculated ALE bin whose ceiling .ceil.","code":"get(mb_gam_math, 'public') #> # A tibble: 2 × 7 #>   public.bin    .n    .y .y_lo .y_mean .y_median .y_hi #>   <ord>      <int> <dbl> <dbl>   <dbl>     <dbl> <dbl> #> 1 FALSE         70  13.3  12.7    13.3      13.3  14.1 #> 2 TRUE          90  12.6  12.1    12.6      12.6  13.1 get(mb_gam_math, 'academic_ratio') #> # A tibble: 10 × 7 #>    academic_ratio.ceil    .n    .y .y_lo .y_mean .y_median .y_hi #>                  <dbl> <int> <dbl> <dbl>   <dbl>     <dbl> <dbl> #>  1                0        1  7.79  5.08    7.79      7.83  11.4 #>  2                0.2     19 12.5  11.6    12.5      12.5   13.8 #>  3                0.28    16 12.5  11.8    12.5      12.5   13.6 #>  4                0.38    18 12.7  12.3    12.7      12.7   13.3 #>  5                0.45    18 12.7  11.9    12.7      12.7   13.3 #>  6                0.53    17 13.0  12.5    13.0      13.0   13.4 #>  7                0.6     18 13.3  12.7    13.3      13.2   13.9 #>  8                0.71    18 13.4  12.4    13.4      13.5   14.1 #>  9                0.9     18 13.9  12.8    13.9      13.7   15.0 #> 10                1       17 14.9  13.4    14.9      15.0   16.3"},{"path":"https://tripartio.github.io/ale/articles/ale-statistics.html","id":"bootstrap-based-inference-with-ale","dir":"Articles","previous_headings":"Statistical inference with ALE","what":"Bootstrap-based inference with ALE","title":"ALE-based statistics for statistical inference and effect sizes","text":"bootstrapped ALE plot, values within confidence intervals statistically significant; values outside ALER band can considered least somewhat meaningful. Thus, essence ALE-based inference variable least effects whose confidence intervals outside ALER band considered conceptually meaningful. can see , example, plot mean_ses:  might always easy tell plot regions relevant, results statistical significance summarized ale$conf_regions$by_term element, can accessed variable by_term element: numeric variables, confidence regions summary one row consecutive sequence x values status: values region ALER band, overlap band, band. summary components: start_x first end_x last x value sequence. start_y y value corresponds start_x end_y corresponds end_x. n number data elements (rows) sequence; pct percentage total data elements total number. x_span_pct percentage domain x sequence confidence status (aler_band). expressed percentage full domain x values may comparable across variables different units x. trend average slope point (start_x, start_y) (end_x, end_y). start end points used calculate trend, reflect ups downs might occur two points. Since various x values dataset different scales, scales x y values calculating trend normalized scale 100 trends variables directly comparable. positive trend means , average, y increases x; negative trend means , average, y decreases x; zero trend means y value start end points–always case one point indicated sequence. : higher limit confidence interval ALE y (.y_hi) lower limit ALER band. : lower limit confidence interval ALE y (.y_lo) higher limit ALER band. overlap: neither first two conditions holds; , confidence region .y_lo .y_hi least partially overlaps ALER band. results tell us , mean_ses, -1.19 -0.517, ALE ALER band 5.32 11.3. -0.335 0.831, ALE overlaps ALER band 12.3 15. Interestingly, text previous paragraph generated automatically internal (unexported function) ale:::summarize_conf_regions_1D_in_words. (Since function exported, must use ale::: three colons, just two, want access .) wording rather mechanical, nonetheless illustrates potential value able summarize inferentially relevant conclusions tabular form. Confidence region summary tables available numeric also categorical variables, see public. ALE plot :  confidence regions summary table: Since categories , start end position trend. instead x category single ALE y value, n pct respective category. aler_band indicate whether indicated category , overlaps , ALER band. help ale:::summarize_conf_regions_1D_in_words(), can summarize results public: FALSE, ALE 13.3 overlaps ALER band. TRUE, ALE 12.6 overlaps ALER band. , random variable rand_norm particularly interesting. ALE plot:  confidence regions summary table: Despite apparent pattern (even though deliberately selected random seed particularly erratic random variable), see -2.4 2.61, ALE overlaps ALER band 11.7 12.5.. , despite random highs lows bootstrap confidence interval, reason suppose random variable effect anywhere domain. can conveniently summarize confidence regions variables statistically significant meaningful accessing conf_regions$significant element: summary focuses x variables meaningful ALE regions anywhere domain. can also conveniently isolate variables meaningful region extracting unique values term column: especially useful analyses dozens variables; can thus quickly isolate focus meaningful ones.","code":"get(mb_gam_plots, 'mean_ses') get(mb_gam_math, 'mean_ses', stats = 'conf_regions') #> # A tibble: 2 × 10 #>   term     start_x  end_x x_span_pct     n   pct start_y end_y trend aler_band #>   <chr>      <dbl>  <dbl>      <dbl> <int> <dbl>   <dbl> <dbl> <dbl> <ord>     #> 1 mean_ses  -1.19  -0.517       33.2    18  11.2    5.32  11.3 1.20  below     #> 2 mean_ses  -0.335  0.831       57.8   142  88.8   12.3   15.0 0.314 overlap get(mb_gam_math, 'mean_ses', stats = 'conf_regions') |>    ale:::summarize_conf_regions_1D_in_words() #> [1] \"From -1.19 to -0.517, ALE is below the ALER band from 5.32 to 11.3. From -0.335 to 0.831, ALE overlaps the ALER band from 12.3 to 15.\" get(mb_gam_plots, 'public') get(mb_gam_math, 'public', stats = 'conf_regions') #> # A tibble: 2 × 6 #>   term   x         n   pct     y aler_band #>   <chr>  <chr> <int> <dbl> <dbl> <ord>     #> 1 public FALSE    70  43.8  13.3 overlap   #> 2 public TRUE     90  56.2  12.6 overlap get(mb_gam_plots, 'rand_norm') get(mb_gam_math, 'rand_norm', stats = 'conf_regions') #> # A tibble: 1 × 10 #>   term      start_x end_x x_span_pct     n   pct start_y end_y  trend aler_band #>   <chr>       <dbl> <dbl>      <dbl> <int> <dbl>   <dbl> <dbl>  <dbl> <ord>     #> 1 rand_norm   -2.40  2.61        100   160   100    11.7  12.5 0.0555 overlap get(mb_gam_math, stats = 'conf_sig') #> # A tibble: 5 × 12 #>   term   x     start_x   end_x x_span_pct     n   pct     y start_y end_y  trend #>   <chr>  <chr>   <dbl>   <dbl>      <dbl> <int> <dbl> <dbl>   <dbl> <dbl>  <dbl> #> 1 mean_… NA    -1.19   -0.517       33.2     18  11.2    NA    5.32 11.3   1.20  #> 2 mean_… NA    -0.335   0.831       57.8    142  88.8    NA   12.3  15.0   0.314 #> 3 minor… NA     0       0.0339       3.39    36  22.5    NA   14.5  14.2  -0.742 #> 4 minor… NA     0.0638  0.792       72.8    107  66.9    NA   13.8  11.8  -0.184 #> 5 minor… NA     1       1            0       17  10.6    NA    9.10  9.10  0     #> # ℹ 1 more variable: aler_band <ord> get(mb_gam_math, stats = 'conf_sig')$term |>    unique() #> [1] \"mean_ses\"       \"minority_ratio\""},{"path":"https://tripartio.github.io/ale/articles/ale-x-datatypes.html","id":"var_cars-modified-mtcars-dataset-motor-trend-car-road-tests","dir":"Articles","previous_headings":"","what":"var_cars: modified mtcars dataset (Motor Trend Car Road Tests)","title":"ale package handling of various input datatypes","text":"demonstration, use modified version built-mtcars dataset binary (logical), categorical (factor, , non-ordered categories), ordinal (ordered factor), discrete interval (integer), continuous interval (numeric double) values. modified version, called var_cars, let us test different basic variations x variables. factor, adds country car manufacturer. data tibble 32 observations 12 variables:","code":"print(var_cars) #> # A tibble: 32 × 14 #>    model         mpg   cyl  disp    hp  drat    wt  qsec vs    am    gear   carb #>    <chr>       <dbl> <int> <dbl> <dbl> <dbl> <dbl> <dbl> <lgl> <lgl> <ord> <int> #>  1 Mazda RX4    21       6  160    110  3.9   2.62  16.5 FALSE TRUE  four      4 #>  2 Mazda RX4 …  21       6  160    110  3.9   2.88  17.0 FALSE TRUE  four      4 #>  3 Datsun 710   22.8     4  108     93  3.85  2.32  18.6 TRUE  TRUE  four      1 #>  4 Hornet 4 D…  21.4     6  258    110  3.08  3.22  19.4 TRUE  FALSE three     1 #>  5 Hornet Spo…  18.7     8  360    175  3.15  3.44  17.0 FALSE FALSE three     2 #>  6 Valiant      18.1     6  225    105  2.76  3.46  20.2 TRUE  FALSE three     1 #>  7 Duster 360   14.3     8  360    245  3.21  3.57  15.8 FALSE FALSE three     4 #>  8 Merc 240D    24.4     4  147.    62  3.69  3.19  20   TRUE  FALSE four      2 #>  9 Merc 230     22.8     4  141.    95  3.92  3.15  22.9 TRUE  FALSE four      2 #> 10 Merc 280     19.2     6  168.   123  3.92  3.44  18.3 TRUE  FALSE four      4 #> # ℹ 22 more rows #> # ℹ 2 more variables: country <fct>, continent <fct> summary(var_cars) #>     model                mpg             cyl             disp       #>  Length:32          Min.   :10.40   Min.   :4.000   Min.   : 71.1   #>  Class :character   1st Qu.:15.43   1st Qu.:4.000   1st Qu.:120.8   #>  Mode  :character   Median :19.20   Median :6.000   Median :196.3   #>                     Mean   :20.09   Mean   :6.188   Mean   :230.7   #>                     3rd Qu.:22.80   3rd Qu.:8.000   3rd Qu.:326.0   #>                     Max.   :33.90   Max.   :8.000   Max.   :472.0   #>        hp             drat             wt             qsec       #>  Min.   : 52.0   Min.   :2.760   Min.   :1.513   Min.   :14.50   #>  1st Qu.: 96.5   1st Qu.:3.080   1st Qu.:2.581   1st Qu.:16.89   #>  Median :123.0   Median :3.695   Median :3.325   Median :17.71   #>  Mean   :146.7   Mean   :3.597   Mean   :3.217   Mean   :17.85   #>  3rd Qu.:180.0   3rd Qu.:3.920   3rd Qu.:3.610   3rd Qu.:18.90   #>  Max.   :335.0   Max.   :4.930   Max.   :5.424   Max.   :22.90   #>      vs              am             gear         carb          country   #>  Mode :logical   Mode :logical   three:15   Min.   :1.000   Germany: 8   #>  FALSE:18        FALSE:19        four :12   1st Qu.:2.000   Italy  : 4   #>  TRUE :14        TRUE :13        five : 5   Median :2.000   Japan  : 6   #>                                             Mean   :2.812   Sweden : 1   #>                                             3rd Qu.:4.000   UK     : 1   #>                                             Max.   :8.000   USA    :12   #>          continent  #>  Asia         : 6   #>  Europe       :14   #>  North America:12   #>                     #>                     #>"},{"path":"https://tripartio.github.io/ale/articles/ale-x-datatypes.html","id":"modelling-with-ale-and-gam","dir":"Articles","previous_headings":"","what":"Modelling with ALE and GAM","title":"ale package handling of various input datatypes","text":"GAM, numeric variables can smoothed, binary categorical ones. However, smoothing always help improve model since variables related outcome related actually simple linear relationship. keep demonstration simple, done earlier analysis (shown ) determines smoothing worthwhile modified var_cars dataset, numeric variables smoothed. goal demonstrate best modelling procedure rather demonstrate flexibility ale package. Now generate ALE data gam_cars GAM model plot .  can see ALE() trouble modelling datatypes sample (logical, factor, ordered, integer, double). plots line charts numeric predictors column charts everything else. numeric predictors rug plots indicate ranges x (predictor) y (mpg) values data actually exists dataset. helps us -interpret regions data sparse. Since column charts discrete scale, display rug plots. Instead, percentage data represented column displayed. can also generate plot ALE data two-way interactions.  interactions model point demonstration show ale package can handle 2D interactions just pair interaction types: numeric-numeric, ordinal-binary, categorical-ordinal, etc. Finally, explained vignette modelling small datasets, appropriate modelling workflow require bootstrapping entire model, just ALE data. , let’s now.  (default, ModelBoot object creates 100 bootstrap samples , illustration runs faster, demonstrate 10 iterations.) small dataset, bootstrap confidence interval always overlap median, indicating dataset support claims variables meaningful effect fuel efficiency (mpg). Considering average bootstrapped ALE values suggest various intriguing patterns, problem doubt dataset small–data collected analyzed, patterns probably confirmed.","code":"gam_cars <- mgcv::gam(   mpg ~ cyl + disp + hp + drat + wt + s(qsec) +     vs + am + gear + carb + country,   data = var_cars ) summary(gam_cars) #>  #> Family: gaussian  #> Link function: identity  #>  #> Formula: #> mpg ~ cyl + disp + hp + drat + wt + s(qsec) + vs + am + gear +  #>     carb + country #>  #> Parametric coefficients: #>               Estimate Std. Error t value Pr(>|t|)    #> (Intercept)   -7.84775   12.47080  -0.629  0.54628    #> cyl            1.66078    1.09449   1.517  0.16671    #> disp           0.06627    0.01861   3.561  0.00710 ** #> hp            -0.01241    0.02502  -0.496  0.63305    #> drat           4.54975    1.48971   3.054  0.01526 *  #> wt            -5.03737    1.53979  -3.271  0.01095 *  #> vsTRUE        12.45630    3.62342   3.438  0.00852 ** #> amTRUE         8.77813    2.67611   3.280  0.01080 *  #> gear.L         0.53111    3.03337   0.175  0.86525    #> gear.Q         0.57129    1.18201   0.483  0.64150    #> carb          -0.34479    0.78600  -0.439  0.67223    #> countryItaly  -0.08633    2.22316  -0.039  0.96995    #> countryJapan  -3.31948    2.22723  -1.490  0.17353    #> countrySweden -3.83437    2.74934  -1.395  0.19973    #> countryUK     -7.24222    3.81985  -1.896  0.09365 .  #> countryUSA    -7.69317    2.37998  -3.232  0.01162 *  #> --- #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 #>  #> Approximate significance of smooth terms: #>           edf Ref.df     F p-value   #> s(qsec) 7.797  8.641 5.975  0.0101 * #> --- #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 #>  #> R-sq.(adj) =  0.955   Deviance explained = 98.8% #> GCV = 6.4263  Scale est. = 1.6474    n = 32 # For faster processing, you can enable parallel processing: set the number of CPU cores available. See help(ALE) for details. options(ale.parallel = 2) # For speed, these examples use retrieve_rds() to load pre-created objects  # from an online repository. # To run the code yourself, execute the code blocks directly.   serialized_objects_site <- \"https://github.com/tripartio/ale/raw/main/download\" # # To run the slow code yourself, uncomment and execute this code block directly. # # For models like mgcv::gam that store their data, # # there is no need to specify the data argument. # ale_cars_1D <- ALE(gam_cars)  ale_cars_1D <- retrieve_rds(   # For speed, load a pre-created object by default.   c(serialized_objects_site, 'ale_cars_1D.0.5.2.rds'),   {   } ) # saveRDS(ale_cars_1D, file.choose())  # Print all plots plot(ale_cars_1D) |>    print(ncol = 2) # # # To run the slow code yourself, uncomment and execute this code block directly. # # For models like mgcv::gam that store their data, # # there is no need to specify the data argument. # ale_cars_2D <- ALE( #   gam_cars, #   x_cols = list(d2 = TRUE) # )  ale_cars_2D <- serialized_objects_site |>    file.path('ale_cars_2D.0.5.2.rds') |>   url() |>    readRDS()  # Print plots plot(ale_cars_2D) |>    print(     ncol = 2,      # By default, at most 20 plots are printed. Set max_print to increase this limit     max_print = 100   ) # # To run the slow code yourself, uncomment and execute this code block directly. # # For models like mgcv::gam that store their data, # # there is no need to specify the data argument. # mb_cars <- ModelBoot(gam_cars) # 100 bootstrap iterations by default  mb_cars <- serialized_objects_site |>    file.path('mb_cars.0.5.2.rds') |>   url() |>    readRDS()  plot(mb_cars) |>    print(ncol = 2)"},{"path":"https://tripartio.github.io/ale/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Chitu Okoli. Author, maintainer.","code":""},{"path":"https://tripartio.github.io/ale/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Okoli C (2023). “Statistical inference using machine learning classical techniques based accumulated local effects (ALE).” arXiv, 1-30. doi:10.48550/arXiv.2310.09877, https://arxiv.org/abs/2310.09877. Okoli C (2024). “Reliable Inference Human-Centred Datasets Accumulated Local Effects.” Conference, https://submissions.mirasmart.com/InformsAnnual2024/Itinerary/PresentationDetail.aspx?evdid=6275. Okoli C (2024). “Model-Agnostic Interpretability: Effect Size Measures Accumulated Local Effects (ALE).” Conference, https://sites.google.com/view/data-science-2024/program. Okoli C (2026). ale: Interpretable Machine Learning Statistical Inference Accumulated Local Effects (ALE). R package version 0.5.3.20260217, https://CRAN.R-project.org/package=ale.","code":"@Article{alestatsarxiv,   title = {Statistical inference using machine learning and classical techniques based on accumulated local effects (ALE)},   author = {Chitu Okoli},   year = {2023},   journal = {arXiv},   doi = {10.48550/arXiv.2310.09877},   url = {https://arxiv.org/abs/2310.09877},   pages = {1-30}, } @Unpublished{aleinforms24,   note = {Conference},   author = {Chitu Okoli},   title = {Reliable Inference from Human-Centred Datasets with Accumulated Local Effects},   booktitle = {2024 INFORMS Annual Meeting},   year = {2024},   url = {https://submissions.mirasmart.com/InformsAnnual2024/Itinerary/PresentationDetail.aspx?evdid=6275}, } @Unpublished{alestatsinformsds,   note = {Conference},   author = {Chitu Okoli},   title = {Model-Agnostic Interpretability: Effect Size Measures from Accumulated Local Effects (ALE)},   booktitle = {INFORMS Workshop on Data Science 2024},   year = {2024},   url = {https://sites.google.com/view/data-science-2024/program}, } @Manual{,   title = {ale: Interpretable Machine Learning and Statistical Inference with Accumulated Local Effects (ALE)},   author = {Chitu Okoli},   year = {2026},   note = {R package version 0.5.3.20260217},   url = {https://CRAN.R-project.org/package=ale}, }"},{"path":"https://tripartio.github.io/ale/index.html","id":"ale-","dir":"","previous_headings":"","what":"Interpretable Machine Learning and Statistical Inference with Accumulated Local Effects (ALE)","title":"Interpretable Machine Learning and Statistical Inference with Accumulated Local Effects (ALE)","text":"Accumulated Local Effects (ALE) initially developed model-agnostic approach global explanations results black-box machine learning algorithms (Apley, Daniel W., Jingyu Zhu. ‘Visualizing effects predictor variables black box supervised learning models.’ Journal Royal Statistical Society Series B: Statistical Methodology 82.4 (2020): 1059-1086 doi:10.1111/rssb.12377). ALE two primary advantages approaches like partial dependency plots (PDP) SHapley Additive exPlanations (SHAP): values affected presence interactions among variables model computation relatively rapid. package reimplements algorithms calculating ALE data develops highly interpretable visualizations plotting ALE values. also extends original ALE concept add bootstrap-based confidence intervals ALE-based statistics can used statistical inference. details, see Okoli, Chitu. 2023. “Statistical Inference Using Machine Learning Classical Techniques Based Accumulated Local Effects (ALE).” arXiv. doi:10.48550/arXiv.2310.09877. ale package defines four main S7 classes: ALE: data 1D ALE (single variables) 2D ALE (two-way interactions). ALE values may bootstrapped ALE statistics calculated. ModelBoot: bootstrap results entire model, just ALE values. function returns bootstrapped model statistics coefficients well bootstrapped ALE values. appropriate approach models cross-validated. ALEPlots: store ALE plots generated either ALE ModelBoot convenient print(), plot(), get() methods. ALEpDist: distribution object calculating p-values ALE statistics ALE object.","code":""},{"path":"https://tripartio.github.io/ale/index.html","id":"documentation","dir":"","previous_headings":"","what":"Documentation","title":"Interpretable Machine Learning and Statistical Inference with Accumulated Local Effects (ALE)","text":"can obtain direct help package’s user-facing functions R help() function, e.g., help(ale). However, detailed documentation found website recent development version. can find several articles. particularly recommend: Introduction {ale} package ALE-based statistics statistical inference effect sizes","code":""},{"path":"https://tripartio.github.io/ale/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Interpretable Machine Learning and Statistical Inference with Accumulated Local Effects (ALE)","text":"can obtain official releases CRAN: CRAN releases extensively tested relatively bugs. However, package still beta stage. ale package, means occasionally new features changes function interface might break functionality earlier versions. Please excuse us move towards stable version flexibly meets needs broadest user base. get recent features, can install development version package GitHub : development version main branch GitHub always thoroughly checked. However, documentation might fully --date functionality.","code":"install.packages('ale') # install.packages('pak') pak::pak('tripartio/ale')"},{"path":"https://tripartio.github.io/ale/index.html","id":"usage","dir":"","previous_headings":"","what":"Usage","title":"Interpretable Machine Learning and Statistical Inference with Accumulated Local Effects (ALE)","text":"give two demonstrations use package: first, simple demonstration ALE plots, second, sophisticated demonstration suitable statistical inference p-values. demonstrations, begin fitting GAM model. assume final deployment model needs fitted entire dataset.","code":"library(dplyr) #>  #> Attaching package: 'dplyr' #> The following objects are masked from 'package:stats': #>  #>     filter, lag #> The following objects are masked from 'package:base': #>  #>     intersect, setdiff, setequal, union  # Load diamonds dataset with some cleanup diamonds <- ggplot2::diamonds |>   filter(!(x == 0 | y == 0 | z == 0)) |>   # https://lorentzen.ch/index.php/2021/04/16/a-curious-fact-on-the-diamonds-dataset/   distinct(     price, carat, cut, color, clarity,     .keep_all = TRUE   ) |>   rename(     x_length = x,     y_width = y,     z_depth = z,     depth_pct = depth   ) # Create a GAM model with flexible curves to predict diamond price # Smooth all numeric variables and include all other variables # Build the model on training data, not on the full dataset. gam_diamonds <- mgcv::gam(   price ~ s(carat) + s(depth_pct) + s(table) + s(x_length) + s(y_width) + s(z_depth) +     cut + color + clarity,   data = diamonds )"},{"path":"https://tripartio.github.io/ale/index.html","id":"simple-demonstration","dir":"","previous_headings":"Usage","what":"Simple demonstration","title":"Interpretable Machine Learning and Statistical Inference with Accumulated Local Effects (ALE)","text":"simple demonstration, directly create ALE data ALE() function plot ggplot plot objects.  explanation basic features, see introductory vignette.","code":"library(ale) #>  #> Attaching package: 'ale' #> The following object is masked from 'package:base': #>  #>     get  # For speed, these examples use retrieve_rds() to load pre-created objects  # from an online repository. # To run the code yourself, execute the code blocks directly.   serialized_objects_site <- \"https://github.com/tripartio/ale/raw/main/download\" # Create ALE data # # To run the slow code yourself, uncomment and execute this code block directly. ale_gam_diamonds <- ALE(gam_diamonds, data = diamonds)  ale_gam_diamonds <- serialized_objects_site |>    file.path('ale_gam_diamonds.0.5.2.rds') |>   url() |>    readRDS()  # Plot the ALE data plot(ale_gam_diamonds) |>    print(ncol = 2)"},{"path":"https://tripartio.github.io/ale/index.html","id":"statistical-inference-with-ale","dir":"","previous_headings":"Usage","what":"Statistical inference with ALE","title":"Interpretable Machine Learning and Statistical Inference with Accumulated Local Effects (ALE)","text":"statistical functionality ale package rather slow typically involves 100 bootstrap iterations sometimes 1,000 random simulations. Even though functions package support parallel processing, procedures still take time. , statistical demonstration gives downloadable objects rapid demonstration. First, need create p-value distribution object ALE statistics can properly distinguished random effects. Now can create bootstrapped ALE data see differences plots bootstrapped ALE p-values:   detailed explanation interpret plots, see vignette ALE-based statistics statistical inference effect sizes.","code":"# Create p_value distribution object  # # Rather slow because it retrains the model 100 times. # # To run the slow code yourself, uncomment and execute this code block directly. # p_dist_gam_diamonds_readme <- ALEpDist( #   gam_diamonds, diamonds, #   # Normally should be default 1000, but just 100 for a quicker demo. #   rand_it = 100 # )  p_dist_gam_diamonds_readme <- serialized_objects_site |>    file.path('p_dist_gam_diamonds_readme.0.5.2.rds') |>   url() |>    readRDS() # Create ALE data with p-values  # # To run the slow code yourself, uncomment and execute this code block directly. # ale_gam_diamonds_stats_readme <- ALE( #   gam_diamonds, #   # generate ALE for all 1D variables and the carat:clarity 2D interaction #   x_cols = list(d1 = TRUE, d2 = 'carat:clarity'), #   data = diamonds, #   p_values = p_dist_gam_diamonds_readme, #   # Usually at least 100 bootstrap iterations, but just 10 here for a faster demo #   boot_it = 10 # )  ale_gam_diamonds_stats_readme <- serialized_objects_site |>    file.path('ale_gam_diamonds_stats_readme.0.5.2.rds') |>   url() |>    readRDS() # Create an ALEPlots object for fine-tuned plotting ale_plots <- plot(ale_gam_diamonds_stats_readme)  # Plot 1D ALE plots  ale_plots |>    # Only select 1D ALE plots.   # Use subset() instead of get() to keep the special ALEPlots object    # plot and print functionality.   subset(list(d1 = TRUE)) |>    print(ncol = 2) # Plot a selected 2D plot ale_plots |>    # get() retrieves a specific desired plot   get('carat:clarity')"},{"path":"https://tripartio.github.io/ale/index.html","id":"getting-help","dir":"","previous_headings":"","what":"Getting help","title":"Interpretable Machine Learning and Statistical Inference with Accumulated Local Effects (ALE)","text":"find bug, please report GitHub. sure always include minimal reproducible example usage requests. include dataset question, use one built-datasets frame help request: var_cars census. may also use ggplot2::diamonds larger sample.","code":""},{"path":"https://tripartio.github.io/ale/index.html","id":"citations","dir":"","previous_headings":"","what":"Citations","title":"Interpretable Machine Learning and Statistical Inference with Accumulated Local Effects (ALE)","text":"find package useful, appreciate cite appropriate sources follows, depending aspects use.","code":""},{"path":"https://tripartio.github.io/ale/index.html","id":"core-idea-of-accumulated-local-effects","dir":"","previous_headings":"Citations","what":"Core idea of accumulated local effects","title":"Interpretable Machine Learning and Statistical Inference with Accumulated Local Effects (ALE)","text":"Apley, Daniel W., Jingyu Zhu (2020). “Visualizing effects predictor variables black box supervised learning models.” Journal Royal Statistical Society Series B: Statistical Methodology 82, . 4: 1059-1086.","code":""},{"path":"https://tripartio.github.io/ale/index.html","id":"ale-statistics-aled-aler-naled-naler","dir":"","previous_headings":"Citations","what":"ALE statistics (ALED, ALER, NALED, NALER)","title":"Interpretable Machine Learning and Statistical Inference with Accumulated Local Effects (ALE)","text":"Okoli, Chitu (2023). “Statistical inference using machine learning classical techniques based accumulated local effects (ALE).” arXiv preprint arXiv:2310.09877. Okoli, Chitu (2024). “Model-Agnostic Interpretability: Effect Size Measures Accumulated Local Effects (ALE)”. INFORMS Workshop Data Science 2024. Seattle","code":""},{"path":"https://tripartio.github.io/ale/index.html","id":"ale-based-inference-confidence-regions","dir":"","previous_headings":"Citations","what":"ALE-based inference (confidence regions)","title":"Interpretable Machine Learning and Statistical Inference with Accumulated Local Effects (ALE)","text":"Okoli, Chitu (2023). “Statistical inference using machine learning classical techniques based accumulated local effects (ALE).” arXiv preprint arXiv:2310.09877. Okoli, Chitu (2024). “Model-Agnostic Interpretability: Effect Size Measures Accumulated Local Effects (ALE)”. INFORMS Workshop Data Science 2024. Seattle","code":""},{"path":"https://tripartio.github.io/ale/index.html","id":"use-of-the-ale-package-the-software-itself","dir":"","previous_headings":"Citations","what":"Use of the ale package (the software itself)","title":"Interpretable Machine Learning and Statistical Inference with Accumulated Local Effects (ALE)","text":"Okoli, Chitu ([year package version used]). “ale: Interpretable Machine Learning Statistical Inference Accumulated Local Effects (ALE)”. R software package version [enter version number]. https://CRAN.R-project.org/package=ale.","code":""},{"path":"https://tripartio.github.io/ale/reference/ALE.html","id":null,"dir":"Reference","previous_headings":"","what":"ALE data and statistics that describe a trained model — ALE","title":"ALE data and statistics that describe a trained model — ALE","text":"ALE S7 object contains ALE data statistics. details, see vignette('ale-intro') details examples .","code":""},{"path":"https://tripartio.github.io/ale/reference/ALE.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"ALE data and statistics that describe a trained model — ALE","text":"","code":"ALE(   model,   x_cols = list(d1 = TRUE),   data = NULL,   y_col = NULL,   ...,   exclude_cols = NULL,   parallel = 0,   model_packages = NULL,   output_stats = TRUE,   output_boot_data = FALSE,   pred_fun = NULL,   pred_type = \"response\",   p_values = \"auto\",   require_same_p = TRUE,   aler_alpha = c(0.01, 0.05),   aled_fun = NULL,   max_num_bins = 10L,   fct_order = \"levels\",   boot_it = 0L,   boot_alpha = 0.05,   boot_centre = \"mean\",   seed = 0,   y_type = NULL,   sample_size = 500L,   silent = FALSE,   .bins = NULL )"},{"path":"https://tripartio.github.io/ale/reference/ALE.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"ALE data and statistics that describe a trained model — ALE","text":"model model object. Required. Model ALE calculated. May kind R object can make predictions data. x_cols, exclude_cols character, list, formula. Columns names data requested one special x_cols formats ALE data calculated. Defaults 1D ALE columns data except y_col. See details documentation resolve_x_cols(). data dataframe. Dataset create predictions ALE. normally dataset model trained. provided, ALE() try detect automatically included model object. y_col character(1). Name outcome target label (y) variable. provided, ALE() try detect automatically model object. found automatically, y_col provided. time--event (survival) models, see details. ... used. Inserted require explicit naming subsequent arguments. parallel non-negative integer(1) character(1) c(\"\", \"one\"). Number parallel threads (workers tasks) parallel execution constructor. default parallel = 0 disables parallel processing. \"one\" uses available physical CPU cores minus one, reserved system, whereas \"\" uses physical logical cores reported system. See details. model_packages character. Character vector names packages model depends might obvious parallel processing. get weird error messages parallel processing enabled resolved setting parallel = 0, might need specify model_packages. See details. output_stats logical(1). TRUE (default), return ALE statistics. output_boot_data logical(1). TRUE, return raw ALE data bootstrap iteration. Default FALSE. pred_fun, pred_type function,character(1). pred_fun function returns vector predicted values type pred_type model data. default NULL pred_fun often work; get error message, see details. p_values instructions calculating p-values. Possible values : NULL: p-values calculated. ALEpDist object: object used calculate p-values. \"auto\" (default): statistics requested (output_stats = TRUE) bootstrapping requested (boot_it > 0), constructor try automatically create fast surrogate ALEpDist object; otherwise, p-values calculated. However, automatic creation surrogate ALEpDist object might work R models. automatic process errors, must explicitly create provide ALEpDist() object. Note: although faster surrogate p-values convenient interactive analysis, acceptable definitive conclusions publication. See details . require_same_p logical(1). TRUE (default), p_values must generated exactly model object, even case surrogate p-values. disable option FALSE certain deliberate exception appropriate, otherwise calculated p-values may completely invalid. notable valid exception resampling model specification various samples, bootstrapping cross-validation. aler_alpha numeric(2) 0 1. Thresholds p-values (\"alpha\") confidence interval ranges ALER band p_values provided (, NULL). inner band range median value y ± aler_alpha[2] relevant ALE statistic (usually ALE range normalized ALE range). second outer band, range median ± aler_alpha[1]. example, ALE plots, default aler_alpha = c(0.01, 0.05), inner band median ± ALER minimum maximum p = 0.05 outer band median ± ALER minimum maximum p = 0.01. aled_fun character(1) c(\"mad\", \"sd\"), NULL. Deviation function used calculated ALE deviation. \"mad\" mean absolute deviation; \"sd\" standard deviation. default NULL normally use \"mad\" except ALEpDist object provided p_values; case, aled_fun taken ALEpDist object. max_num_bins integer(1) > 1 list. numeric x_cols, sets upper bound number ALE bins, actual bins lesser number unique values max_num_bins. Valid formats : Single integer > 1: used numeric x_cols. List overrides: list exactly two elements: default single integer > 1 used default value; except named integer vector values > 1 per-column upper bounds. Unknown names ignored warning. Non-numeric x_cols (binary/ordinal/categorical) always use observed levels. example list format max_num_bins = list(default = 10, except = c(wt = 25, carb = 4)) default value 10 recommended speed; adequately express relationships. Increase (e.g., 100) complex relationships. However, higher values slower, especially ALE interactions. fct_order character(1) list. Specifies unordered factors characters ordered ALE calculation. (Ordered factors ignore setting; always use intrinsic order.) following options possible: \"levels\" (default): ordered factors, use order factor levels. Recommended meaningful interpretation lets user explicitly control semantic sort order desired. characters, order unique values alphabetically. \"y_col\": Sort based increasing mean values predictions y_col factor level. \"ksd\": recommended except compatibility original ALEPlot reference implementation. List overrides: list exactly two elements: default character string one default value; except named character vector per-column orderings. Unknown names trigger error. example list format fct_order = list(default = \"levels\", except = c(continent = \"y_col\")) See details. boot_it non-negative integer(1). Number bootstrap iterations data-bootstrapping ALE data. appropriate models developed cross-validation. models validated, full-model bootstrapping used instead ModelBoot() class object. See details . default boot_it = 0 turns bootstrapping. boot_alpha numeric(1) 0 1. ALE bootstrapped (boot_it > 0), boot_alpha specifies thresholds p-values (\"alpha\") percentile-based confidence interval range bootstrapped ALE values. bootstrap confidence intervals lowest highest (1 - 0.05) / 2 percentiles. example, boot_alpha = 0.05 (default), confidence intervals 2.5 (low) 97.5 (high) percentiles. boot_centre character(1) c('mean', 'median'). bootstrapping, main estimate ALE y value considered boot_centre. Regardless value specified , mean median available. seed integer(1). Random seed. Supply runs assure identical random ALE data generated time bootstrapping. Without bootstrapping, ALE deterministic algorithm result identical results time regardless seed specified. However, parallel processing enabled, exact computing setup give reproducible results. reproducible results across different computers, leave parallelization disabled parallel = 0. y_type character(1) c('binary', 'numeric', 'categorical', 'ordinal'). Datatype y (outcome) variable. Normally determined automatically; provide error message complex model requires . sample_size non-negative integer(1). Size sample data returned ALE object. primarily used rug plots ALEPlots(). silent logical(1), default FALSE. TRUE, display non-essential messages execution (progress bars). Regardless, warnings errors always display. See details customize progress bars. .bins Internal use . List ALE bin n count vectors. provided, vectors used set intervals ALE x axis variable. default (NULL), ALE() automatically calculates bins. .bins normally used advanced analyses bins previous analysis reused subsequent analyses (example, full model bootstrapping ModelBoot()).","code":""},{"path":"https://tripartio.github.io/ale/reference/ALE.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"ALE data and statistics that describe a trained model — ALE","text":"object class ALE properties effect params.","code":""},{"path":"https://tripartio.github.io/ale/reference/ALE.html","id":"properties","dir":"Reference","previous_headings":"","what":"Properties","title":"ALE data and statistics that describe a trained model — ALE","text":"effect Stores ALE data , optionally, ALE statistics bootstrap data one categories. params parameters used calculate ALE data. include arguments used construct ALE object. either values provided user used default user change also includes several objects created within constructor. extra objects described , well parameters stored differently form arguments:","code":"* `max_d`: the highest dimension of ALE data present. If only 1D ALE is present, then `max_d == 1`. If even one 2D ALE element is present (even with no 1D), then `max_d == 2`. * `requested_x_cols`,`ordered_x_cols`: `requested_x_cols` is the resolved list of `x_cols` as requested by the user (that is, `x_cols` minus `exclude_cols`). `ordered_x_cols` is the same set of `x_cols` but arranged in the internal storage order. * `y_cats`: categories for categorical classification models. For non-categorical models, this is the same as `y_col`. * `y_type`: high-level datatype of the y outcome variable. * `y_summary`: summary statistics of y values used for the ALE calculation. These statistics are based on the actual values of `y_col` unless if `y_type` is a probability or other value that is constrained in the `[0, 1]` range, in which case `y_summary` is based on the predictions of `y_col` from `model` on the `data`. `y_summary` is a named numeric matrix. For most outcomes with a single value per predicted row, there is just one column with the same name as `y_col`. For categorical y outcomes, there is one column for each category in `y_cats` plus an additional column with the same name as `y_col`; this is the mean of the categorical columns. The rows are named mostly as the percentile of the y values. E.g., the '5%' row is the 5th percentile of y values. The following named rows have special meanings: * `min`, `mean`, `max`: the minimum, mean, and maximum y values, respectively. Note that the median is `50%`, the 50th percentile. * `aler_lo_lo`, `aler_lo`, `aler_hi`, `aler_hi_hi`: When p-values are present, `aler_lo` and `aler_hi` are the inner lower and upper confidence intervals of `y_col` values with respect to the median (`50%`); `aler_lo_lo` and `aler_hi_hi` are the outer confidence intervals. See the documentation for the `aler_alpha` argument to understand how these are determined. Without p-values, these elements are absent. * `model`: selected elements that describe the `model` that the `ALE` object interprets. * `data`: selected elements that describe the `data` used to produce the `ALE` object. To avoid the large size of duplicating `data` entirely, only a sample of the size of the `sample_size` argument is retained. * `probs_inverted`: `TRUE` if the original probability values of the ALE object have been inverted using [invert_probs()]. `FALSE`, `NULL`, or absent otherwise."},{"path":"https://tripartio.github.io/ale/reference/ALE.html","id":"custom-predict-function","dir":"Reference","previous_headings":"","what":"Custom predict function","title":"ALE data and statistics that describe a trained model — ALE","text":"calculation ALE requires modifying several values original data. Thus, ALE() needs direct access predict function model. default, ALE() uses generic default predict function form predict(object, newdata, type) default prediction type 'response'. , however, desired prediction values generated format, user must specify want. often, modification needed change prediction type value setting pred_type argument (e.g., 'prob' generated classification probabilities). desired predictions need different function signature, user must create custom prediction function pass pred_fun. requirements custom function : must take three required arguments nothing else: object: model newdata: dataframe compatible table type tibble data.table type: string; usually specified type = pred_type argument names according R convention generic stats::predict() function. must return vector matrix numeric values prediction. can see example custom prediction function.","code":""},{"path":"https://tripartio.github.io/ale/reference/ALE.html","id":"ale-statistics-and-p-values","dir":"Reference","previous_headings":"","what":"ALE statistics and p-values","title":"ALE data and statistics that describe a trained model — ALE","text":"details ALE-based statistics (ALED, ALER, NALED, NALER), see vignette('ale-statistics'). general details calculation p-values, see ALEpDist(). , clarify automatic calculation p-values ALE() constructor. explained documentation p_values argument, default p_values = \"auto\" try automatically create fast surrogate ALEpDist object. However, condition statistics requested (default, output_stats = TRUE) bootstrapping also requested (default, boot_it value greater 0). Requesting statistics necessary otherwise p-values needed. However, requirement requiring bootstrapping pragmatic design choice. challenge creating ALEpDist object can slow. (Even fast surrogate option rarely takes less 10 seconds, even parallelization.) Thus, optimize speed, p-values calculated unless requested. However, user requests bootstrapping (slower requesting ), can assumed willing sacrifice speed sake greater precision ALE analysis; thus, extra time taken least create relatively faster surrogate ALEpDist object.","code":""},{"path":"https://tripartio.github.io/ale/reference/ALE.html","id":"parallel-processing","dir":"Reference","previous_headings":"","what":"Parallel processing","title":"ALE data and statistics that describe a trained model — ALE","text":"Parallel processing possible using {furrr} framework. number parallel threads (workers cores) specified parallel argument. default (parallel = 0), disabled. parallel = \"one\" use available physical CPU cores except one, reserved computer slow continue working tasks procedure runs. parallel = \"\" option use physical logical CPU cores reported system, result might sometimes slower inappropriate allocation parallel processors chokes system. {ale} package able automatically recognize load packages needed, parallel processing enabled, packages might properly loaded. problem might indicated get strange error message mentions something somewhere \"progress interrupted\" \"future\", especially see errors progress bars begin displaying (assuming disable progress bars silent = TRUE). case, first try disabling parallel processing parallel = 0. resolves problem, get faster parallel processing work, try adding package names needed model model_packages argument, e.g., model_packages = c('tidymodels', 'mgcv').","code":""},{"path":"https://tripartio.github.io/ale/reference/ALE.html","id":"time-to-event-survival-models","dir":"Reference","previous_headings":"","what":"Time-to-event (survival) models","title":"ALE data and statistics that describe a trained model — ALE","text":"time--event (survival) models, set following arguments: y_col must set name binary event column. Include time column exclude_cols argument ALE calculated, e.g., exclude_cols = 'time'. essential excluded, always result exactly zero ALE effect time outcome, predictor, time--event model's outcome, calculating waste time. pred_type must specified according desired type argument predict() method time--event algorithm (e.g., \"risk\", \"survival\", \"time\", etc.). pred_fun might work fine without modification long settings configured. However, error time--event models, custom pred_fun specified might needed.","code":""},{"path":"https://tripartio.github.io/ale/reference/ALE.html","id":"progress-bars","dir":"Reference","previous_headings":"","what":"Progress bars","title":"ALE data and statistics that describe a trained model — ALE","text":"Progress bars implemented {progressr} package. details customizing progress bars, see introduction {progressr} package. disable progress bars calling function ale package, set silent = TRUE.","code":""},{"path":"https://tripartio.github.io/ale/reference/ALE.html","id":"sorting-of-unordered-factors","dir":"Reference","previous_headings":"","what":"Sorting of unordered factors","title":"ALE data and statistics that describe a trained model — ALE","text":"ALE algorithm requires order values variables. basic datatypes natural order except unordered factors characters. fct_order specifies unordered factors ordered ALE calculation. (Ordered factors ignore setting; always use intrinsic order.) Note factor ordering effect discriminativeness ALE algorithm; affects level listed first, second, comparison , relevant interpretation. first level according fct_order always calculated zero effect; ALE levels relative first level. recommend users explicitly set levels factor order meaningful interpretation leave fct_order default value (\"levels\"). Character columns treat unique values factor levels. fct_order = \"levels\", order values alphabetical make easier find results plots. alternative ordering set fct_order = \"y_col\", sorts levels based increasing mean values predictions y_col factor level. Thus, ALE results show isolated effects level factor might differ average effects variables come play. original ALEPlot reference implementation sorts factor levels based similarity , using algorithm based Kolmogorov-Smirnov distances multidimensional scaling. However, implementation calculates distances using data happen dataset, even data used model . results arbitrary different sort orders unless columns used model excluded dataset. recommend approach, include \"ksd\" option compatibility original ALEPlot reference implementation.","code":""},{"path":"https://tripartio.github.io/ale/reference/ALE.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"ALE data and statistics that describe a trained model — ALE","text":"Okoli, Chitu. 2023. “Statistical Inference Using Machine Learning Classical Techniques Based Accumulated Local Effects (ALE).” arXiv. doi:10.48550/arXiv.2310.09877.","code":""},{"path":"https://tripartio.github.io/ale/reference/ALE.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"ALE data and statistics that describe a trained model — ALE","text":"","code":"# Load diamonds dataset with some cleanup library(dplyr) #>  #> Attaching package: ‘dplyr’ #> The following objects are masked from ‘package:stats’: #>  #>     filter, lag #> The following objects are masked from ‘package:base’: #>  #>     intersect, setdiff, setequal, union diamonds <- ggplot2::diamonds |>   filter(!(x == 0 | y == 0 | z == 0)) |>   # https://lorentzen.ch/index.php/2021/04/16/a-curious-fact-on-the-diamonds-dataset/   distinct(     price, carat, cut, color, clarity,     .keep_all = TRUE   ) |>   rename(     x_length = x,     y_width = y,     z_depth = z,     depth_pct = depth   )   # Create a GAM model with flexible curves to predict diamond price # Smooth all numeric variables and include all other variables gam_diamonds <- mgcv::gam(   price ~ s(carat) + s(depth_pct) + s(table) + s(x_length) + s(y_width) + s(z_depth) +     cut + color + clarity,   data = diamonds ) summary(gam_diamonds) #>  #> Family: gaussian  #> Link function: identity  #>  #> Formula: #> price ~ s(carat) + s(depth_pct) + s(table) + s(x_length) + s(y_width) +  #>     s(z_depth) + cut + color + clarity #>  #> Parametric coefficients: #>              Estimate Std. Error  t value Pr(>|t|)     #> (Intercept)  4436.199     13.315  333.165  < 2e-16 *** #> cut.L         263.124     39.117    6.727 1.76e-11 *** #> cut.Q           1.792     27.558    0.065 0.948151     #> cut.C          74.074     20.169    3.673 0.000240 *** #> cut^4          27.694     14.373    1.927 0.054004 .   #> color.L     -2152.488     18.996 -113.313  < 2e-16 *** #> color.Q      -704.604     17.385  -40.528  < 2e-16 *** #> color.C       -66.839     16.366   -4.084 4.43e-05 *** #> color^4        80.376     15.289    5.257 1.47e-07 *** #> color^5      -110.164     14.484   -7.606 2.89e-14 *** #> color^6       -49.565     13.464   -3.681 0.000232 *** #> clarity.L    4111.691     33.499  122.742  < 2e-16 *** #> clarity.Q   -1539.959     31.211  -49.341  < 2e-16 *** #> clarity.C     762.680     27.013   28.234  < 2e-16 *** #> clarity^4    -232.214     21.977  -10.566  < 2e-16 *** #> clarity^5     193.854     18.324   10.579  < 2e-16 *** #> clarity^6      46.812     16.172    2.895 0.003799 **  #> clarity^7     132.621     14.274    9.291  < 2e-16 *** #> --- #> Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 #>  #> Approximate significance of smooth terms: #>                edf Ref.df       F  p-value     #> s(carat)     8.695  8.949  37.027  < 2e-16 *** #> s(depth_pct) 7.606  8.429   6.758  < 2e-16 *** #> s(table)     5.759  6.856   3.682 0.000736 *** #> s(x_length)  8.078  8.527  60.936  < 2e-16 *** #> s(y_width)   7.477  8.144 211.202  < 2e-16 *** #> s(z_depth)   9.000  9.000  16.266  < 2e-16 *** #> --- #> Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 #>  #> R-sq.(adj) =  0.929   Deviance explained = 92.9% #> GCV = 1.2602e+06  Scale est. = 1.2581e+06  n = 39739   # \\donttest{  # Simple ALE without bootstrapping: by default, all 1D ALE effects  # For speed, these examples use retrieve_rds() to load pre-created objects # from an online repository. # To run the code yourself, execute the code blocks directly. serialized_objects_site <- \"https://github.com/tripartio/ale/raw/main/download\"  # Create ALE data ale_gam_diamonds <- retrieve_rds(   # For speed, load a pre-created object by default.   c(serialized_objects_site, 'ale_gam_diamonds.0.5.2.rds'),   {     # To run the code yourself, execute this code block directly.     # For models like mgcv::gam that store their data,     # there is no need to specify the data argument.     ALE(gam_diamonds)   } )  # Simple printing of all plots plot(ale_gam_diamonds)   # Bootstrapped ALE # This can be slow, since bootstrapping runs the algorithm boot_it times. # In addition, bootstrapping automatically generates surrogate p-values by default.  # Create ALE with 100 bootstrap samples ale_gam_diamonds_boot <- retrieve_rds(   # For speed, load a pre-created object by default.   c(serialized_objects_site, 'ale_gam_diamonds_boot.0.5.2.rds'),   {     # To run the code yourself, execute this code block directly.     ALE(       gam_diamonds,       # request all 1D ALE effects and only the carat:clarity 2D effect       list(d1 = TRUE, d2 = 'carat:clarity'),       boot_it = 100     )   } ) # saveRDS(ale_gam_diamonds_boot, file.choose())  # More advanced plot manipulation ale_plots <- plot(ale_gam_diamonds_boot) # Create an ALEPlots object  # Print the plots: First page prints 1D ALE; second page prints 2D ALE ale_plots  # or print(ale_plots) to be explicit    # Extract specific plots (as lists of ggplot objects) get(ale_plots, 'carat')  # extract a specific 1D plot  get(ale_plots, 'carat:clarity')  # extract a specific 2D plot  get(ale_plots, type = 'effect')  # ALE effects plot #> `height` was translated to `width`.  # See help(get.ALEPlots) for more options, such as for categorical plots    # If the predict function you want does not work automatically, you may # define a custom predict function. It must return a single numeric vector. custom_predict <- function(object, newdata, type = pred_type) {   predict(object, newdata, type = type, se.fit = TRUE)$fit }  ale_gam_diamonds_custom <- retrieve_rds(   # For speed, load a pre-created object by default.   c(serialized_objects_site, 'ale_gam_diamonds_custom.0.5.2.rds'),   {     # To run the code yourself, execute this code block directly.     ALE(       gam_diamonds,       pred_fun = custom_predict,       pred_type = 'link'     )   } ) # saveRDS(ale_gam_diamonds_custom, file.choose())  # Plot the ALE data plot(ale_gam_diamonds_custom)    # How to retrieve specific types of ALE data from an ALE object. ale_diamonds_with_boot_data <- retrieve_rds(   # For speed, load a pre-created object by default.   c(serialized_objects_site, 'ale_diamonds_with_boot_data.0.5.2.rds'),   {     # To run the code yourself, execute this code block directly.     # For models like mgcv::gam that store their data,     # there is no need to specify the data argument.     ALE(       gam_diamonds,       # For detailed options for x_cols, see examples at resolve_x_cols()       x_cols = ~ carat + cut + clarity + carat:clarity + color:depth_pct,       output_boot_data = TRUE,       boot_it = 10  # just for demonstration     )   } ) # saveRDS(ale_diamonds_with_boot_data, file.choose())  # See ?get.ALE for details on the various kinds of data that may be retrieved. get(ale_diamonds_with_boot_data, ~ carat + color:depth_pct)  # default ALE data #> $d1 #> $d1$carat #> # A tibble: 10 × 7 #>    carat.ceil    .n     .y  .y_lo .y_mean .y_median  .y_hi #>         <dbl> <int>  <dbl>  <dbl>   <dbl>     <dbl>  <dbl> #>  1       0.2      7 -3234. -3234.  -3234.    -3234. -3234. #>  2       0.36  4737 -1009. -1009.  -1009.    -1009. -1009. #>  3       0.5   4431   869.   869.    869.      869.   869. #>  4       0.6   4100  2101.  2101.   2101.     2101.  2101. #>  5       0.73  4442  3467.  3467.   3467.     3467.  3467. #>  6       0.94  4406  4910.  4910.   4910.     4910.  4910. #>  7       1.03  4535  5244.  5244.   5244.     5244.  5244. #>  8       1.2   4370  5604.  5604.   5604.     5604.  5604. #>  9       1.52  4605  6446.  6446.   6446.     6446.  6446. #> 10       5.01  4106  9489.  9489.   9489.     9489.  9489. #>  #>  #> $d2 #> $d2$`color:depth_pct` #> # A tibble: 70 × 8 #>    color.bin depth_pct.ceil    .n    .y .y_lo .y_mean .y_median .y_hi #>    <ord>              <dbl> <int> <dbl> <dbl>   <dbl>     <dbl> <dbl> #>  1 D                     43     0  3365  3365    3365      3365  3365 #>  2 E                     43     0  3365  3365    3365      3365  3365 #>  3 F                     43     0  3365  3365    3365      3365  3365 #>  4 G                     43     1  3365  3365    3365      3365  3365 #>  5 H                     43     0  3365  3365    3365      3365  3365 #>  6 I                     43     0  3365  3365    3365      3365  3365 #>  7 J                     43     1  3365  3365    3365      3365  3365 #>  8 D                     60   627  3365  3365    3365      3365  3365 #>  9 E                     60   940  3365  3365    3365      3365  3365 #> 10 F                     60   871  3365  3365    3365      3365  3365 #> # ℹ 60 more rows #>  #>  get(ale_diamonds_with_boot_data, what = 'boot_data')  # raw bootstrap data #> $d1 #> $d1$carat #> # A tibble: 110 × 6 #>      .it carat .y_composite    .n .y_distinct     .y #>    <dbl> <dbl>        <dbl> <dbl>       <dbl>  <dbl> #>  1     0  0.2        -3234.     7      -3234. -3234. #>  2     0  0.36       -1009.  4737      -1009. -1009. #>  3     0  0.5          869.  4431        869.   869. #>  4     0  0.6         2101.  4100       2101.  2101. #>  5     0  0.73        3467.  4442       3467.  3467. #>  6     0  0.94        4910.  4406       4910.  4910. #>  7     0  1.03        5244.  4535       5244.  5244. #>  8     0  1.2         5604.  4370       5604.  5604. #>  9     0  1.52        6446.  4605       6446.  6446. #> 10     0  5.01        9489.  4106       9489.  9489. #> # ℹ 100 more rows #>  #> $d1$cut #> # A tibble: 55 × 6 #>      .it cut       .y_composite    .n .y_distinct    .y #>    <dbl> <fct>            <dbl> <dbl>       <dbl> <dbl> #>  1     0 Fair             3110.  1492       3110. 3110. #>  2     0 Good             3245.  4173       3245. 3245. #>  3     0 Very Good        3314.  9714       3314. 3314. #>  4     0 Premium          3318.  9657       3318. 3318. #>  5     0 Ideal            3489. 14703       3489. 3489. #>  6     1 Fair             3361.  1492       3361. 3361. #>  7     1 Good             3615.  4173       3615. 3615. #>  8     1 Very Good        3733.  9714       3733. 3733. #>  9     1 Premium          3785.  9657       3785. 3785. #> 10     1 Ideal            3831. 14703       3831. 3831. #> # ℹ 45 more rows #>  #> $d1$clarity #> # A tibble: 88 × 6 #>      .it clarity .y_composite    .n .y_distinct    .y #>    <dbl> <fct>          <dbl> <dbl>       <dbl> <dbl> #>  1     0 I1             -109.   704       -109. -109. #>  2     0 SI2            2114.  7916       2114. 2114. #>  3     0 SI1            3035.  9857       3035. 3035. #>  4     0 VS2            3702.  8227       3702. 3702. #>  5     0 VS1            4020.  6007       4020. 4020. #>  6     0 VVS2           4517.  3463       4517. 4517. #>  7     0 VVS1           4594.  2413       4594. 4594. #>  8     0 IF             5052.  1152       5052. 5052. #>  9     1 I1             3356.   704       3356. 3356. #> 10     1 SI2            6830.  7916       6830. 6830. #> # ℹ 78 more rows #>  #>  #> $d2 #> $d2$`carat:clarity` #> # A tibble: 880 × 7 #>      .it carat clarity .y_composite    .n .y_distinct    .y #>    <dbl> <dbl> <fct>          <dbl> <dbl>       <dbl> <dbl> #>  1     0  0.2  I1              3365     0       3365  3365  #>  2     0  0.36 I1              3365    10       3365  3365  #>  3     0  0.5  I1              3365    28       3365  3365  #>  4     0  0.6  I1              3365    14       3365  3365  #>  5     0  0.73 I1              3365    55       3365  3365  #>  6     0  0.94 I1              3365    56       3365  3365  #>  7     0  1.03 I1              3365   134       3365  3365  #>  8     0  1.2  I1              3365   125       3365  3365  #>  9     0  1.52 I1              3365   119       3365  3365  #> 10     0  5.01 I1              3365   163       3365. 3365. #> # ℹ 870 more rows #>  #> $d2$`color:depth_pct` #> # A tibble: 770 × 7 #>      .it color depth_pct .y_composite    .n .y_distinct    .y #>    <dbl> <fct>     <dbl>        <dbl> <dbl>       <dbl> <dbl> #>  1     0 D            43         3365     0        3365  3365 #>  2     0 E            43         3365     0        3365  3365 #>  3     0 F            43         3365     0        3365  3365 #>  4     0 G            43         3365     1        3365  3365 #>  5     0 H            43         3365     0        3365  3365 #>  6     0 I            43         3365     0        3365  3365 #>  7     0 J            43         3365     1        3365  3365 #>  8     0 D            60         3365   627        3365  3365 #>  9     0 E            60         3365   940        3365  3365 #> 10     0 F            60         3365   871        3365  3365 #> # ℹ 760 more rows #>  #>  get(ale_diamonds_with_boot_data, stats = 'estimate')  # summary statistics #> $d1 #> # A tibble: 3 × 7 #>   term     aled  aler_min aler_max naled naler_min naler_max #>   <chr>   <dbl>     <dbl>    <dbl> <dbl>     <dbl>     <dbl> #> 1 carat   2592. -6599.       6124. 25.5  -50           36.2  #> 2 cut      398.     0.585     474.  3.59   0.00453      4.31 #> 3 clarity 4185.   -16.3      5038. 29.5   -0.174       33.0  #>  #> $d2 #> # A tibble: 2 × 7 #>   term                aled  aler_min aler_max naled naler_min naler_max #>   <chr>              <dbl>     <dbl>    <dbl> <dbl>     <dbl>     <dbl> #> 1 carat:clarity   1.08e-12 -6.27e-12 2.43e-12     0         0         0 #> 2 color:depth_pct 6.69e-13 -1.27e-12 6.74e-13     0         0         0 #>  get(ale_diamonds_with_boot_data, stats = c('aled', 'naled')) #> $d1 #> # A tibble: 6 × 8 #>   statistic estimate p.value term    conf.low    mean  median conf.high #>   <chr>        <dbl>   <dbl> <chr>      <dbl>   <dbl>   <dbl>     <dbl> #> 1 aled       2592.         0 carat    2583.   2592.   2592.     2597.   #> 2 naled        25.5        0 carat      25.4    25.5    25.5      25.5  #> 3 aled        398.         0 cut       392.    398.    398.      403.   #> 4 naled         3.59       0 cut         3.54    3.59    3.60      3.64 #> 5 aled       4185.         0 clarity  4081.   4185.   4195.     4252.   #> 6 naled        29.5        0 clarity    29.1    29.5    29.6      29.8  #>  #> $d2 #> # A tibble: 4 × 8 #>   statistic estimate p.value term           conf.low     mean   median conf.high #>   <chr>        <dbl>   <dbl> <chr>             <dbl>    <dbl>    <dbl>     <dbl> #> 1 aled      1.08e-12       1 carat:clarity  7.67e-13 1.08e-12 1.08e-12  1.43e-12 #> 2 naled     0              1 carat:clarity  0        0        0         0        #> 3 aled      6.69e-13       1 color:depth_p… 1.80e-13 6.69e-13 5.33e-13  1.56e-12 #> 4 naled     0              1 color:depth_p… 0        0        0         0        #>  get(ale_diamonds_with_boot_data, stats = 'all') #> $d1 #> # A tibble: 18 × 8 #>    statistic    estimate p.value term      conf.low      mean   median conf.high #>    <chr>           <dbl>   <dbl> <chr>        <dbl>     <dbl>    <dbl>     <dbl> #>  1 aled       2592.         0    carat    2583.       2.59e+3  2.59e+3   2.60e+3 #>  2 aler_min  -6599.         0    carat   -6599.      -6.60e+3 -6.60e+3  -6.60e+3 #>  3 aler_max   6124.         0    carat    6124.       6.12e+3  6.12e+3   6.12e+3 #>  4 naled        25.5        0    carat      25.4      2.55e+1  2.55e+1   2.55e+1 #>  5 naler_min   -50          0    carat     -50       -5   e+1 -5   e+1  -5   e+1 #>  6 naler_max    36.2        0    carat      36.2      3.62e+1  3.62e+1   3.62e+1 #>  7 aled        398.         0    cut       392.       3.98e+2  3.98e+2   4.03e+2 #>  8 aler_min      0.585      1    cut        -3.47     5.85e-1  1.23e-1   5.89e+0 #>  9 aler_max    474.         0.14 cut       467.       4.74e+2  4.74e+2   4.79e+2 #> 10 naled         3.59       0    cut         3.54     3.59e+0  3.60e+0   3.64e+0 #> 11 naler_min     0.00453    1    cut        -0.0352   4.53e-3  0         4.86e-2 #> 12 naler_max     4.31       0.13 cut         4.26     4.31e+0  4.32e+0   4.36e+0 #> 13 aled       4185.         0    clarity  4081.       4.18e+3  4.20e+3   4.25e+3 #> 14 aler_min    -16.3        0.96 clarity  -129.      -1.63e+1  1.11e+0   3.68e+1 #> 15 aler_max   5038.         0    clarity  4939.       5.04e+3  5.04e+3   5.11e+3 #> 16 naled        29.5        0    clarity    29.1      2.95e+1  2.96e+1   2.98e+1 #> 17 naler_min    -0.174      0.96 clarity    -1.28    -1.74e-1 -5.05e-3   3.42e-1 #> 18 naler_max    33.0        0    clarity    32.7      3.30e+1  3.30e+1   3.32e+1 #>  #> $d2 #> # A tibble: 12 × 8 #>    statistic  estimate p.value term       conf.low      mean    median conf.high #>    <chr>         <dbl>   <dbl> <chr>         <dbl>     <dbl>     <dbl>     <dbl> #>  1 aled       1.08e-12       1 carat:cl…  7.67e-13  1.08e-12  1.08e-12  1.43e-12 #>  2 aler_min  -6.27e-12       1 carat:cl… -7.85e-12 -6.27e-12 -6.09e-12 -5.01e-12 #>  3 aler_max   2.43e-12       1 carat:cl…  1.76e-12  2.43e-12  2.41e-12  3.37e-12 #>  4 naled      0              1 carat:cl…  0         0         0         0        #>  5 naler_min  0              1 carat:cl…  0         0         0         0        #>  6 naler_max  0              1 carat:cl…  0         0         0         0        #>  7 aled       6.69e-13       1 color:de…  1.80e-13  6.69e-13  5.33e-13  1.56e-12 #>  8 aler_min  -1.27e-12       1 color:de… -2.75e-12 -1.27e-12 -1.35e-12 -3.14e-13 #>  9 aler_max   6.74e-13       1 color:de…  1.75e-13  6.74e-13  5.38e-13  1.34e-12 #> 10 naled      0              1 color:de…  0         0         0         0        #> 11 naler_min  0              1 color:de…  0         0         0         0        #> 12 naler_max  0              1 color:de…  0         0         0         0        #>  get(ale_diamonds_with_boot_data, stats = 'conf_regions') #> ! Note that confidence regions are not reliable with fewer than 100 bootstrap #>   iterations or p-values based on fewer than 100 random iterations. #> ℹ There are 10 bootstrap iterations. #> ℹ p-values are based on 100 iterations. #> $d1 #> # A tibble: 16 × 12 #>    term    x     start_x end_x x_span_pct     n   pct     y start_y end_y  trend #>    <chr>   <chr>   <dbl> <dbl>      <dbl> <int> <dbl> <dbl>   <dbl> <dbl>  <dbl> #>  1 carat   NA       0.2   0.6        8.32 13275 33.4    NA   -3234. 2101.  3.71  #>  2 carat   NA       0.73  0.73       0     4442 11.2    NA    3467. 3467.  0     #>  3 carat   NA       0.94  5.01      84.6  22022 55.4    NA    4910. 9489.  0.313 #>  4 cut     Fair    NA    NA         NA     1492  3.75 3342.     NA    NA  NA     #>  5 cut     Good    NA    NA         NA     4173 10.5  3587.     NA    NA  NA     #>  6 cut     Very…   NA    NA         NA     9714 24.4  3702.     NA    NA  NA     #>  7 cut     Prem…   NA    NA         NA     9657 24.3  3748.     NA    NA  NA     #>  8 cut     Ideal   NA    NA         NA    14703 37.0  3807.     NA    NA  NA     #>  9 clarity I1      NA    NA         NA      704  1.77 3034.     NA    NA  NA     #> 10 clarity SI2     NA    NA         NA     7916 19.9  6392.     NA    NA  NA     #> 11 clarity SI1     NA    NA         NA     9857 24.8  7610.     NA    NA  NA     #> 12 clarity VS2     NA    NA         NA     8227 20.7  7975.     NA    NA  NA     #> 13 clarity VS1     NA    NA         NA     6007 15.1  7695.     NA    NA  NA     #> 14 clarity VVS2    NA    NA         NA     3463  8.71 7144.     NA    NA  NA     #> 15 clarity VVS1    NA    NA         NA     2413  6.07 6101.     NA    NA  NA     #> 16 clarity IF      NA    NA         NA     1152  2.90 5045.     NA    NA  NA     #> # ℹ 1 more variable: aler_band <ord> #>  #> $d2 #> # A tibble: 45 × 8 #>    term1 x1          term2   x2    aler_band     n   pct     y #>    <chr> <chr>       <chr>   <chr> <ord>     <int> <dbl> <dbl> #>  1 carat [0.2,0.6]   clarity I1    overlap      52 0.131  3365 #>  2 carat (0.6,1.03]  clarity I1    overlap     245 0.617  3365 #>  3 carat (1.03,5.01] clarity I1    overlap     407 1.02   3365 #>  4 carat [0.2,0.6]   clarity SI2   overlap    1180 2.97   3365 #>  5 carat (0.6,1.03]  clarity SI2   overlap    3036 7.64   3365 #>  6 carat (1.03,5.01] clarity SI2   overlap    3700 9.31   3365 #>  7 carat [0.2,0.6]   clarity SI1   overlap    2665 6.71   3365 #>  8 carat (0.6,1.03]  clarity SI1   overlap    3921 9.87   3365 #>  9 carat (1.03,5.01] clarity SI1   overlap    3271 8.23   3365 #> 10 carat [0.2,0.6]   clarity VS2   overlap    2693 6.78   3365 #> # ℹ 35 more rows #>  get(ale_diamonds_with_boot_data, stats = 'conf_sig') #> ! Note that confidence regions are not reliable with fewer than 100 bootstrap #>   iterations or p-values based on fewer than 100 random iterations. #> ℹ There are 10 bootstrap iterations. #> ℹ p-values are based on 100 iterations. #> # A tibble: 11 × 12 #>    term    x     start_x end_x x_span_pct     n   pct     y start_y end_y  trend #>    <chr>   <chr>   <dbl> <dbl>      <dbl> <int> <dbl> <dbl>   <dbl> <dbl>  <dbl> #>  1 carat   NA       0.2   0.6        8.32 13275 33.4    NA   -3234. 2101.  3.71  #>  2 carat   NA       0.73  0.73       0     4442 11.2    NA    3467. 3467.  0     #>  3 carat   NA       0.94  5.01      84.6  22022 55.4    NA    4910. 9489.  0.313 #>  4 clarity I1      NA    NA         NA      704  1.77 3034.     NA    NA  NA     #>  5 clarity SI2     NA    NA         NA     7916 19.9  6392.     NA    NA  NA     #>  6 clarity SI1     NA    NA         NA     9857 24.8  7610.     NA    NA  NA     #>  7 clarity VS2     NA    NA         NA     8227 20.7  7975.     NA    NA  NA     #>  8 clarity VS1     NA    NA         NA     6007 15.1  7695.     NA    NA  NA     #>  9 clarity VVS2    NA    NA         NA     3463  8.71 7144.     NA    NA  NA     #> 10 clarity VVS1    NA    NA         NA     2413  6.07 6101.     NA    NA  NA     #> 11 clarity IF      NA    NA         NA     1152  2.90 5045.     NA    NA  NA     #> # ℹ 1 more variable: aler_band <ord> # }"},{"path":"https://tripartio.github.io/ale/reference/ALEPlots.html","id":null,"dir":"Reference","previous_headings":"","what":"ALE plots with print and plot methods — ALEPlots","title":"ALE plots with print and plot methods — ALEPlots","text":"ALEPlots S7 object contains ALE plots ALE ModelBoot objects stored ggplot objects. ALEPlots constructor creates possible plots ALE ModelBoot passed —individual 1D 2D ALE plots, also special plots like ALE effects plot. , ALEPlots object collection plots, almost never single plot. retrieve specific plots, use get.ALEPlots() method. See examples ALE() ModelBoot() objects manipulate ALEPlots objects.","code":""},{"path":"https://tripartio.github.io/ale/reference/ALEPlots.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"ALE plots with print and plot methods — ALEPlots","text":"","code":"ALEPlots(   obj,   ...,   ale_centre = \"median\",   consolid_cats = 10L,   y_1d_refs = c(\"25%\", \"75%\"),   rug_sample_size = obj@params$sample_size,   min_rug_per_interval = 1L,   min_col_width = 0.05,   y_nonsig_band = 0.05,   seed = 0,   silent = FALSE )"},{"path":"https://tripartio.github.io/ale/reference/ALEPlots.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"ALE plots with print and plot methods — ALEPlots","text":"obj ALE ModelBoot object. object containing ALE data plotted. ... used. Inserted require explicit naming subsequent arguments. ale_centre character(1) c('median', 'mean', 'zero'). ALE y values plots centred relative value. 'median' default. 'zero' maintain actual ALE values, centred zero. consolid_cats integer(1) > 1 list. 1D plots categorical variables, maximum consolid_cats distinct values (e.g., factor levels) shown. top consolid_cats - 1 values ALE strength shown values consolidated \"\" category. See details calculation. Valid formats : Single integer > 1: Consolidate categories consolid_cats factor levels. List required levels: list exactly two elements: max single-integer option : maximum allowable levels consolidation begins; include named list. sublist character vector specific levels must included factor variable names. Unknown names factor levels trigger error. example list format : consolid_cats = list(max = 10, include = list(model = c(\"Cadillac Fleetwood\", \"Volvo 142E\"))) y_1d_refs character numeric vector. 1D ALE plots, y outcome values reference line drawn. character vector, y_1d_refs values names obj@params$y_summary (usually quantile names). numeric vector, y_1d_refs values must values within range y, , obj@params$y_summary$min obj@params$y_summary$max inclusive. rug_sample_size, min_rug_per_interval non-negative integer(1). Rug plots -sampled rug_sample_size rows, otherwise can slow large datasets. default, size value obj@params$sample_size. maintain representativeness data guaranteeing ALE bins retain least min_rug_per_interval elements; usually set just 1 (default) 2. prevent -sampling, set rug_sample_size Inf (ALEPlots object store entire dataset, become large). min_col_width numeric(1) [0.01, 1]. Column charts scale column column representing category elements scale 1 columns width fraction largest category proportional numbers elements. However, visibility, column displayed narrower scale min_col_width. disable scaling width, set min_col_width = 1. y_nonsig_band numeric(1) 0 1. p-values, plots (notably 1D effects plot) shade grey inner y_nonsig_band quantile ale_centre average (median, default) indicate nonsignificant effects. seed See documentation ALE() silent See documentation ALE()","code":""},{"path":"https://tripartio.github.io/ale/reference/ALEPlots.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"ALE plots with print and plot methods — ALEPlots","text":"object class ALEPlots properties plots params.","code":""},{"path":"https://tripartio.github.io/ale/reference/ALEPlots.html","id":"properties","dir":"Reference","previous_headings":"","what":"Properties","title":"ALE plots with print and plot methods — ALEPlots","text":"plots Stores ALE plots. Use get.ALEPlots() access . params parameters used calculate ALE plots. include arguments used construct ALEPlots object. either values provided user used default user change also includes several objects created within constructor. extra objects described , well parameters stored differently form arguments:","code":"* `y_col`, `y_cats`: See documentation for [ALE()] * `max_d`: See documentation for [ALE()] * `requested_x_cols`: See documentation for [ALE()]. Note, however, that `ALEPlots` does not store `ordered_x_cols`."},{"path":"https://tripartio.github.io/ale/reference/ALEPlots.html","id":"consolidation-of-factors","dir":"Reference","previous_headings":"","what":"Consolidation of factors","title":"ALE plots with print and plot methods — ALEPlots","text":"categorical (unordered factor) variable many levels, 1D column charts used plot ALE become unwieldy hard read. , consolid_cats argument sets maximum number categories (factor levels) display. example, default consolid_cats = 10: consolid_cats (default 10) fewer categories, consolidation. consolid_cats categories, categories ranked decreasing absolute ALE y value. top consolid_cats - 1 (default 9) categories retained. categories consolidated one \"\" category reports count consolidated categories. Consolidated means weighted mean categories; consolidated medians, maximums, minimums medians, maximums, minimums, respectively, categories. Sometimes, specific factor levels always want see; want consolidated even effects low. case, see argument specification list levels must always included. Note consolidation purely visualization; underlying ALE data consolidated. unordered factors consolidated thus; ordered factors never consolidated since order meaningful. Moreover, now, 1D ALE plots consolidated.","code":""},{"path":"https://tripartio.github.io/ale/reference/ALEPlots.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"ALE plots with print and plot methods — ALEPlots","text":"","code":"# See examples with ALE() and ModelBoot() objects."},{"path":"https://tripartio.github.io/ale/reference/ALEpDist.html","id":null,"dir":"Reference","previous_headings":"","what":"Random variable distributions of ALE statistics for generating p-values — ALEpDist","title":"Random variable distributions of ALE statistics for generating p-values — ALEpDist","text":"ALE statistics accompanied two indicators confidence values. First, bootstrapping creates confidence intervals ALE effects ALE statistics give range possible ALE values. Second, calculate p-values, indicator probability given ALE statistic random. ALEpDist S7 object contains necessary distribution data generating p-values.","code":""},{"path":"https://tripartio.github.io/ale/reference/ALEpDist.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Random variable distributions of ALE statistics for generating p-values — ALEpDist","text":"","code":"ALEpDist(   model,   data = NULL,   ...,   y_col = NULL,   rand_it = NULL,   surrogate = FALSE,   parallel = 0,   model_packages = NULL,   random_model_call_string = NULL,   random_model_call_string_vars = character(),   positive = TRUE,   pred_fun = NULL,   pred_type = \"response\",   aled_fun = \"mad\",   output_residuals = FALSE,   seed = 0,   silent = FALSE,   .skip_validation = FALSE )"},{"path":"https://tripartio.github.io/ale/reference/ALEpDist.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Random variable distributions of ALE statistics for generating p-values — ALEpDist","text":"model See documentation ALE() data See documentation ALE() ... used. Inserted require explicit naming subsequent arguments. y_col See documentation ALE() rand_it non-negative integer(1). Number times model retrained new random variable. default NULL generate 1000 iterations, give reasonably stable p-values; considered \"exact\" p-values. can reduced approximate (\"approx\") p-values low 100 faster test runs p-values stable. rand_it 100 allowed p-values inaccurate. surrogate logical(1). Create p-value distributions based surrogate linear model (TRUE) instead original model (default FALSE). Note faster surrogate p-values convenient interactive analysis, acceptable definitive conclusions publication. See details. parallel See documentation ALE(). Note exact p-values, default 1000 random variables trained. , even parallel processing, procedure slow. model_packages See documentation ALE() random_model_call_string character(1). NULL, ALEpDist() constructor tries automatically detect construct call p-values. , constructor fail. case, character string full call model must provided includes random variable. See details. random_model_call_string_vars See documentation model_call_string_vars ModelBoot(); operation similar. positive See documentation ModelBoot() pred_fun, pred_type See documentation ALE() aled_fun See documentation ALE() output_residuals logical(1). TRUE, returns residuals addition raw data generated random statistics (always returned). default FALSE return residuals. seed See documentation ALE() silent See documentation ALE() .skip_validation Internal use . logical(1). Skip non-mutating data validation checks. Changing default FALSE risks crashing incomprehensible error messages.","code":""},{"path":"https://tripartio.github.io/ale/reference/ALEpDist.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Random variable distributions of ALE statistics for generating p-values — ALEpDist","text":"object class ALEpDist properties rand_stats, residual_distribution, residuals, params.","code":""},{"path":"https://tripartio.github.io/ale/reference/ALEpDist.html","id":"properties","dir":"Reference","previous_headings":"","what":"Properties","title":"Random variable distributions of ALE statistics for generating p-values — ALEpDist","text":"rand_stats named list tibbles. normally one element whose name y_col except y_col categorical variable; case, elements named category y_col. element tibble whose rows rand_it_ok iterations random variable analysis whose columns ALE statistics obtained random variable. residual_distribution univariateML object closest estimated distribution residuals determined univariateML::model_select(). distribution used generate random variables. residuals output_residuals == TRUE, returns matrix actual y_col values data minus predicted values model (without random variables) data. rows correspond row data. columns correspond named elements (y_col categories) described rand_stats. NULL output_residuals == FALSE (default). params Parameters used generate p-value distributions. repeat selected arguments passed ALEpDist(). either values provided user used default user change following additional modified objects notable:","code":"* `model`: selected elements that describe the `model` used to generate the random distributions. * `rand_it`: the number of random iterations requested by the user either explicitly (by specifying a whole number) or implicitly with the default `NULL`: exact p distributions imply 1000 iterations and surrogate distributions imply 100 unless an explicit number of iterations is requested. * `rand_it_ok`: A whole number with the number of `rand_it` iterations that successfully generated a random variable, that is, those that did not fail for whatever reason. The `rand_it` - `rand_it_ok` failed attempts are discarded. * `exactness`: A string. For regular p-values generated from the original model, `'exact'` if `rand_it_ok >= 1000` and `'approx'` otherwise. `'surrogate'` for p-values generated from a surrogate model. `'invalid'` if `rand_it_ok < 100`.  * `probs_inverted`: `TRUE` if the original probability values of the `ALEpDist` object have been inverted. This is accomplished using [invert_probs()] on an `ALE` object. `FALSE`, `NULL`, or absent otherwise."},{"path":"https://tripartio.github.io/ale/reference/ALEpDist.html","id":"exact-p-values-for-ale-statistics","dir":"Reference","previous_headings":"","what":"Exact p-values for ALE statistics","title":"Random variable distributions of ALE statistics for generating p-values — ALEpDist","text":"ALE non-parametric (, assume particular distribution data), {ale} package takes literal frequentist approach calculation empirical (Monte Carlo) p-values. , literally retrains model 1000 times, time modifying adding distinct random variable model. (number iterations customizable rand_it argument.) ALEs ALE statistics calculated random variable. percentiles distribution random-variable ALEs used determine p-values non-random variables. Thus, p-values interpreted frequency random variable ALE statistics exceed value ALE statistic actual variable question. specific steps follows: residuals original model trained training data calculated (residuals actual y target value minus predicted values). closest distribution residuals detected univariateML::model_select(). 1000 new models trained generating random variable time univariateML::rml() training new model random variable added. ALEs ALE statistics calculated random variable. ALE statistic, empirical cumulative distribution function (stats::ecdf()) used create function determine p-values according distribution random variables' ALE statistics. ale package model-agnostic (, works kind R model), ALEpDist() constructor always automatically manipulate model object create p-values. can models follow modelling conventions similar base R algorithms (like stats::lm() stats::glm()) many widely used statistics packages (like mgcv survival), probably machine learning algorithms (like tidymodels caret). algorithms follow base R conventions, user needs little work help ALEpDist() constructor correctly manipulate model object: full model call must passed character string argument random_model_call_string, two slight modifications follows. formula specifies model, must add variable named 'random_variable'. corresponds random variables constructor use estimate p-values. dataset model trained must named 'rand_data'. corresponds modified datasets used train random variables. See example implemented. model generation unstable (small dataset size finicky model algorithm), one iterations might fail, possibly dropping number successful iterations 1000. p-values considered approximate; longer exact. case, request rand_it sufficiently high number even iterations fail, least 1000 succeed. example, ALEpDist object named p_dist, p_dist@params$rand_it_ok 950, rerun ALEpDist() rand_it = 1100 higher allow 100 possible failures.","code":""},{"path":"https://tripartio.github.io/ale/reference/ALEpDist.html","id":"faster-approximate-and-surrogate-p-values","dir":"Reference","previous_headings":"","what":"Faster approximate and surrogate p-values","title":"Random variable distributions of ALE statistics for generating p-values — ALEpDist","text":"procedure just described requires least 1000 random iterations p-values considered \"exact\". Unfortunately, procedure rather slow–takes least 1000 times long time takes train model . fewer iterations (least 100), p-values can considered approximate (\"approx\"). Fewer 100 p-values invalid. might fewer iterations either user requests rand_it argument iterations fail whatever reason. long least 1000 iterations succeed, p-values considered exact. procedure can slow, faster version algorithm generates \"surrogate\" p-values substituting original model linear model predicts y_col outcome columns data. default, surrogate p-values use 100 iterations dataset large, surrogate model samples 1000 rows. Thus, surrogate p-values can generated much faster slower model algorithms larger datasets. Although suitable model development analysis faster generate, less reliable approximate p-values based original model. case, definitive conclusions (e.g., publication) always require exact p-values least 1000 iterations original model. Note surrogate p-values always marked \"surrogate\"; even generated based 1000 iterations, can never considered exact based original model.","code":""},{"path":"https://tripartio.github.io/ale/reference/ALEpDist.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Random variable distributions of ALE statistics for generating p-values — ALEpDist","text":"Okoli, Chitu. 2023. \"Statistical Inference Using Machine Learning Classical Techniques Based Accumulated Local Effects (ALE).\" arXiv. doi:10.48550/arXiv.2310.09877.","code":""},{"path":"https://tripartio.github.io/ale/reference/ALEpDist.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Random variable distributions of ALE statistics for generating p-values — ALEpDist","text":"","code":"# \\donttest{  library(dplyr)  # Load diamonds dataset with some cleanup diamonds <- ggplot2::diamonds |>   filter(!(x == 0 | y == 0 | z == 0)) |>   # https://lorentzen.ch/index.php/2021/04/16/a-curious-fact-on-the-diamonds-dataset/   distinct(     price, carat, cut, color, clarity,     .keep_all = TRUE   ) |>   rename(     x_length = x,     y_width = y,     z_depth = z,     depth_pct = depth   )  # Create a GAM model with flexible curves to predict diamond price # Smooth all numeric variables and include all other variables # Build the model on training data, not on the full dataset. gam_diamonds <- mgcv::gam(   price ~ s(carat) + s(depth_pct) + s(table) + s(x_length) + s(y_width) + s(z_depth) +     cut + color + clarity,   data = diamonds ) summary(gam_diamonds) #>  #> Family: gaussian  #> Link function: identity  #>  #> Formula: #> price ~ s(carat) + s(depth_pct) + s(table) + s(x_length) + s(y_width) +  #>     s(z_depth) + cut + color + clarity #>  #> Parametric coefficients: #>              Estimate Std. Error  t value Pr(>|t|)     #> (Intercept)  4436.199     13.315  333.165  < 2e-16 *** #> cut.L         263.124     39.117    6.727 1.76e-11 *** #> cut.Q           1.792     27.558    0.065 0.948151     #> cut.C          74.074     20.169    3.673 0.000240 *** #> cut^4          27.694     14.373    1.927 0.054004 .   #> color.L     -2152.488     18.996 -113.313  < 2e-16 *** #> color.Q      -704.604     17.385  -40.528  < 2e-16 *** #> color.C       -66.839     16.366   -4.084 4.43e-05 *** #> color^4        80.376     15.289    5.257 1.47e-07 *** #> color^5      -110.164     14.484   -7.606 2.89e-14 *** #> color^6       -49.565     13.464   -3.681 0.000232 *** #> clarity.L    4111.691     33.499  122.742  < 2e-16 *** #> clarity.Q   -1539.959     31.211  -49.341  < 2e-16 *** #> clarity.C     762.680     27.013   28.234  < 2e-16 *** #> clarity^4    -232.214     21.977  -10.566  < 2e-16 *** #> clarity^5     193.854     18.324   10.579  < 2e-16 *** #> clarity^6      46.812     16.172    2.895 0.003799 **  #> clarity^7     132.621     14.274    9.291  < 2e-16 *** #> --- #> Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 #>  #> Approximate significance of smooth terms: #>                edf Ref.df       F  p-value     #> s(carat)     8.695  8.949  37.027  < 2e-16 *** #> s(depth_pct) 7.606  8.429   6.758  < 2e-16 *** #> s(table)     5.759  6.856   3.682 0.000736 *** #> s(x_length)  8.078  8.527  60.936  < 2e-16 *** #> s(y_width)   7.477  8.144 211.202  < 2e-16 *** #> s(z_depth)   9.000  9.000  16.266  < 2e-16 *** #> --- #> Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 #>  #> R-sq.(adj) =  0.929   Deviance explained = 92.9% #> GCV = 1.2602e+06  Scale est. = 1.2581e+06  n = 39739   # For speed, these examples use retrieve_rds() to load pre-created objects # from an online repository. # To run the code yourself, execute the code blocks directly. serialized_objects_site <- \"https://github.com/tripartio/ale/raw/main/download\"  # Generating p_value distribution objects is slow because it retrains the model 100 times, # so this example loads a pre-created ALEpDist object. p_dist_gam_diamonds <- retrieve_rds(   c(serialized_objects_site, 'p_dist_gam_diamonds_readme.0.5.2.rds'),   {     # To run the code yourself, execute this code block directly.     ALEpDist(       gam_diamonds, diamonds,       # Normally should be default 1000, but just 100 for quicker demo       rand_it = 100     )   } )  # Examine the structure of the returned object print(p_dist_gam_diamonds) #> <ale::ALEpDist> #>  @ rand_stats           :List of 1 #>  .. $ price: tibble [100 × 6] (S3: tbl_df/tbl/data.frame) #>  ..  ..$ aled     : num [1:100] 4.07 6.15 7.69 8.13 2.26 ... #>  ..  ..$ aler_min : num [1:100] -55.2 -227.8 -398.2 -637.2 -82.7 ... #>  ..  ..$ aler_max : num [1:100] 307.8 187.6 237.5 226.4 59.3 ... #>  ..  ..$ naled    : num [1:100] 0.0531 0.0745 0.089 0.0904 0.0321 ... #>  ..  ..$ naler_min: num [1:100] -0.576 -2.257 -3.865 -6.049 -0.808 ... #>  ..  ..$ naler_max: num [1:100] 2.733 1.696 2.151 2.041 0.581 ... #>  @ residual_distribution: 'univariateML' Named num [1:4] 22.86 1372.41 2.67 1.34 #>  .. - attr(*, \"logLik\")= num -329520 #>  .. - attr(*, \"call\")= language f(x = x, na.rm = na.rm) #>  .. - attr(*, \"n\")= int 39739 #>  .. - attr(*, \"model\")= chr \"Skew Student-t\" #>  .. - attr(*, \"density\")= chr \"fGarch::dsstd\" #>  .. - attr(*, \"support\")= num [1:2] -Inf Inf #>  .. - attr(*, \"names\")= chr [1:4] \"mean\" \"sd\" \"nu\" \"xi\" #>  .. - attr(*, \"default\")= num [1:4] 0 1 3 2 #>  .. - attr(*, \"continuous\")= logi TRUE #>  @ residuals            : NULL #>  @ params               :List of 11 #>  .. $ model                        :List of 4 #>  ..  ..$ class  : chr [1:3] \"gam\" \"glm\" \"lm\" #>  ..  ..$ call   : chr \"mgcv::gam(formula = price ~ s(carat) + s(depth_pct) + s(table) + \\n    s(x_length) + s(y_width) + s(z_depth) + \"| __truncated__ #>  ..  ..$ print  : chr \"\\nFamily: gaussian \\nLink function: identity \\n\\nFormula:\\nprice ~ s(carat) + s(depth_pct) + s(table) + s(x_len\"| __truncated__ #>  ..  ..$ summary: chr \"\\nFamily: gaussian \\nLink function: identity \\n\\nFormula:\\nprice ~ s(carat) + s(depth_pct) + s(table) + s(x_len\"| __truncated__ #>  .. $ y_col                        : chr \"price\" #>  .. $ rand_it                      : num 100 #>  .. $ parallel                     : Named int 22 #>  ..  ..- attr(*, \"names\")= chr \"system\" #>  .. $ model_packages               : chr \"mgcv\" #>  .. $ random_model_call_string     : NULL #>  .. $ random_model_call_string_vars: chr(0)  #>  .. $ positive                     : logi TRUE #>  .. $ seed                         : num 0 #>  .. $ rand_it_ok                   : int 100 #>  .. $ exactness                    : chr \"approx\"  # Calculate ALEs with p-values ale_gam_diamonds <- retrieve_rds(   # For speed, load a pre-created object by default.   c(serialized_objects_site, 'ale_gam_diamonds_stats_readme.0.5.2.rds'),   {     # To run the code yourself, execute this code block directly.     ALE(       gam_diamonds,       # generate ALE for all 1D variables and the carat:clarity 2D interaction,       x_cols = list(d1 = TRUE, d2 = 'carat:clarity'),       data = diamonds,       p_values = p_dist_gam_diamonds,       # Usually at least 100 bootstrap iterations, but just 10 here for a faster demo       boot_it = 10     )   } )  # Plot the ALE data. The horizontal bands in the plots use the p-values. plot(ale_gam_diamonds)     # For models that give errors with the default settings, # you can use 'random_model_call_string' to specify a model for the estimation # of p-values from random variables as in this example. # See details above for an explanation.  pd_diamonds_special <- retrieve_rds(   # For speed, load a pre-created object by default.   c(serialized_objects_site, 'pd_diamonds_special.0.5.2.rds'),   {     # To run the code yourself, execute this code block directly.     ALEpDist(       gam_diamonds,       diamonds,       random_model_call_string = 'mgcv::gam(         price ~ s(carat) + s(depth_pct) + s(table) + s(x_length) + s(y_width) + s(z_depth) +           cut + color + clarity + random_variable,         data = rand_data       )',       # Normally should be default 1000, but just 100 for quicker demo       rand_it = 100     )   } ) #> Warning: cannot open URL 'https://github.com/tripartio/ale/raw/main/download/pd_diamonds_special.0.5.2.rds': HTTP status was '404 Not Found' # saveRDS(pd_diamonds_special, file.choose())  # Examine the structure of the returned object print(pd_diamonds_special) #> <ale::ALEpDist> #>  @ rand_stats           :List of 1 #>  .. $ price: tibble [100 × 6] (S3: tbl_df/tbl/data.frame) #>  ..  ..$ aled     : num [1:100] 4.07 6.15 7.69 8.13 2.26 ... #>  ..  ..$ aler_min : num [1:100] -55.2 -227.8 -398.2 -637.2 -82.7 ... #>  ..  ..$ aler_max : num [1:100] 307.8 187.6 237.5 226.4 59.3 ... #>  ..  ..$ naled    : num [1:100] 0.0531 0.0745 0.089 0.0904 0.0321 ... #>  ..  ..$ naler_min: num [1:100] -0.576 -2.257 -3.865 -6.049 -0.808 ... #>  ..  ..$ naler_max: num [1:100] 2.733 1.696 2.151 2.041 0.581 ... #>  @ residual_distribution: 'univariateML' Named num [1:4] 22.86 1372.41 2.67 1.34 #>  .. - attr(*, \"logLik\")= num -329520 #>  .. - attr(*, \"call\")= language f(x = x, na.rm = na.rm) #>  .. - attr(*, \"n\")= int 39739 #>  .. - attr(*, \"model\")= chr \"Skew Student-t\" #>  .. - attr(*, \"density\")= chr \"fGarch::dsstd\" #>  .. - attr(*, \"support\")= num [1:2] -Inf Inf #>  .. - attr(*, \"names\")= chr [1:4] \"mean\" \"sd\" \"nu\" \"xi\" #>  .. - attr(*, \"default\")= num [1:4] 0 1 3 2 #>  .. - attr(*, \"continuous\")= logi TRUE #>  @ residuals            : NULL #>  @ params               :List of 12 #>  .. $ model                        :List of 2 #>  ..  ..$ class: chr [1:3] \"gam\" \"glm\" \"lm\" #>  ..  ..$ hash : chr \"e92e511307cb9457ffafbe991e2738f3\" #>  .. $ y_col                        : chr \"price\" #>  .. $ rand_it                      : num 100 #>  .. $ parallel                     : num 0 #>  .. $ model_packages               : NULL #>  .. $ random_model_call_string     : chr \"mgcv::gam(\\n        price ~ s(carat) + s(depth_pct) + s(table) + s(x_length) + s(y_width) + s(z_depth) +\\n     \"| __truncated__ #>  .. $ random_model_call_string_vars: chr(0)  #>  .. $ positive                     : logi TRUE #>  .. $ aled_fun                     : chr \"mad\" #>  .. $ seed                         : num 0 #>  .. $ rand_it_ok                   : int 100 #>  .. $ exactness                    : chr \"approx\"   # }"},{"path":"https://tripartio.github.io/ale/reference/ModelBoot.html","id":null,"dir":"Reference","previous_headings":"","what":"Statistics and ALE data for a bootstrapped model — ModelBoot","title":"Statistics and ALE data for a bootstrapped model — ModelBoot","text":"ModelBoot S7 object contains full-model bootstrapped statistics ALE data trained model. Full-model bootstrapping (distinct data-bootstrapping) retrains model bootstrap iteration. Thus, can rather slow, though much reliable. However, obtaining bootstrapped ALE data, plots, statistics, full-model bootstrapping provided ModelBoot necessary models developed cross-validation. cross-validated models, sufficient (much faster) create regular [ALE()] object bootstrapping setting boot_it argument constructor. fact, full-model bootstrapping ModelBoot often infeasible slow machine-learning models trained large datasets, rather cross-validated assure reliability. However, models cross-validated, full-model bootstrapping ModelBoot necessary reliable results. details follow ; see also vignette('ale-statistics').","code":""},{"path":"https://tripartio.github.io/ale/reference/ModelBoot.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Statistics and ALE data for a bootstrapped model — ModelBoot","text":"","code":"ModelBoot(   model,   data = NULL,   ...,   model_call_string = NULL,   model_call_string_vars = character(),   parallel = 0,   model_packages = NULL,   y_col = NULL,   positive = TRUE,   pred_fun = NULL,   pred_type = \"response\",   boot_it = 100,   boot_alpha = 0.05,   boot_centre = \"mean\",   seed = 0,   output_model_stats = TRUE,   output_model_coefs = TRUE,   output_ale = TRUE,   output_boot_data = FALSE,   ale_options = list(),   ale_p = \"auto\",   tidy_options = list(),   glance_options = list(),   silent = FALSE )"},{"path":"https://tripartio.github.io/ale/reference/ModelBoot.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Statistics and ALE data for a bootstrapped model — ModelBoot","text":"model Required. See documentation ALE() data dataframe. Dataset bootstrapped. must data model trained. provided, ModelBoot() try detect automatically. model objects contain data within , data provided. ... used. Inserted require explicit naming subsequent arguments. model_call_string character(1). NULL (default), ModelBoot tries automatically detect construct call bootstrapped datasets. , function fail early. case, character string full call model must provided includes boot_data data argument call. See examples. model_call_string_vars character. Names variables included model_call_string columns data. variables exist, must specified else parallel processing may produce error. parallelization disabled parallel = 0, concern. See documentation model_packages argument ALE(). parallel, model_packages See documentation ALE() y_col, pred_fun, pred_type See documentation ALE(). Used calculate bootstrapped performance measures. left default values, relevant performance measures calculated arguments can automatically detected. Otherwise, specified. positive single atomic value. model represented model model_call_string binary classification model, positive specifies 'positive' value y_col (target outcome), , value interest considered TRUE; value y_col considered FALSE. argument ignored model binary classification model. example, 2 means TRUE 1 means FALSE, set positive = 2. boot_it non-negative integer(1). Number bootstrap iterations full-model bootstrapping. bootstrapping ALE values, see details verify ALE() bootstrapping appropriate ModelBoot(). boot_it = 0, model run normal full data bootstrapping. boot_alpha numeric(1) 0 1. Alpha percentile-based confidence interval range bootstrap intervals; bootstrap confidence intervals lowest highest (1 - 0.05) / 2 percentiles. example, boot_alpha = 0.05 (default), intervals 2.5 97.5 percentiles. boot_centre character(1) c('mean', 'median'). bootstrapping, main estimate ALE y value considered boot_centre. Regardless value specified , mean median available. seed integer. Random seed. Supply runs assure identical bootstrap samples generated time data. See documentation ALE() details. output_model_stats logical(1). TRUE (default), return overall model statistics using broom::glance() (available model) bootstrap-validated statistics boot_it > 0. output_model_coefs logical(1). TRUE (default), return model coefficients using broom::tidy() (available model). output_ale logical(1). TRUE (default), return ALE data statistics. output_boot_data logical(1). TRUE, return full raw data bootstrap iteration, specifically, bootstrapped models model row indices. Default FALSE return large, detailed data. ale_options, tidy_options, glance_options list named arguments. Arguments pass ALE() constructor ale = TRUE, broom::tidy() model_coefs = TRUE, broom::glance() model_stats = TRUE, respectively, beyond (overriding) defaults. Note: obtain p-values ALE statistics, see ale_p argument. ale_p p_values argument ALE() constructor; see documentation . argument overrides p_values element ale_options argument. silent See documentation ALE()","code":""},{"path":"https://tripartio.github.io/ale/reference/ModelBoot.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Statistics and ALE data for a bootstrapped model — ModelBoot","text":"object class ALE properties model_stats, model_coefs, ale, model_stats, boot_data, params.","code":""},{"path":"https://tripartio.github.io/ale/reference/ModelBoot.html","id":"properties","dir":"Reference","previous_headings":"","what":"Properties","title":"Statistics and ALE data for a bootstrapped model — ModelBoot","text":"model_stats tibble bootstrapped results broom::glance(). NULL model_stats argument FALSE. general, broom::glance() results make sense bootstrapped included, df adj.r.squared. Results incomparable across bootstrapped datasets (aic) excluded. addition, certain model performance measures included; bootstrap-validated .632 correction (Efron & Tibshirani 1986) (.632+ correction): regression (numeric prediction) models: mae: mean absolute error (MAE) sa_mae: standardized accuracy MAE referenced mean absolute deviation rmse: root mean squared error (RMSE) sa_rmse: standardized accuracy RMSE referenced standard deviation binary categorical classification (probability) models: auc: area ROC curve model_coefs tibble bootstrapped results broom::tidy(). NULL model_coefs argument FALSE. ale list bootstrapped ALE results using default ALE() settings unless overridden ale_options. NULL ale argument FALSE. Elements :   boot_data tibble bootstrap results. row represents bootstrap iteration. NULL boot_data argument FALSE. columns :   params Parameters used calculate bootstrapped data. repeat arguments passed ModelBoot(). either values provided user used default user change following additional objects created internally also provided:","code":"* `single`: an `ALE` object of ALE calculations on the full dataset without bootstrapping.   * `boot`: a list of bootstrapped ALE data and statistics. This element is not an `ALE` object; it uses a special internal format. * `it`: the specific bootstrap iteration from 0 to `boot_it` iterations. Iteration 0 is the results from the full dataset (not bootstrapped).   * `row_idxs`: the row indexes for the bootstrapped sample for that iteration. To save space, the row indexes are returned rather than the full datasets. So, for example, iteration i's bootstrap sample can be reproduced by `data[ModelBoot_obj@boot_data$row_idxs[[2]], ]` where `data` is the dataset and `ModelBoot_obj` is the result of `ModelBoot()`.   * `model`: the model object trained on that iteration.   * `ale`: the results of `ALE()` on that iteration.   * `tidy`: the results of `broom::tidy(model)` on that iteration.   * `stats`: the results of `broom::glance(model)` on that iteration.   * `perf`: performance measures on the entire dataset. These are the measures specified above for regression and classification models. * `y_cats`: same as `ALE@params$y_cats` (see documentation there). * `y_type`: same as `ALE@params$y_type` (see documentation there). * `model`: same as `ALE@params$model` (see documentation there). * `data`: same as `ALE@params$data` (see documentation there)."},{"path":"https://tripartio.github.io/ale/reference/ModelBoot.html","id":"full-model-bootstrapping","dir":"Reference","previous_headings":"","what":"Full-model bootstrapping","title":"Statistics and ALE data for a bootstrapped model — ModelBoot","text":"modelling results, without ALE, considered reliable without appropriate validation. ALE, trained model ALE explains trained model must validated. ALE must validated bootstrapping. trained model might validated either cross-validation bootstrapping. ALE explains trained models developed cross-validation, sufficient bootstrap just training data. ALE object boot_it argument. However, unvalidated models must validated bootstrapping along calculation ALE; ModelBoot object boot_it argument. ModelBoot() carries full-model bootstrapping validate models. Specifically, : Creates multiple bootstrap samples (default 100; user can specify number); Creates model bootstrap sample; Calculates overall model statistics, variable coefficients, ALE values model bootstrap sample; Calculates mean, median, lower upper confidence intervals values across bootstrap samples.","code":""},{"path":"https://tripartio.github.io/ale/reference/ModelBoot.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Statistics and ALE data for a bootstrapped model — ModelBoot","text":"Okoli, Chitu. 2023. “Statistical Inference Using Machine Learning Classical Techniques Based Accumulated Local Effects (ALE).” arXiv. doi:10.48550/arXiv.2310.09877.< Efron, Bradley, Robert Tibshirani. \"Bootstrap methods standard errors, confidence intervals, measures statistical accuracy.\" Statistical science (1986): 54-75. doi:10.1214/ss/1177013815","code":""},{"path":"https://tripartio.github.io/ale/reference/ModelBoot.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Statistics and ALE data for a bootstrapped model — ModelBoot","text":"","code":"# attitude dataset attitude #>    rating complaints privileges learning raises critical advance #> 1      43         51         30       39     61       92      45 #> 2      63         64         51       54     63       73      47 #> 3      71         70         68       69     76       86      48 #> 4      61         63         45       47     54       84      35 #> 5      81         78         56       66     71       83      47 #> 6      43         55         49       44     54       49      34 #> 7      58         67         42       56     66       68      35 #> 8      71         75         50       55     70       66      41 #> 9      72         82         72       67     71       83      31 #> 10     67         61         45       47     62       80      41 #> 11     64         53         53       58     58       67      34 #> 12     67         60         47       39     59       74      41 #> 13     69         62         57       42     55       63      25 #> 14     68         83         83       45     59       77      35 #> 15     77         77         54       72     79       77      46 #> 16     81         90         50       72     60       54      36 #> 17     74         85         64       69     79       79      63 #> 18     65         60         65       75     55       80      60 #> 19     65         70         46       57     75       85      46 #> 20     50         58         68       54     64       78      52 #> 21     50         40         33       34     43       64      33 #> 22     64         61         52       62     66       80      41 #> 23     53         66         52       50     63       80      37 #> 24     40         37         42       58     50       57      49 #> 25     63         54         42       48     66       75      33 #> 26     66         77         66       63     88       76      72 #> 27     78         75         58       74     80       78      49 #> 28     48         57         44       45     51       83      38 #> 29     85         85         71       71     77       74      55 #> 30     82         82         39       59     64       78      39  ## ALE for generalized additive models (GAM) ## GAM is tweaked to work on the small dataset. gam_attitude <- mgcv::gam(rating ~ complaints + privileges + s(learning) +                             raises + s(critical) + advance,                           data = attitude) summary(gam_attitude) #>  #> Family: gaussian  #> Link function: identity  #>  #> Formula: #> rating ~ complaints + privileges + s(learning) + raises + s(critical) +  #>     advance #>  #> Parametric coefficients: #>             Estimate Std. Error t value Pr(>|t|)     #> (Intercept) 36.97245   11.60967   3.185 0.004501 **  #> complaints   0.60933    0.13297   4.582 0.000165 *** #> privileges  -0.12662    0.11432  -1.108 0.280715     #> raises       0.06222    0.18900   0.329 0.745314     #> advance     -0.23790    0.14807  -1.607 0.123198     #> --- #> Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 #>  #> Approximate significance of smooth terms: #>               edf Ref.df     F p-value   #> s(learning) 1.923  2.369 3.761  0.0312 * #> s(critical) 2.296  2.862 3.272  0.0565 . #> --- #> Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 #>  #> R-sq.(adj) =  0.776   Deviance explained = 83.9% #> GCV = 47.947  Scale est. = 33.213    n = 30  # \\donttest{ # Full model bootstrapping   # For speed, these examples use retrieve_rds() to load pre-created objects # from an online repository. # To run the code yourself, execute the code blocks directly. serialized_objects_site <- \"https://github.com/tripartio/ale/raw/main/download\"  # Create ALE data mb_gam_attitude <- retrieve_rds(   # For speed, load a pre-created object by default.   c(serialized_objects_site, 'mb_gam_attitude.0.5.2.rds'),   {     # To run the code yourself, execute this code block directly.     # For models like lm that store their data,     # there is no need to specify the data argument.     # 100 bootstrap iterations by default.     ModelBoot(gam_attitude)   } )  # # If default settings cause errors, supply model_call_string with 'data = boot_data' # # in the string instead of the actual dataset name (in addition to the actual dataset # # as the 'data' argument directly to the `ModelBoot` constructor). # mb_gam_attitude <- ModelBoot( #   gam_attitude, #   data = attitude,  # the actual dataset #   model_call_string = 'mgcv::gam( #     rating ~ complaints + privileges + s(learning) + #       raises + s(critical) + advance, #     data = boot_data  # required for model_call_string #   )' # )  # Model statistics and coefficients mb_gam_attitude@model_stats #> # A tibble: 9 × 7 #>   name          boot_valid conf.low median   mean conf.high      sd #>   <chr>              <dbl>    <dbl>  <dbl>  <dbl>     <dbl>   <dbl> #> 1 df                NA        8.36  17.0   15.8      21.0    4.08   #> 2 df.residual       NA        9.00  13.0   14.2      21.6    4.08   #> 3 nobs              NA       30     30     30        30      0      #> 4 adj.r.squared     NA        0.746  1.000  0.945     1      0.0832 #> 5 npar              NA       23     23     23        23      0      #> 6 mae               12.9      4.50  NA     NA        62.6   15.0    #> 7 sa_mae             0.307   -2.00  NA     NA         0.769  0.772  #> 8 rmse              16.3      5.51  NA     NA        79.4   19.5    #> 9 sa_rmse            0.332   -2.08  NA     NA         0.786  0.754  mb_gam_attitude@model_coefs #> # A tibble: 2 × 6 #>   term        conf.low median  mean conf.high std.error #>   <chr>          <dbl>  <dbl> <dbl>     <dbl>     <dbl> #> 1 s(learning)     1.00   7.94  6.10      9.00      3.12 #> 2 s(critical)     1.74   4.34  4.69      8.96      2.24  # Plot ALE plot(mb_gam_attitude)   # Retrieve ALE data get(mb_gam_attitude, type = 'boot')    # bootstrapped #> $complaints #> # A tibble: 10 × 7 #>    complaints.ceil    .n    .y .y_lo .y_mean .y_median .y_hi #>              <dbl> <int> <dbl> <dbl>   <dbl>     <dbl> <dbl> #>  1              37     1  49.4  29.9    49.4      47.9  90.8 #>  2              53     3  60.9  48.7    60.9      58.6  80.8 #>  3              57     3  60.5  54.6    60.5      59.7  70.4 #>  4              60     3  62.8  59.3    62.8      62.4  69.5 #>  5              63     4  64.7  61.8    64.7      64.6  68.1 #>  6              67     3  66.5  62.5    66.5      66.3  71.5 #>  7              75     4  70.0  51.2    70.0      71.2  79.0 #>  8              78     3  73.8  58.4    73.8      73.4  82.7 #>  9              83     3  74.0  51.6    74.0      74.8  89.7 #> 10              90     3  79.9  49.6    79.9      80.9  99.6 #>  #> $privileges #> # A tibble: 10 × 7 #>    privileges.ceil    .n    .y .y_lo .y_mean .y_median .y_hi #>              <dbl> <int> <dbl> <dbl>   <dbl>     <dbl> <dbl> #>  1              30     1  67.1  49.9    67.1      68.0  80.1 #>  2              42     5  66.3  58.6    66.3      66.8  72.6 #>  3              44     1  65.5  59.8    65.5      66.1  68.7 #>  4              46     3  66.2  61.6    66.2      66.2  70.0 #>  5              50     4  65.5  62.8    65.5      65.6  67.1 #>  6              52     3  65.6  64.4    65.6      65.5  68.0 #>  7              57     4  65.3  59.5    65.3      65.0  70.6 #>  8              65     3  65.1  54.6    65.1      63.7  78.7 #>  9              68     3  63.5  55.2    63.5      63.5  74.9 #> 10              83     3  59.9  46.3    59.9      59.4  76.3 #>  #> $learning #> # A tibble: 10 × 7 #>    learning.ceil    .n    .y .y_lo .y_mean .y_median .y_hi #>            <dbl> <int> <dbl> <dbl>   <dbl>     <dbl> <dbl> #>  1            34     1  61.9  27.4    61.9      62.0 105.  #>  2            42     3  63.5  48.2    63.5      63.6  94.7 #>  3            45     3  64.6  49.8    64.6      62.8  86.3 #>  4            48     3  64.1  40.7    64.1      63.7  86.8 #>  5            55     4  61.9  44.3    61.9      61.9  84.1 #>  6            58     4  62.8  25.5    62.8      65.3  79.5 #>  7            63     3  65.5  43.2    65.5      67.2  77.5 #>  8            69     4  72.7  57.5    72.7      71.6  95.2 #>  9            72     3  72.2  56.3    72.2      72.2  92.5 #> 10            75     2  74.7  58.2    74.7      75.0  95.9 #>  #> $raises #> # A tibble: 10 × 7 #>    raises.ceil    .n    .y .y_lo .y_mean .y_median .y_hi #>          <dbl> <int> <dbl> <dbl>   <dbl>     <dbl> <dbl> #>  1          43     1  61.1  3.74    61.1      64.5  88.1 #>  2          54     4  64.9 49.2     64.9      65.8  82.8 #>  3          55     2  63.8 44.0     63.8      65.1  72.3 #>  4          59     3  64.7 57.8     64.7      65.2  67.5 #>  5          63     5  65.7 62.8     65.7      65.5  69.6 #>  6          64     2  65.8 63.8     65.8      65.6  69.3 #>  7          70     4  65.9 55.5     65.9      65.6  78.3 #>  8          75     3  69.8 60.1     69.8      67.1  97.4 #>  9          79     4  66.1 31.1     66.1      65.4  94.1 #> 10          88     2  69.5 44.1     69.5      66.1 116.  #>  #> $critical #> # A tibble: 10 × 7 #>    critical.ceil    .n    .y .y_lo .y_mean .y_median .y_hi #>            <dbl> <int> <dbl> <dbl>   <dbl>     <dbl> <dbl> #>  1            49     1  54.1 34.0     54.1      54.5  68.7 #>  2            63     3  74.2 53.8     74.2      72.9  96.2 #>  3            67     3  68.9 54.2     68.9      67.5  88.2 #>  4            74     4  70.7 57.2     70.7      70.6  81.0 #>  5            77     4  66.8 51.9     66.8      67.3  81.6 #>  6            78     3  66.6 54.1     66.6      66.8  79.0 #>  7            80     5  64.9 51.6     64.9      65.5  79.4 #>  8            83     3  63.2 46.5     63.2      64.6  74.7 #>  9            84     1  59.9 45.6     59.9      62.6  67.5 #> 10            92     3  56.1  8.94    56.1      56.1  99.2 #>  #> $advance #> # A tibble: 9 × 7 #>   advance.ceil    .n    .y .y_lo .y_mean .y_median .y_hi #>          <dbl> <int> <dbl> <dbl>   <dbl>     <dbl> <dbl> #> 1           25     1  67.7  50.0    67.7      69.4  79.9 #> 2           33     3  67.5  60.4    67.5      67.0  79.4 #> 3           35     5  67.1  62.0    67.1      66.5  74.5 #> 4           36     1  67.2  62.8    67.2      66.5  75.7 #> 5           41     7  65.7  64.8    65.7      65.6  68.4 #> 6           47     5  65.2  57.7    65.2      64.7  75.9 #> 7           49     3  65.2  58.3    65.2      64.3  74.6 #> 8           55     2  62.9  47.6    62.9      63.7  74.0 #> 9           72     3  56.6  23.6    56.6      57.7  81.2 #>  get(mb_gam_attitude, type = 'single')  # full (unbootstrapped) model #> $complaints #> # A tibble: 10 × 7 #>    complaints.ceil    .n    .y .y_lo .y_mean .y_median .y_hi #>              <dbl> <int> <dbl> <dbl>   <dbl>     <dbl> <dbl> #>  1              37     1  47.9  47.9    47.9      47.9  47.9 #>  2              53     3  57.7  57.7    57.7      57.7  57.7 #>  3              57     3  60.1  60.1    60.1      60.1  60.1 #>  4              60     3  61.9  61.9    61.9      61.9  61.9 #>  5              63     4  63.8  63.8    63.8      63.8  63.8 #>  6              67     3  66.2  66.2    66.2      66.2  66.2 #>  7              75     4  71.1  71.1    71.1      71.1  71.1 #>  8              78     3  72.9  72.9    72.9      72.9  72.9 #>  9              83     3  75.9  75.9    75.9      75.9  75.9 #> 10              90     3  80.2  80.2    80.2      80.2  80.2 #>  #> $privileges #> # A tibble: 10 × 7 #>    privileges.ceil    .n    .y .y_lo .y_mean .y_median .y_hi #>              <dbl> <int> <dbl> <dbl>   <dbl>     <dbl> <dbl> #>  1              30     1  68.3  68.3    68.3      68.3  68.3 #>  2              42     5  66.8  66.8    66.8      66.8  66.8 #>  3              44     1  66.5  66.5    66.5      66.5  66.5 #>  4              46     3  66.3  66.3    66.3      66.3  66.3 #>  5              50     4  65.8  65.8    65.8      65.8  65.8 #>  6              52     3  65.5  65.5    65.5      65.5  65.5 #>  7              57     4  64.9  64.9    64.9      64.9  64.9 #>  8              65     3  63.9  63.9    63.9      63.9  63.9 #>  9              68     3  63.5  63.5    63.5      63.5  63.5 #> 10              83     3  61.6  61.6    61.6      61.6  61.6 #>  #> $learning #> # A tibble: 10 × 7 #>    learning.ceil    .n    .y .y_lo .y_mean .y_median .y_hi #>            <dbl> <int> <dbl> <dbl>   <dbl>     <dbl> <dbl> #>  1            34     1  61.9  61.9    61.9      61.9  61.9 #>  2            42     3  61.8  61.8    61.8      61.8  61.8 #>  3            45     3  61.8  61.8    61.8      61.8  61.8 #>  4            48     3  62.1  62.1    62.1      62.1  62.1 #>  5            55     4  63.6  63.6    63.6      63.6  63.6 #>  6            58     4  64.9  64.9    64.9      64.9  64.9 #>  7            63     3  67.4  67.4    67.4      67.4  67.4 #>  8            69     4  70.9  70.9    70.9      70.9  70.9 #>  9            72     3  72.7  72.7    72.7      72.7  72.7 #> 10            75     2  74.5  74.5    74.5      74.5  74.5 #>  #> $raises #> # A tibble: 10 × 7 #>    raises.ceil    .n    .y .y_lo .y_mean .y_median .y_hi #>          <dbl> <int> <dbl> <dbl>   <dbl>     <dbl> <dbl> #>  1          43     1  64.2  64.2    64.2      64.2  64.2 #>  2          54     4  64.9  64.9    64.9      64.9  64.9 #>  3          55     2  65.0  65.0    65.0      65.0  65.0 #>  4          59     3  65.2  65.2    65.2      65.2  65.2 #>  5          63     5  65.4  65.4    65.4      65.4  65.4 #>  6          64     2  65.5  65.5    65.5      65.5  65.5 #>  7          70     4  65.9  65.9    65.9      65.9  65.9 #>  8          75     3  66.2  66.2    66.2      66.2  66.2 #>  9          79     4  66.4  66.4    66.4      66.4  66.4 #> 10          88     2  67.0  67.0    67.0      67.0  67.0 #>  #> $critical #> # A tibble: 10 × 7 #>    critical.ceil    .n    .y .y_lo .y_mean .y_median .y_hi #>            <dbl> <int> <dbl> <dbl>   <dbl>     <dbl> <dbl> #>  1            49     1  55.7  55.7    55.7      55.7  55.7 #>  2            63     3  66.3  66.3    66.3      66.3  66.3 #>  3            67     3  67.8  67.8    67.8      67.8  67.8 #>  4            74     4  68.1  68.1    68.1      68.1  68.1 #>  5            77     4  67.2  67.2    67.2      67.2  67.2 #>  6            78     3  66.9  66.9    66.9      66.9  66.9 #>  7            80     5  66.0  66.0    66.0      66.0  66.0 #>  8            83     3  64.5  64.5    64.5      64.5  64.5 #>  9            84     1  64.0  64.0    64.0      64.0  64.0 #> 10            92     3  58.9  58.9    58.9      58.9  58.9 #>  #> $advance #> # A tibble: 9 × 7 #>   advance.ceil    .n    .y .y_lo .y_mean .y_median .y_hi #>          <dbl> <int> <dbl> <dbl>   <dbl>     <dbl> <dbl> #> 1           25     1  69.5  69.5    69.5      69.5  69.5 #> 2           33     3  67.6  67.6    67.6      67.6  67.6 #> 3           35     5  67.1  67.1    67.1      67.1  67.1 #> 4           36     1  66.8  66.8    66.8      66.8  66.8 #> 5           41     7  65.7  65.7    65.7      65.7  65.7 #> 6           47     5  64.2  64.2    64.2      64.2  64.2 #> 7           49     3  63.8  63.8    63.8      63.8  63.8 #> 8           55     2  62.3  62.3    62.3      62.3  62.3 #> 9           72     3  58.3  58.3    58.3      58.3  58.3 #>  # See get.ALE() for other options  # }"},{"path":"https://tripartio.github.io/ale/reference/ale-package.html","id":null,"dir":"Reference","previous_headings":"","what":"Interpretable Machine Learning and Statistical Inference with Accumulated Local Effects (ALE) — ale-package","title":"Interpretable Machine Learning and Statistical Inference with Accumulated Local Effects (ALE) — ale-package","text":"Accumulated Local Effects (ALE) initially developed model-agnostic approach global explanations results black-box machine learning algorithms. ALE key advantage approaches like partial dependency plots (PDP) SHapley Additive exPlanations (SHAP): values represent clean functional decomposition model. , ALE values affected presence absence interactions among variables mode. Moreover, computation relatively rapid. package reimplements algorithms calculating ALE data develops highly interpretable visualizations plotting ALE values. also extends original ALE concept add bootstrap-based confidence intervals ALE-based statistics can used statistical inference. details, see Okoli, Chitu. 2023. “Statistical Inference Using Machine Learning Classical Techniques Based Accumulated Local Effects (ALE).” arXiv. doi:10.48550/arXiv.2310.09877.","code":""},{"path":"https://tripartio.github.io/ale/reference/ale-package.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Interpretable Machine Learning and Statistical Inference with Accumulated Local Effects (ALE) — ale-package","text":"Okoli, Chitu. 2023. “Statistical Inference Using Machine Learning Classical Techniques Based Accumulated Local Effects (ALE).” arXiv. doi:10.48550/arXiv.2310.09877.","code":""},{"path":[]},{"path":"https://tripartio.github.io/ale/reference/ale-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Interpretable Machine Learning and Statistical Inference with Accumulated Local Effects (ALE) — ale-package","text":"Chitu Okoli Chitu.Okoli@skema.edu","code":""},{"path":"https://tripartio.github.io/ale/reference/census.html","id":null,"dir":"Reference","previous_headings":"","what":"Census Income — census","title":"Census Income — census","text":"Census data indicates, among details, respondent's income exceeds $50,000 per year. Also known \"Adult\" dataset.","code":""},{"path":"https://tripartio.github.io/ale/reference/census.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Census Income — census","text":"","code":"census"},{"path":"https://tripartio.github.io/ale/reference/census.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Census Income — census","text":"tibble 32,561 rows 15 columns: higher_income TRUE income > $50,000 age continuous workclass Private, Self-emp--inc, Self-emp-inc, Federal-gov, Local-gov, State-gov, Without-pay, Never-worked fnlwgt continuous. \"proxy demographic background people: 'People similar demographic characteristics similar weights'\" details, see https://www.openml.org/search?type=data&id=1590. education Bachelors, -college, 11th, HS-grad, Prof-school, Assoc-acdm, Assoc-voc, 9th, 7th-8th, 12th, Masters, 1st-4th, 10th, Doctorate, 5th-6th, Preschool education_num continuous marital_status Married-civ-spouse, Divorced, Never-married, Separated, Widowed, Married-spouse-absent, Married-AF-spouse occupation Tech-support, Craft-repair, -service, Sales, Exec-managerial, Prof-specialty, Handlers-cleaners, Machine-op-inspct, Adm-clerical, Farming-fishing, Transport-moving, Priv-house-serv, Protective-serv, Armed-Forces relationship Wife, -child, Husband, --family, -relative, Unmarried race White, Asian-Pac-Islander, Amer-Indian-Eskimo, , Black sex Female, Male capital_gain continuous capital_loss continuous hours_per_week continuous native_country United-States, Cambodia, England, Puerto-Rico, Canada, Germany, Outlying-US(Guam-USVI-etc), India, Japan, Greece, South, China, Cuba, Iran, Honduras, Philippines, Italy, Poland, Jamaica, Vietnam, Mexico, Portugal, Ireland, France, Dominican-Republic, Laos, Ecuador, Taiwan, Haiti, Columbia, Hungary, Guatemala, Nicaragua, Scotland, Thailand, Yugoslavia, El-Salvador, Trinidad&Tobago, Peru, Hong, Holland-Netherlands dataset licensed Creative Commons Attribution 4.0 International (CC 4.0) license.","code":""},{"path":"https://tripartio.github.io/ale/reference/census.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Census Income — census","text":"Becker,Barry Kohavi,Ronny. (1996). Adult. UCI Machine Learning Repository. https://doi.org/10.24432/C5XW20.","code":""},{"path":"https://tripartio.github.io/ale/reference/customize.html","id":null,"dir":"Reference","previous_headings":"","what":"Customize plots contained in an ALEPlots object — customize","title":"Customize plots contained in an ALEPlots object — customize","text":"Customize ALEPlots object modifying plots indicated combination x_cols, type, cats specified. arguments indicate common customizations zooming ; see argument documentation available simple options. flexible option specify list ggplot layers layers argument; appends provided layers plot applying ggplot2::+.gg() method . Thus, customization supported appending ggplot layers can applied. layers simple options like zoom_y specified, layers layers applied first option applied order presented argument list. full control order customizations, provide layers. See get.ALE() explanation parameters described .","code":""},{"path":"https://tripartio.github.io/ale/reference/customize.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Customize plots contained in an ALEPlots object — customize","text":"","code":"customize(   plots_obj,   x_cols = NULL,   ...,   exclude_cols = NULL,   type = \"ale\",   cats = NULL,   layers = NULL,   zoom_x = NULL,   zoom_y = NULL )"},{"path":"https://tripartio.github.io/ale/reference/customize.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Customize plots contained in an ALEPlots object — customize","text":"plots_obj ALEPlots object customize. x_cols, exclude_cols See documentation get.ALE() ... used. Inserted require explicit naming subsequent arguments. type See documentation get.ALE() cats See documentation get.ALE() layers List ggplot layers. appended plot indicated combination x_cols, type, cats applying ggplot2 + operator . zoom_x, zoom_y numeric(2). Zoom specified plots match specified x y limits, respectively. Must two-element numeric vector first element <= second. Default NULL zoom.","code":""},{"path":"https://tripartio.github.io/ale/reference/customize.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Customize plots contained in an ALEPlots object — customize","text":"ALEPlots object elements specified x_cols exclude_cols modified accordingly. Non-specified elements modified.","code":""},{"path":"https://tripartio.github.io/ale/reference/get.ALE.html","id":null,"dir":"Reference","previous_headings":"","what":"get method for ALE objects — get.ALE","title":"get method for ALE objects — get.ALE","text":"Retrieve specific elements ALE object.","code":""},{"path":"https://tripartio.github.io/ale/reference/get.ALE.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"get method for ALE objects — get.ALE","text":"obj ALE object retrieve elements. x_cols, exclude_cols character, list, formula. Columns names interaction terms obj requested one special x_cols formats. default value NULL x_cols retrieves available data output requested . See details documentation resolve_x_cols(). character(1). kind output requested. Must either \"ale\" (default) \"boot_data\". retrieve ALE statistics, see stats argument. ... used. Inserted require explicit naming subsequent arguments. stats character(1). Retrieve ALE statistics. stats specified, must left default (\"ale\"). Otherwise, get() errors stats specified value. See return value details valid values stats. cats character. Optional category names retrieve ALE categorical y outcome model. ale_centre documentation ALEPlots() simplify logical(1). TRUE (default), results simplified simplest list structure possible give requested results. FALSE, complex consistent list structure returned; might preferred programmatic non-interactive use. silent See documentation resolve_x_cols()","code":""},{"path":"https://tripartio.github.io/ale/reference/get.ALE.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"get method for ALE objects — get.ALE","text":"Regardless requested data, get.ALE() common structure: one category y outcome returned, top level list named category. , however, y outcome categorical one category multiple possibilities specified using cats argument, top level never categories, regardless value simplify. next level (top level zero one category) list one two levels: d1: 1D ALE elements. d2: 2D ALE elements. However, elements one dimension (either 1D 2D) requested simplify = TRUE (default), empty list eliminated level skipped provide elements present. example, 1D ALE data requested, d1 sublist list ALE data described next level. simplify = FALSE, d1 d2 sublists always returned; empty sublist NULL. results follow general structure just described, specific type data returned depends values stats arguments: = 'ale' (default) stats = NULL (default) list whose elements, named requested x variable, tibble. rows represent one ALE bin. tibble following columns: * var.bin var.ceil var name variable (column): non-numeric x, var.bin value ALE categories. numeric x, var.ceil value upper bound (ceiling) ALE bin. first \"bin\" numeric variables represents minimum value. 2D ALE var1 var2 interaction, var1.bin var2.bin columns returned (var1.ceil var2.ceilfor numeric var1 var2). * .n: number rows data bin represented var.bin var.ceil. numeric x, first bin contains data elements exactly minimum value x. often 1, might 1 one data element exactly minimum value. * .y: ALE function value calculated bin. bootstrapped ALE, .y_mean default .y_median boot_centre = 'median'. Regardless, .y_mean .y_median returned columns . * .y_lo, .y_hi: lower upper confidence intervals, respectively, bootstrapped .y value based boot_alpha argument ALE() constructor. = 'boot_data' stats = NULL (default) list whose elements, named requested x variable, tibble. data .y_mean, .y_median, .y_lo, .y_hi summarized = 'ale'. rows represent one ALE bin specified bootstrap iteration. tibble following columns: * .: bootstrap iteration. Iteration 0 represents ALE calculations full dataset; remaining values .1 boot_it (number bootstrap iterations specified ALE() constructor. * var var name variable (column): non-numeric x, var value ALE categories. numeric x, var value upper bound (ceiling) ALE bin. otherwise similar meanings described = 'ale' . * .n .y: = 'ale'. = 'ale' (default) stats = 'estimate' list elements d1 d2 value ALE statistic. row represents one variable interaction. tibble following columns: * term: variables columns 1D 2D ALE statistic. * aled, aler_min, aler_max, naled, naler_min, naler_max: respective ALE statistic variable interaction. = 'ale' (default) stats one values c('aled', 'aler_min', 'aler_max', 'naled', 'naler_min', 'naler_max') list elements d1 d2 distribution value single requested ALE statistic. element d1 d2 tibble. row represents one statistic one variable interaction. tibble following columns: * term: stats = 'estimate'. * statistic: requested ALE statistic(s). * estimate, mean, median: average bootstrapped value requested statistic. estimate equal either mean median depending boot_centre argument ALE() constructor. ALE bootstrapped, estimate, mean, median equal. * conf.low, conf.high: lower upper confidence intervals, respectively, bootstrapped statistic based boot_alpha argument ALE() constructor. ALE bootstrapped, estimate, conf.low, conf.high equal. = 'ale' (default) stats = '' list elements d1 d2 distribution values available ALE statistics requested variables interactions. Whereas stats = 'aled' (example) format returns data single statistic, stats = '' returns statistics requested variables. Thus, data structure columns identical single statistics , except available ALE statistics returned. = 'ale' (default) stats = 'conf_regions' list elements d1 d2 confidence regions requested variables interactions. element list requested d1 d2 sub-elements described general structure . data element tibble confidence regions single variable interaction. explanation columns, see vignette('ale-statistics'). = 'ale' (default) stats = 'conf_sig' Identical structure stats = 'conf_regions' except elements filtered terms (variables interactions) statistically significant confidence regions exceeding threshold inner ALER band, specifically, least obj@params$aler_alpha[2] rows data. See vignette(\"ale-statistics\") details.","code":""},{"path":"https://tripartio.github.io/ale/reference/get.ALE.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"get method for ALE objects — get.ALE","text":"","code":"# See examples at ALE() for a demonstration of how to use the get() method."},{"path":"https://tripartio.github.io/ale/reference/get.ALEPlots.html","id":null,"dir":"Reference","previous_headings":"","what":"get method for ALEPlots objects — get.ALEPlots","title":"get method for ALEPlots objects — get.ALEPlots","text":"Retrieve specific plots ALEPlots object. Unlike subset.ALEPlots() returns ALEPlots object subsetted x_cols variables interactions, get.ALEPlots() method returns list ggplot2::ggplot objects specified return value description. retain special ALEPlots behaviour like plotting, printing, summarizing multiple plots, use subset.ALEPlots() instead. See get.ALE() explanation parameters described .","code":""},{"path":"https://tripartio.github.io/ale/reference/get.ALEPlots.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"get method for ALEPlots objects — get.ALEPlots","text":"obj ALEPlots object retrieve ALE elements. type character(1). type ALEPlots retrieve: 'ale' standard ALE plots 'effect' ALE effects plots. See cats argument options categorical plots. cats character. categories (one ) categorical outcome variable retrieve. retrieve categories individual category plots, leave cats default NULL. categorical plots combine categories, specify cats = \".\". (forget \".\" \".\", avoids naming conflicts legitimate categories might named \"\".) -category plots, type must set \"overlay\" \"facet\" specific desired type categorical plot.","code":""},{"path":"https://tripartio.github.io/ale/reference/get.ALEPlots.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"get method for ALEPlots objects — get.ALEPlots","text":"list ggplot objects described documentation return value get.ALE(). different subset.ALEPlots(), returns ALEPlots object subsetted x_cols variables interactions.","code":""},{"path":"https://tripartio.github.io/ale/reference/get.ModelBoot.html","id":null,"dir":"Reference","previous_headings":"","what":"get method for ModelBoot objects — get.ModelBoot","title":"get method for ModelBoot objects — get.ModelBoot","text":"Retrieve specific ALE elements ModelBoot object. method similar get.ALE() except user may specify type ALE data retrieve (see argument definition details). See get.ALE() explanation parameters described .","code":""},{"path":"https://tripartio.github.io/ale/reference/get.ModelBoot.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"get method for ModelBoot objects — get.ModelBoot","text":"obj ModelBoot object retrieve ALE elements. type character(1). type ModelBoot ALE elements retrieve: 'single' ALE calculated full data set 'boot' bootstrapped ALE data (based full-model bootstrapping). default 'auto' retrieve 'boot' available 'single' otherwise.","code":""},{"path":"https://tripartio.github.io/ale/reference/get.ModelBoot.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"get method for ModelBoot objects — get.ModelBoot","text":"See get.ALE()","code":""},{"path":"https://tripartio.github.io/ale/reference/get.html","id":null,"dir":"Reference","previous_headings":"","what":"S7 generic get method for objects in the ale package — get","title":"S7 generic get method for objects in the ale package — get","text":"Retrieve specific data elements object based X column names. obj object ale package, generic passes arguments base::get() function.","code":""},{"path":"https://tripartio.github.io/ale/reference/get.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"S7 generic get method for objects in the ale package — get","text":"","code":"get(obj, ...)"},{"path":"https://tripartio.github.io/ale/reference/get.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"S7 generic get method for objects in the ale package — get","text":"obj object. ... ale package objects, instructions predictor (x) columns retrieved. everything else, arguments pass base::get().","code":""},{"path":"https://tripartio.github.io/ale/reference/invert_probs.html","id":null,"dir":"Reference","previous_headings":"","what":"Invert ALE Probabilities — invert_probs","title":"Invert ALE Probabilities — invert_probs","text":"Inverts predicted probabilities ALE object reflect complementary outcomes (.e., 1 - p). particularly useful model probability predictions opposite desired easy interpretability. invert_probs(), need change original data retrain model; ALE data, p-values, subsequent ALE plots reflect desired inverted probabilities.","code":""},{"path":"https://tripartio.github.io/ale/reference/invert_probs.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Invert ALE Probabilities — invert_probs","text":"","code":"invert_probs(ale_obj, rename_y_col = NULL, force = FALSE)"},{"path":"https://tripartio.github.io/ale/reference/invert_probs.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Invert ALE Probabilities — invert_probs","text":"ale_obj object class ALE. rename_y_col character(1). provided, renames y outcome column. probabilities inverted, name outcome column often needs change intuitive interpretability. default NULL change outcome column name. force logical(1). TRUE, inverts probabilities even already inverted (reverting ). default FALSE error probabilities already inverted.","code":""},{"path":"https://tripartio.github.io/ale/reference/invert_probs.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Invert ALE Probabilities — invert_probs","text":"updated ALE object probabilities relevant statistics inverted.","code":""},{"path":"https://tripartio.github.io/ale/reference/invert_probs.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Invert ALE Probabilities — invert_probs","text":"function inverts ALE y-values (.e., .y, .y_mean, .y_median, etc.) terms, including main ALE effects, bootstrap data, ALE statistics (aler_min, aler_max, etc.). also updates y_col name y_summary column names rename_y_col provided. ALE object already inverted (probs_inverted = TRUE), function throws error default. force reinversion (.e., revert original probabilities), set force = TRUE. operation permitted y-summary probabilities [0, 1] interval.","code":""},{"path":"https://tripartio.github.io/ale/reference/invert_probs.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Invert ALE Probabilities — invert_probs","text":"","code":"# \\donttest{ # Binary model setosa <- iris |>   dplyr::mutate(setosa = Species == \"setosa\") |>   dplyr::select(-Species)  ale_obj <- glm(setosa ~ ., data = setosa, family = binomial()) |>   ALE() #> Warning: glm.fit: algorithm did not converge #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred  # Invert the predicted probabilities ale_inverted <- invert_probs(ale_obj)  # Revert back to original by inverting again ale_reverted <- invert_probs(ale_inverted, force = TRUE) #> ! Probabilities are already inverted; they will now be reverted.  # }"},{"path":"https://tripartio.github.io/ale/reference/plot.ALEPlots.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot method for ALEPlots object — plot.ALEPlots","title":"Plot method for ALEPlots object — plot.ALEPlots","text":"Plot ALEPlots object.","code":""},{"path":"https://tripartio.github.io/ale/reference/plot.ALEPlots.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot method for ALEPlots object — plot.ALEPlots","text":"x object class ALEPlots. max_print integer(1). maximum number plots may printed time. 1D plots 2D printed separate pages, maximum applies separately dimension ALE plots, dimensions combined. ... Arguments pass patchwork::wrap_plots()","code":""},{"path":"https://tripartio.github.io/ale/reference/plot.ALEPlots.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot method for ALEPlots object — plot.ALEPlots","text":"Invisibly returns x.","code":""},{"path":"https://tripartio.github.io/ale/reference/plot.ModelBoot.html","id":null,"dir":"Reference","previous_headings":"","what":"plot method for ModelBoot objects — plot.ModelBoot","title":"plot method for ModelBoot objects — plot.ModelBoot","text":"plot method simply calls constructor ALEPlots object.","code":""},{"path":"https://tripartio.github.io/ale/reference/plot.ModelBoot.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"plot method for ModelBoot objects — plot.ModelBoot","text":"x ModelBoot object. ... Arguments passed ALEPlots()","code":""},{"path":"https://tripartio.github.io/ale/reference/plot.ale.html","id":null,"dir":"Reference","previous_headings":"","what":"plot method for ALE objects — plot.ALE","title":"plot method for ALE objects — plot.ALE","text":"plot method simply calls constructor ALEPlots object.","code":""},{"path":"https://tripartio.github.io/ale/reference/plot.ale.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"plot method for ALE objects — plot.ALE","text":"x ALE object. ... Arguments passed ALEPlots()","code":""},{"path":"https://tripartio.github.io/ale/reference/print.ALEPlots.html","id":null,"dir":"Reference","previous_headings":"","what":"Print method for ALEPlots object — print.ALEPlots","title":"Print method for ALEPlots object — print.ALEPlots","text":"Print ALEPlots object calling plot().","code":""},{"path":"https://tripartio.github.io/ale/reference/print.ALEPlots.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print method for ALEPlots object — print.ALEPlots","text":"x object class ALEPlots. max_print See documentation plot.ALEPlots() ... Additional arguments (currently used).","code":""},{"path":"https://tripartio.github.io/ale/reference/print.ALEPlots.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Print method for ALEPlots object — print.ALEPlots","text":"Invisibly returns x.","code":""},{"path":"https://tripartio.github.io/ale/reference/print.ModelBoot.html","id":null,"dir":"Reference","previous_headings":"","what":"print method for ModelBoot object — print.ModelBoot","title":"print method for ModelBoot object — print.ModelBoot","text":"Print ModelBoot object.","code":""},{"path":"https://tripartio.github.io/ale/reference/print.ModelBoot.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"print method for ModelBoot object — print.ModelBoot","text":"x object class ModelBoot. details logical(1). TRUE (default), brief details printed. FALSE, minimal information printed. ... Additional arguments (currently used).","code":""},{"path":"https://tripartio.github.io/ale/reference/print.ModelBoot.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"print method for ModelBoot object — print.ModelBoot","text":"Invisibly returns x.","code":""},{"path":"https://tripartio.github.io/ale/reference/print.ModelBoot.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"print method for ModelBoot object — print.ModelBoot","text":"","code":"# \\donttest{ lm_cars <- stats::lm(mpg ~ wt + gear, mtcars) mb <- ModelBoot(lm_cars, boot_it = 2, ale_p = NULL) print(mb) #> <ModelBoot> object of a <lm> model that predicts `mpg` (a numeric outcome) from #> a 32-row by 3-column dataset. #> * The model was retrained with 2 bootstrap iterations. #>  #> The following overall model summary statistics are available: #> * Overall average statistics: r.squared, adj.r.squared, sigma, statistic, #> p.value, df, df.residual, and nobs #> * Bootstrap-validated model accuracy: mae, sa_mae, rmse, and sa_rmse #> Statistics for the following specific variables or interactions are available: #> (Intercept), wt, and gear #>  #> Accumulated local effects (ALE) data and statistics are provided for the #> following terms: #> 2 1D terms: wt and gear #> no 2D terms: # }"},{"path":"https://tripartio.github.io/ale/reference/print.ale.html","id":null,"dir":"Reference","previous_headings":"","what":"print Method for ALE object — print.ALE","title":"print Method for ALE object — print.ALE","text":"Print ALE object.","code":""},{"path":"https://tripartio.github.io/ale/reference/print.ale.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"print Method for ALE object — print.ALE","text":"x object class ALE. details logical(1). TRUE (default), brief details printed. FALSE, minimal information printed. ... Additional arguments (currently used).","code":""},{"path":"https://tripartio.github.io/ale/reference/print.ale.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"print Method for ALE object — print.ALE","text":"Invisibly returns x.","code":""},{"path":"https://tripartio.github.io/ale/reference/print.ale.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"print Method for ALE object — print.ALE","text":"","code":"# \\donttest{ lm_cars <- stats::lm(mpg ~ ., mtcars) ale_cars <- ALE(lm_cars, p_values = NULL) print(ale_cars) #> <ALE> object of a <lm> model that predicts `mpg` (a numeric outcome) from a #> 32-row by 11-column dataset. #> ALE data and statistics are provided for the following terms: #> 10 1D terms: cyl, disp, hp, drat, wt, qsec, vs, am, gear, and carb #> no 2D terms: #> The results were not bootstrapped. # }"},{"path":"https://tripartio.github.io/ale/reference/resolve_x_cols.html","id":null,"dir":"Reference","previous_headings":"","what":"Resolve x_cols and exclude_cols to their standardized format — resolve_x_cols","title":"Resolve x_cols and exclude_cols to their standardized format — resolve_x_cols","text":"Resolve x_cols exclude_cols standardized format x_cols specify 1D 2D ALE elements required. specification used throughout ALE package. x_cols specifies desired columns interactions whereas exclude_cols optionally specifies columns interactions remove x_cols. result x_cols – exclude_cols, giving considerable flexibility specifying precise columns desired.","code":""},{"path":"https://tripartio.github.io/ale/reference/resolve_x_cols.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Resolve x_cols and exclude_cols to their standardized format — resolve_x_cols","text":"","code":"resolve_x_cols(x_cols, col_names, y_col, exclude_cols = NULL, silent = FALSE)"},{"path":"https://tripartio.github.io/ale/reference/resolve_x_cols.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Resolve x_cols and exclude_cols to their standardized format — resolve_x_cols","text":"x_cols character, list, formula. Columns interactions requested one special x_cols formats. x_cols variable names found col_names error. See examples. col_names character. column names dataset. values x_cols must contained among values col_names. interaction terms x_cols, e.g., \":b\", individual variable names must contained col_names, e.g, c(\"\", \"b\"). y_col character(1). y outcome column. found x_cols value, silently removed. exclude_cols possible formats x_cols. Columns interactions exclude requested x_cols. exclude_cols values found col_names ignored message (can silenced silent). silent logical(1). TRUE, message given; particular, x_cols found col_names silently ignored. Default FALSE. Regardless, warnings errors never silenced (e.g, invalid x_cols formats still report errors).","code":""},{"path":"https://tripartio.github.io/ale/reference/resolve_x_cols.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Resolve x_cols and exclude_cols to their standardized format — resolve_x_cols","text":"x_cols canonical format, always list two elements, d1 d2. element character vector requested column 1D ALE (d1) 2D ALE interaction pair (d2). either dimension empty, value empty character, character(). See examples details.","code":""},{"path":"https://tripartio.github.io/ale/reference/resolve_x_cols.html","id":"x-cols-format-options","dir":"Reference","previous_headings":"","what":"x_cols format options","title":"Resolve x_cols and exclude_cols to their standardized format — resolve_x_cols","text":"x_cols argument determines predictor variables interactions included analysis. supports multiple input formats: Character vector: Users can explicitly specify 1D terms 2D ALE interactions, e.g., c(\"\", \"b\", \":b\", \":c\"). Formula (~): Allows specifying variables interactions formula notation (e.g., ~ + b + :b), automatically converted structured format. outcome term optional ignored regardless. , ~ + b + :b produces results identical whatever ~ + b + :b. List format: basic list format list character vectors named d1 1D ALE terms, d2 2D interactions, . example, list(d1 = c(\"\", \"b\"), d2 = c(\":b\", \":c\")) Boolean selection entire dimension: list(d1 = TRUE) selects available variables 1D ALE, excluding y_col. list(d2 = TRUE) selects possible 2D interactions among columns col_names, excluding y_col. character vector 1D terms named d2_all may used include 2D interactions include specified 1D terms. example, specifying list(d2_all = \"\") select c(\":b\", \":c\", \":d\"), etc. addition terms requested d1 d2 elements. NULL (unspecified): x_cols = NULL, variables selected. function ensures variables valid col_names, providing informative messages unless silent = TRUE. regardless specification format, result always standardized format specified return value. Note y_col removed included x_cols. However, message alerts included, case mistake. Run examples details.","code":""},{"path":"https://tripartio.github.io/ale/reference/resolve_x_cols.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Resolve x_cols and exclude_cols to their standardized format — resolve_x_cols","text":"","code":"## Sample data set.seed(0) df <- data.frame(   y = runif(10),   a = sample(letters[1:3], 10, replace = TRUE),   b = rnorm(10),   c = sample(1:5, 10, replace = TRUE) ) col_names <- names(df) y_col <- \"y\"  # Assume 'y' is the outcome variable   ## Examples with just x_cols to show different formats for specifying x_cols ## (same format for exclude_cols)  # Character vector: Simple ALE with no interactions resolve_x_cols(c(\"a\", \"b\"), col_names, y_col) #> $d1 #> [1] \"a\" \"b\" #>  #> $d2 #> character(0) #>   # Character string: Select just one 1D element resolve_x_cols(\"c\", col_names, y_col) #> $d1 #> [1] \"c\" #>  #> $d2 #> character(0) #>   # list of 1- and 2-length character vectors: specify precise 1D and 2D elements desired resolve_x_cols(c('a:b', \"c\", 'c:a', \"b\"), col_names, y_col) #> $d1 #> [1] \"c\" \"b\" #>  #> $d2 #> [1] \"a:b\" \"c:a\" #>   # Formula: Converts to a list of individual elements resolve_x_cols(~ a + b, col_names, y_col) #> $d1 #> [1] \"a\" \"b\" #>  #> $d2 #> character(0) #>   # Formula with interactions (1D and 2D). # This format is probably more convenient if you know precisely which terms you want. # Note that the outcome on the left-hand-side is always silently ignored. resolve_x_cols(whatever ~ a + b + a:b + c:b, col_names, y_col) #> $d1 #> [1] \"a\" \"b\" #>  #> $d2 #> [1] \"a:b\" \"b:c\" #>   # List specifying d1 (1D ALE) resolve_x_cols(list(d1 = c(\"a\", \"b\")), col_names, y_col) #> $d1 #> [1] \"a\" \"b\" #>  #> $d2 #> character(0) #>   # List specifying d2 (2D ALE) resolve_x_cols(list(d2 = 'a:b'), col_names, y_col) #> $d1 #> character(0) #>  #> $d2 #> [1] \"a:b\" #>   # List specifying both d1 and d2 resolve_x_cols(list(d1 = c(\"a\", \"b\"), d2 = 'a:b'), col_names, y_col) #> $d1 #> [1] \"a\" \"b\" #>  #> $d2 #> [1] \"a:b\" #>   # d1 as TRUE (select all columns except y_col) resolve_x_cols(list(d1 = TRUE), col_names, y_col) #> $d1 #> [1] \"a\" \"b\" \"c\" #>  #> $d2 #> character(0) #>   # d2 as TRUE (select all possible 2D interactions) resolve_x_cols(list(d2 = TRUE), col_names, y_col) #> $d1 #> character(0) #>  #> $d2 #> [1] \"a:b\" \"a:c\" \"b:c\" #>   # d2_all: Request all 2D interactions involving a specific variable resolve_x_cols(list(d2_all = \"a\"), col_names, y_col) #> $d1 #> character(0) #>  #> $d2 #> [1] \"a:b\" \"a:c\" #>   # NULL: No variables selected resolve_x_cols(NULL, col_names, y_col) #> $d1 #> character(0) #>  #> $d2 #> character(0) #>     ## Examples of how exclude_cols are removed from x_cols to obtain various desired results  # Exclude one column from a simple character vector resolve_x_cols(   x_cols = c(\"a\", \"b\", \"c\"),   col_names = col_names,   y_col = y_col,   exclude_cols = \"b\" ) #> $d1 #> [1] \"a\" \"c\" #>  #> $d2 #> character(0) #>   # Exclude multiple columns resolve_x_cols(   x_cols = c(\"a\", \"b\", \"c\"),   col_names = col_names,   y_col = y_col,   exclude_cols = c(\"a\", \"c\") ) #> $d1 #> [1] \"b\" #>  #> $d2 #> character(0) #>   # Exclude an interaction term from a formula input resolve_x_cols(   x_cols = ~ a + b + a:b,   col_names = col_names,   y_col = y_col,   exclude_cols = ~ a:b ) #> $d1 #> [1] \"a\" \"b\" #>  #> $d2 #> character(0) #>   # Exclude all columns from x_cols resolve_x_cols(   x_cols = c(\"a\", \"b\", \"c\"),   col_names = col_names,   y_col = y_col,   exclude_cols = c(\"a\", \"b\", \"c\") ) #> $d1 #> character(0) #>  #> $d2 #> character(0) #>   # Exclude non-existent columns (should be ignored) resolve_x_cols(   x_cols = c(\"a\", \"b\"),   col_names = col_names,   y_col = y_col,   exclude_cols = \"z\" ) #> ℹ The following columns in exclude_cols were not found in `col_names`: z #> $d1 #> [1] \"a\" \"b\" #>  #> $d2 #> character(0) #>   # Exclude one column from a list-based input resolve_x_cols(   x_cols = list(d1 = c(\"a\", \"b\"), d2 = c(\"a:b\", \"a:c\")),   col_names = col_names,   y_col = y_col,   exclude_cols = list(d1 = \"a\") ) #> $d1 #> [1] \"b\" #>  #> $d2 #> [1] \"a:b\" \"a:c\" #>   # Exclude interactions only resolve_x_cols(   x_cols = list(d1 = c(\"a\", \"b\", \"c\"), d2 = c(\"a:b\", \"a:c\")),   col_names = col_names,   y_col = y_col,   exclude_cols = list(d2 = 'a:b') ) #> $d1 #> [1] \"a\" \"b\" \"c\" #>  #> $d2 #> [1] \"a:c\" #>   # Exclude everything, including interactions resolve_x_cols(   x_cols = list(d1 = c(\"a\", \"b\", \"c\"), d2 = c(\"a:b\", \"a:c\")),   col_names = col_names,   y_col = y_col,   exclude_cols = list(d1 = c(\"a\", \"b\", \"c\"), d2 = c(\"a:b\", \"a:c\")) ) #> $d1 #> character(0) #>  #> $d2 #> character(0) #>   # Exclude a column implicitly removed by y_col resolve_x_cols(   x_cols = c(\"y\", \"a\", \"b\"),   col_names = col_names,   y_col = \"y\",   exclude_cols = \"a\" ) #> ℹ `y_col` (y) was requested in x_cols. #> $d1 #> [1] \"y\" \"b\" #>  #> $d2 #> character(0) #>   # Exclude entire 2D dimension from x_cols with d2 = TRUE resolve_x_cols(   x_cols = list(d1 = TRUE, d2 = c(\"a:b\", \"a:c\")),   col_names = col_names,   y_col = y_col,   exclude_cols = list(d1 = c(\"a\"), d2 = TRUE) ) #> $d1 #> [1] \"b\" \"c\" #>  #> $d2 #> character(0) #>"},{"path":"https://tripartio.github.io/ale/reference/retrieve_rds.html","id":null,"dir":"Reference","previous_headings":"","what":"Retrieve an R object from the first successful source among multiple attempts — retrieve_rds","title":"Retrieve an R object from the first successful source among multiple attempts — retrieve_rds","text":"retrieve_rds() tries argument ...—order—one successfully yields value, returned immediately. supports two kinds attempts: Character input interpreted remote RDS URL (char_as_url = TRUE, default): character vectors collapsed '/', opened via URL connection, read readRDS(). Arbitrary R expressions/code blocks: captured unevaluated evaluated caller’s environment; resulting value returned. attempt fail, tries next listed attempt. every attempt fails, function aborts.","code":""},{"path":"https://tripartio.github.io/ale/reference/retrieve_rds.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Retrieve an R object from the first successful source among multiple attempts — retrieve_rds","text":"","code":"retrieve_rds(..., char_as_url = TRUE)"},{"path":"https://tripartio.github.io/ale/reference/retrieve_rds.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Retrieve an R object from the first successful source among multiple attempts — retrieve_rds","text":"... One attempts obtain value. attempt may : character vector representing components URL .rds file (e.g., c(\"https://host\", \"path\", \"file.rds\")) char_as_url = TRUE; R expression (including {} block) , evaluated, yields desired value. Attempts tried order. first one successfully produces value causes immediate return. char_as_url logical(1). TRUE (default), character attempts treated URL components: concatenated '/', opened via base::url(), read using base::readRDS(). FALSE, character inputs treated specially evaluated normal R expressions.","code":""},{"path":"https://tripartio.github.io/ale/reference/retrieve_rds.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Retrieve an R object from the first successful source among multiple attempts — retrieve_rds","text":"first successfully retrieved/produced R object among attempts .... none succeed, function aborts.","code":""},{"path":"https://tripartio.github.io/ale/reference/retrieve_rds.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Retrieve an R object from the first successful source among multiple attempts — retrieve_rds","text":"Lazy capture attempts: Arguments ... captured unevaluated using rlang::enexprs(), code blocks passed braces executed retrieve_rds() chooses evaluate . Evaluation environment: Expressions evaluated caller’s environment via rlang::eval_tidy() env = rlang::caller_env(), symbols resolve exactly code written call site. Character--URL behaviour (enabled default): character vector pasted '/' separators (leading/trailing slash normalization), passed base::url(), base::readRDS(). error step caught skipped next attempt can run. Short-circuiting: soon one attempt succeeds (either reading RDS HTTP(S) evaluating expression), value returned attempts processed.","code":""},{"path":"https://tripartio.github.io/ale/reference/retrieve_rds.html","id":"error-handling","dir":"Reference","previous_headings":"","what":"Error handling","title":"Retrieve an R object from the first successful source among multiple attempts — retrieve_rds","text":"URL/RDS failures wrapped tryCatch() stop procedure; function proceeds next attempt. attempts fail, function aborts.","code":""},{"path":[]},{"path":"https://tripartio.github.io/ale/reference/retrieve_rds.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Retrieve an R object from the first successful source among multiple attempts — retrieve_rds","text":"","code":"# Example 1: Try a remote RDS first; if it fails, run the code block. # - With char_as_url = TRUE (default), the character vector is collapsed with \"/\", #   opened as a URL, and read via readRDS(). # - If the URL works, the serialized object is returned immediately. # - If it fails, the code block within curly quotes is evaluated in the #   caller's environment and its value is returned (here it would assign and #   return `ale_gam_diamonds`). serialized_objects_site <- \"https://github.com/tripartio/ale/raw/main/download\" retrieve_rds(   c(serialized_objects_site, \"ale_gam_diamonds.0.5.2.rds\"),   {     ale_gam_diamonds <- \"Code for generating an ALE object\"   } ) #> <ALE> object of a <gam/glm/lm> model that predicts `price` (a numeric outcome) #> from a 39739-row by 10-column dataset. #> ALE data and statistics are provided for the following terms: #> 9 1D terms: carat, depth_pct, table, x_length, y_width, z_depth, cut, color, #> and clarity #> no 2D terms: #> The results were not bootstrapped.  # Example 2: First attempt fails as a URL, so the next expression (a literal) is returned. # - \"dodo\" is treated as a URL (char_as_url = TRUE), which fails silently. # - The next attempt (100L) is evaluated and returned. retrieve_rds(   \"dodo\",   100L ) #> [1] 100  # Example 3: Characters are NOT treated as URLs, so the first argument returns immediately. # - With char_as_url = FALSE, 'dodo' is evaluated as a regular expression (a character) #   and returned at once; later attempts are ignored. retrieve_rds(   'dodo',   100L,   char_as_url = FALSE ) #> [1] \"dodo\""},{"path":"https://tripartio.github.io/ale/reference/subset.ALEPlots.html","id":null,"dir":"Reference","previous_headings":"","what":"subset method for ALEPlots object — subset.ALEPlots","title":"subset method for ALEPlots object — subset.ALEPlots","text":"Subset ALEPlots object produce another ALEPlots object subsetted x_cols variables interactions, specified return value description. See get.ALE() explanation parameters described .","code":""},{"path":"https://tripartio.github.io/ale/reference/subset.ALEPlots.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"subset method for ALEPlots object — subset.ALEPlots","text":"x object class ALEPlots. x_cols, exclude_cols See documentation get.ALE() ... used. Inserted require explicit naming subsequent arguments. include_eff logical(1). x_cols exclude_cols specify precisely variables include exclude subset. However, multivariable plots like ALE effects plot ambiguous subsetted remove existing variables. include_eff = TRUE (default) includes ALE effects plot subset rather dropping , available. silent See documentation ALE()","code":""},{"path":"https://tripartio.github.io/ale/reference/subset.ALEPlots.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"subset method for ALEPlots object — subset.ALEPlots","text":"ALEPlots object reduced cover variables interactions specified x_cols exclude_cols. different get.ALEPlots(), returns list ggplot objects loses special ALEPlots behaviour like plotting, printing, summarizing multiple plots.","code":""},{"path":"https://tripartio.github.io/ale/reference/summary.ALE.html","id":null,"dir":"Reference","previous_headings":"","what":"summary Method for ALE object — summary.ALE","title":"summary Method for ALE object — summary.ALE","text":"Prints statistical summary ALE object. ALE statistics, message says . Summarized statistics mean median depending boot_centre argument used ALE() bootstrapping.","code":""},{"path":"https://tripartio.github.io/ale/reference/summary.ALE.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"summary Method for ALE object — summary.ALE","text":"object object class ALE. stats character. One values c(\"aled\", \"aler_min\", \"aler_max\", \"naled\", \"naler_min\", \"naler_max\"): statistics report detail (estimate, p-values, confidence intervals). others listed , average (mean median) estimates reported. statistics presented order specified. all_conf logical(1). default (FALSE), statistically significant confidence regions reported. TRUE, regions reported well. round_digits integer(1). Numbers tables rounded round_digits decimal places. max_rows natural number. Maximum number rows print component. ... Additional arguments (currently used).","code":""},{"path":"https://tripartio.github.io/ale/reference/summary.ALE.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"summary Method for ALE object — summary.ALE","text":"Invisibly returns object. printout side effect.","code":""},{"path":"https://tripartio.github.io/ale/reference/summary.ALE.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"summary Method for ALE object — summary.ALE","text":"","code":"# \\donttest{ lm_cars <- stats::lm(mpg ~ ., mtcars) ale_cars <- ALE(lm_cars, boot_it = 3) summary(ale_cars) #> <ALE> object of a <lm> model that predicts `mpg` (a numeric outcome) from a #> 32-row by 11-column dataset. #> The results were bootstrapped with 3 iterations. #>  #> Mean ALE statistics [get(object, stats = \"estimate\")]: #> # A tibble: 10 × 7 #>    term    aled aler_min aler_max  naled naler_min naler_max #>    <chr>  <dbl>    <dbl>    <dbl>  <dbl>     <dbl>     <dbl> #>  1 cyl   0.108   -0.237    0.209   0          0         0    #>  2 disp  1.32    -2.05     2.53   11.6      -17.6      18.6  #>  3 hp    1.04    -2.90     1.89    8.58     -22.5      14.7  #>  4 drat  0.373   -0.632    0.732   2.46      -8.82      5.88 #>  5 wt    2.80    -8.57     5.96   19.7      -44.1      32.4  #>  6 qsec  1.29    -2.70     1.90   10.1      -17.6      13.7  #>  7 vs    0.0199   0.0199   0.0199  0          0         0    #>  8 am    0.236   -0.0171   0.214   1.19       0         2.94 #>  9 gear  0.163   -0.430    0.881   1.19       0         8.82 #> 10 carb  0.185   -0.831    0.299   0.184     -5.88      0    #>  #> ALE statistic distributions (surrogate p-values, 100 iterations) [get(object, #> stats = c(\"aled\", \"naled\"))]: #> # A tibble: 20 × 8 #>    statistic term  estimate p.value conf.low    mean  median conf.high #>    <ord>     <chr>    <dbl>   <dbl>    <dbl>   <dbl>   <dbl>     <dbl> #>  1 aled      cyl     0.108     0.89   0.106   0.108   0.108     0.109  #>  2 aled      disp    1.32      0.01   1.26    1.32    1.33      1.36   #>  3 aled      hp      1.04      0.01   0.862   1.04    1.08      1.19   #>  4 aled      drat    0.373     0.4    0.342   0.373   0.354     0.419  #>  5 aled      wt      2.80      0      2.41    2.80    2.50      3.46   #>  6 aled      qsec    1.29      0.01   1.27    1.29    1.29      1.31   #>  7 aled      vs      0.0199    0.98   0.0199  0.0199  0.0199    0.0199 #>  8 aled      am      0.236     0.63   0.162   0.236   0.236     0.311  #>  9 aled      gear    0.163     0.77   0.145   0.163   0.145     0.198  #> 10 aled      carb    0.185     0.74   0.169   0.185   0.184     0.202  #> 11 naled     cyl     0         0.84   0       0       0         0      #> 12 naled     disp   11.6       0     10.8    11.6    11.8      12.2    #> 13 naled     hp      8.58      0.01   7.53    8.58    9.10      9.19   #> 14 naled     drat    2.46      0.39   1.67    2.46    1.93      3.69   #> 15 naled     wt     19.7       0     17.6    19.7    17.7      23.6    #> 16 naled     qsec   10.1       0     10.1    10.1    10.1      10.1    #> 17 naled     vs      0         0.84   0       0       0         0      #> 18 naled     am      1.19      0.71   0       1.19    0         3.41   #> 19 naled     gear    1.19      0.71   0.827   1.19    0.827     1.88   #> 20 naled     carb    0.184     0.84   0.0138  0.184   0.276     0.276  #>  #> Statistically significant confidence regions [get(object, stats = \"conf_sig\")]: #> ! Note that confidence regions are not reliable with fewer than 100 bootstrap #>   iterations or p-values based on fewer than 100 random iterations. #> ℹ There are 3 bootstrap iterations. #> ℹ p-values are based on 100 iterations. #> # A tibble: 10 × 12 #>    term  x     start_x  end_x x_span_pct     n   pct     y start_y end_y  trend #>    <chr> <chr>   <dbl>  <dbl>      <dbl> <int> <dbl> <dbl>   <dbl> <dbl>  <dbl> #>  1 disp  NA      71.1  350          69.6    25 78.1     NA    17.1  20.9  0.232 #>  2 disp  NA     400    472          18.0     7 21.9     NA    21.5  22.5  0.232 #>  3 hp    NA      52    180          45.2    25 78.1     NA    21.1  18.3 -0.264 #>  4 hp    NA     245    335          31.8     7 21.9     NA    16.9  15.0 -0.264 #>  5 wt    NA       1.51   2.46       24.3     8 25       NA    25.2  21.6 -0.631 #>  6 wt    NA       2.78   3.52       18.9    14 43.8     NA    20.5  17.7 -0.631 #>  7 wt    NA       3.73   5.42       43.3    10 31.2     NA    16.9  10.6 -0.631 #>  8 qsec  NA      14.5   14.5         0       1  3.12    NA    16.5  16.5  0     #>  9 qsec  NA      15.5   20          53.6    28 87.5     NA    17.3  21.0  0.299 #> 10 qsec  NA      22.9   22.9         0       3  9.38    NA    23.4  23.4  0     #> # ℹ 1 more variable: aler_band <ord> # }"},{"path":"https://tripartio.github.io/ale/reference/summary.ALEPlots.html","id":null,"dir":"Reference","previous_headings":"","what":"summary method for ALEPlots object — summary.ALEPlots","title":"summary method for ALEPlots object — summary.ALEPlots","text":"Present concise summary information ALEPlots object.","code":""},{"path":"https://tripartio.github.io/ale/reference/summary.ALEPlots.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"summary method for ALEPlots object — summary.ALEPlots","text":"object object class ALEPlots. ... used","code":""},{"path":"https://tripartio.github.io/ale/reference/summary.ALEPlots.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"summary method for ALEPlots object — summary.ALEPlots","text":"Summary string.","code":""},{"path":"https://tripartio.github.io/ale/reference/summary.ModelBoot.html","id":null,"dir":"Reference","previous_headings":"","what":"summary Method for ModelBoot object — summary.ModelBoot","title":"summary Method for ModelBoot object — summary.ModelBoot","text":"Prints statistical summary ModelBoot object. ALE statistics, message says . Summarized statistics mean median depending boot_centre argument used ALE() bootstrapping.","code":""},{"path":"https://tripartio.github.io/ale/reference/summary.ModelBoot.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"summary Method for ModelBoot object — summary.ModelBoot","text":"object object class ModelBoot. stats character. One values c(\"aled\", \"aler_min\", \"aler_max\", \"naled\", \"naler_min\", \"naler_max\"): statistics report detail (estimate, p-values, confidence intervals). others listed , average (mean median) estimates reported. statistics presented order specified. all_conf logical(1). default (FALSE), statistically significant confidence regions reported. TRUE, regions reported well. round_digits integer(1). Numbers tables rounded round_digits decimal places. max_rows natural number. Maximum number rows print component. ... Additional arguments (currently used).","code":""},{"path":"https://tripartio.github.io/ale/reference/summary.ModelBoot.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"summary Method for ModelBoot object — summary.ModelBoot","text":"Invisibly returns object. printout side effect.","code":""},{"path":"https://tripartio.github.io/ale/reference/summary.ModelBoot.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"summary Method for ModelBoot object — summary.ModelBoot","text":"","code":"# \\donttest{ lm_cars <- stats::lm(mpg ~ ., mtcars) ale_cars <- ModelBoot(lm_cars, boot_it = 3) summary(ale_cars) #> <ModelBoot> object of a <lm> model that predicts `mpg` (a numeric outcome) from #> a 32-row by 11-column dataset. #> * The model was retrained with 3 bootstrap iterations. #>  #> Overall model statistics (object@model_stats): #> # A tibble: 12 × 7 #>    name          boot_valid conf.low median   mean conf.high      sd #>    <chr>              <dbl>    <dbl>  <dbl>  <dbl>     <dbl>   <dbl> #>  1 r.squared         NA        0.906  0.931  0.930     0.953  0.0249 #>  2 adj.r.squared     NA        0.861  0.898  0.897     0.931  0.0367 #>  3 sigma             NA        1.68   1.70   1.75      1.85   0.0984 #>  4 statistic         NA       20.3   28.3   30.7      43.0   12.1    #>  5 p.value           NA        0      0      0         0      0      #>  6 df                NA       10     10     10        10      0      #>  7 df.residual       NA       21     21     21        21      0      #>  8 nobs              NA       32     32     32        32      0      #>  9 mae                3.27     3.13  NA     NA         4.76   0.981  #> 10 sa_mae             0.629    0.410 NA     NA         0.705  0.173  #> 11 rmse               4.27     3.48  NA     NA         7.10   1.96   #> 12 sa_rmse            0.625    0.326 NA     NA         0.738  0.222  #>  #> Summary model term estimates (object@model_coefs): #> # A tibble: 11 × 6 #>    term        conf.low   median     mean conf.high std.error #>    <chr>          <dbl>    <dbl>    <dbl>     <dbl>     <dbl> #>  1 (Intercept) -99.5    -44.3    -45.3       8.00     56.6    #>  2 cyl          -1.03     0.593    0.281     1.33      1.28   #>  3 disp          0.0099   0.0161   0.0165    0.0235    0.0072 #>  4 hp           -0.0345   0.0359   0.0205    0.0625    0.0528 #>  5 drat          1.92     4.30     4.03      5.91      2.11   #>  6 wt           -5.46    -4.34    -4.16     -2.71      1.45   #>  7 qsec          0.569    2.91     2.58      4.32      2.00   #>  8 vs           -7.40    -6.84    -4.00      1.81      5.44   #>  9 am           -2.68     0.298    0.402     3.57      3.29   #> 10 gear          0.580    4.54     4.59      8.66      4.25   #> 11 carb         -2.27    -2.00    -1.74     -1.000     0.705  #>  #> Mean ALE statistics [get(object, stats = \"estimate\")]: #> # A tibble: 10 × 7 #>    term   aled aler_min aler_max naled naler_min naler_max #>    <fct> <dbl>    <dbl>    <dbl> <dbl>     <dbl>     <dbl> #>  1 cyl   1.01    -1.94      2.18 15.5      -20.7      13.5 #>  2 disp  0.924   -1.37      2.13 11.9      -17.4      25.3 #>  3 hp    1.49    -4.12      3.77 16.2      -29.3      25.3 #>  4 drat  1.77    -2.74      6.00 16.4      -31.8      36.6 #>  5 wt    2.66    -9.18      7.10 19.7      -49.1      38.4 #>  6 qsec  4.96    -8.95     11.5  28.9      -33.3      31.2 #>  7 vs    2.69    -2.80      2.71 24.1      -33.5      14.5 #>  8 am    0.912   -0.987     1.31 17.1      -16.5      22.6 #>  9 gear  0.453   -2.54      6.65  1.05     -18.5      26.4 #> 10 carb  1.56    -8.69      2.26 15.2      -41.2      13.5 #>  #> ALE statistic distributions (surrogate p-values, 100 iterations) [get(object, #> stats = c(\"aled\", \"naled\"))]: #> # A tibble: 20 × 8 #>    statistic term  estimate p.value conf.low median   mean conf.high #>    <ord>     <fct>    <dbl>   <dbl>    <dbl>  <dbl>  <dbl>     <dbl> #>  1 aled      cyl      1.01     0.02   0.617   1.12   1.01       1.31 #>  2 aled      disp     0.924    0.04   0.128   0.985  0.924      1.67 #>  3 aled      hp       1.49     0.01   0.263   1.53   1.49       2.68 #>  4 aled      drat     1.77     0      0.820   1.79   1.77       2.71 #>  5 aled      wt       2.66     0      1.43    2.40   2.66       4.10 #>  6 aled      qsec     4.96     0      3.83    4.96   4.96       6.09 #>  7 aled      vs       2.69     0      1.17    3.30   2.69       3.68 #>  8 aled      am       0.912    0.04   0.167   1.22   0.912      1.40 #>  9 aled      gear     0.453    0.34   0.0551  0.275  0.453      1.00 #> 10 aled      carb     1.56     0.01   0.875   1.76   1.56       2.08 #> 11 naled     cyl     15.5      0      9.47   11.2   15.5       25.3  #> 12 naled     disp    11.9      0      0.817  16.3   11.9       19.1  #> 13 naled     hp      16.2      0      9.65   14.8   16.2       24.0  #> 14 naled     drat    16.4      0     10.2    11.9   16.4       26.5  #> 15 naled     wt      19.7      0     14.7    15.9   19.7       27.9  #> 16 naled     qsec    28.9      0     24.5    28.9   28.9       33.2  #> 17 naled     vs      24.1      0     13.9    27.1   24.1       31.7  #> 18 naled     am      17.1      0      3.44   24.2   17.1       24.8  #> 19 naled     gear     1.05     0.75   0.0439  0.879  1.05       2.19 #> 20 naled     carb    15.2      0      8.17   13.5   15.2       23.7  #>  #> Statistically significant confidence regions [get(object, stats = \"conf_sig\")]: #> ! Note that confidence regions are not reliable with fewer than 100 bootstrap #>   iterations or p-values based on fewer than 100 random iterations. #> ℹ There are 3 bootstrap iterations. #> ℹ p-values are based on 100 iterations. #> # A tibble: 15 × 12 #>    term  x     start_x  end_x x_span_pct     n   pct     y start_y end_y  trend #>    <chr> <chr>   <dbl>  <dbl>      <dbl> <int> <dbl> <dbl>   <dbl> <dbl>  <dbl> #>  1 disp  NA      71.1  400          82.0    29 90.6     NA   17.8  21.4   0.188 #>  2 disp  NA     472    472           0       3  9.38    NA   22.3  22.3   0     #>  3 hp    NA      52    245          68.2    30 93.8     NA   18.7  20.9   0.143 #>  4 hp    NA     335    335           0       2  6.25    NA   11.7  11.7   0     #>  5 drat  NA       2.76   4.22       67.3    30 93.8     NA   16.5  22.3   0.379 #>  6 drat  NA       4.93   4.93        0       2  6.25    NA   25.2  25.2   0     #>  7 wt    NA       1.51   2.46       24.3     8 25       NA   26.3  22.3  -0.707 #>  8 wt    NA       2.78   3.73       24.3    17 53.1     NA   21.0  17.1  -0.707 #>  9 wt    NA       4.07   5.42       34.6     7 21.9     NA   15.7  10.0  -0.707 #> 10 qsec  NA      14.5   14.5         0       1  3.12    NA   10.3  10.3   0     #> 11 qsec  NA      15.5   17.0        18.1    10 31.2     NA    9.43 15.0   1.33  #> 12 qsec  NA      17.4   18.6        14.0    11 34.4     NA   16.4  20.8   1.33  #> 13 qsec  NA      18.9   22.9        47.6    10 31.2     NA   21.9  36.5   1.33  #> 14 carb  NA       1      4          42.9    30 93.8     NA   21.5  16.2  -0.530 #> 15 carb  NA       8      8           0       2  6.25    NA    6.94  6.94  0     #> # ℹ 1 more variable: aler_band <ord> # }"},{"path":"https://tripartio.github.io/ale/reference/var_cars.html","id":null,"dir":"Reference","previous_headings":"","what":"Multi-variable transformation of the mtcars dataset. — var_cars","title":"Multi-variable transformation of the mtcars dataset. — var_cars","text":"transformation mtcars dataset R produce small dataset fundamental datatypes: logical, factor, ordered, integer, double, character. transformations obvious, noteworthy: row names (car model) saved character vector. unordered factors, country continent car manufacturer obtained based row names (model). ordered factor, gears 3, 4, 5 encoded 'three', 'four', 'five', respectively. text labels make explicit variable ordinal, yet number names make order crystal clear. adaptation original description mtcars dataset: data extracted 1974 Motor Trend US magazine, comprises fuel consumption 10 aspects automobile design performance 32 automobiles (1973–74 models).","code":""},{"path":"https://tripartio.github.io/ale/reference/var_cars.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Multi-variable transformation of the mtcars dataset. — var_cars","text":"","code":"var_cars"},{"path":"https://tripartio.github.io/ale/reference/var_cars.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Multi-variable transformation of the mtcars dataset. — var_cars","text":"tibble 32 observations 14 variables. model character: Car model mpg double: Miles/(US) gallon cyl integer: Number cylinders disp double: Displacement (cu..) hp double: Gross horsepower drat double: Rear axle ratio wt double: Weight (1000 lbs) qsec double: 1/4 mile time vs logical: Engine (0 = V-shaped, 1 = straight) logical: Transmission (0 = automatic, 1 = manual) gear ordered: Number forward gears carb integer: Number carburetors country factor: Country car manufacturer continent factor: Continent car manufacturer","code":""},{"path":"https://tripartio.github.io/ale/reference/var_cars.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Multi-variable transformation of the mtcars dataset. — var_cars","text":"Henderson Velleman (1981) comment footnote Table 1: 'Hocking (original transcriber)'s noncrucial coding Mazda's rotary engine straight six-cylinder engine Porsche's flat engine V engine, well inclusion diesel Mercedes 240D, retained enable direct comparisons made previous analyses.'","code":""},{"path":"https://tripartio.github.io/ale/reference/var_cars.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Multi-variable transformation of the mtcars dataset. — var_cars","text":"Henderson Velleman (1981), Building multiple regression models interactively. Biometrics, 37, 391–411.","code":""},{"path":"https://tripartio.github.io/ale/reference/x_medoids.html","id":null,"dir":"Reference","previous_headings":"","what":"k-medoids across a range, returning all internal cluster-quality measures — x_medoids","title":"k-medoids across a range, returning all internal cluster-quality measures — x_medoids","text":"k-medoids across range, returning internal cluster-quality measures","code":""},{"path":"https://tripartio.github.io/ale/reference/x_medoids.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"k-medoids across a range, returning all internal cluster-quality measures — x_medoids","text":"","code":"x_medoids(   data,   min_clusters = 2,   max_clusters = 10,   metric = \"euclidean\",   sort_by = c(\"silhouette\", \"dissimilarity\", \"isolation\", \"diameter\", \"separation\"),   ... )"},{"path":"https://tripartio.github.io/ale/reference/x_medoids.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"k-medoids across a range, returning all internal cluster-quality measures — x_medoids","text":"data data frame / tibble numeric features. min_clusters Smallest k try (≥ 2 – silhouette undefined k = 1). max_clusters Largest  k try. metric \"euclidean\", \"manhattan\", … accepted pam(). sort_by measure sort . Choices: \"silhouette\" (default), \"dissimilarity\", \"isolation\", \"diameter\", \"separation\". ... Extra arguments forwarded cluster::pam().","code":""},{"path":"https://tripartio.github.io/ale/reference/x_medoids.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"k-medoids across a range, returning all internal cluster-quality measures — x_medoids","text":"tibble one row per k, containing: • scalar measures (columns ) • model   – pam object • data    – original data + .cluster factor • clusinfo silhouette_widths full drill-","code":""},{"path":[]},{"path":"https://tripartio.github.io/ale/news/index.html","id":"new-features-development-version","dir":"Changelog","previous_headings":"","what":"New features","title":"ale (development version)","text":"summary() methods now implemented ALE ModelBoot objects. print summary ALE statistics console. ALE statistics available, print message saying . aled_fun argument ALE() ALEpDist() constructors, may optionally choose calculate ALE deviation based standard deviations instead default mean absolute deviation. widths 1D ALE plots non-numerical variables now proportional frequency data. find proportional widths intuitive text annotations indicated percentages, now removed. minimum width can controlled min_col_widths argument plot.ALE(). 1D plots categorical variables, maximum 10 distinct values (e.g., factor levels) now shown (default 10 adjustable consolid_cats argument plot.ALE()). top consolid_cats - 1 values ALE strength shown values consolidated “” category. default value \"levels\" fct_order argument ALE() constructor, unordered factors now sorted order factor levels (characters columns sorted alphabetical order unique values). alternative \"y_col\" sorts based increasing mean values predictions outcome variable factor level. \"ksd\" option allows compatibility original ALEPlot reference implementation. max_num_bins argument ALE() constructor now accepts special list format allows specification per-column maximum ALE bin sizes numeric input columns, default columns named. details, see documentation ALE(). Parallelization can now controlled global option ale.parallel. example, can set 4 CPU cores options(ale.parallel = 4). ranger package now automatically recognized y_col pred_fun don’t need specified. future, popular packages frameworks also automatically recognized, attempt cover packages.","code":""},{"path":"https://tripartio.github.io/ale/news/index.html","id":"changed-functionality-development-version","dir":"Changelog","previous_headings":"","what":"Changed functionality","title":"ale (development version)","text":"Parallelization disabled default (parallel = 0) (#16). pred_fun argument ALE() constructors now defaults NULL. However, functionality unchanged: default still creates generic custom prediction function.","code":""},{"path":"https://tripartio.github.io/ale/news/index.html","id":"bug-fixes-development-version","dir":"Changelog","previous_headings":"","what":"Bug fixes","title":"ale (development version)","text":"Update parallelization settings handle massive parallelization (#16) refactor code (#17).","code":""},{"path":"https://tripartio.github.io/ale/news/index.html","id":"documentation-development-version","dir":"Changelog","previous_headings":"","what":"Documentation","title":"ale (development version)","text":"Added two Quarto vignettes: “Analyzing Large Corn Yield Dataset ALE-Based Inference” “Analyzing Small Rice Yield Dataset ALE-Based Inference”. available vignettes link main CRAN page https://CRAN.R-project.org/package=ale.","code":""},{"path":"https://tripartio.github.io/ale/news/index.html","id":"ale-052","dir":"Changelog","previous_headings":"","what":"ale 0.5.2","title":"ale 0.5.2","text":"CRAN release: 2025-08-29","code":""},{"path":"https://tripartio.github.io/ale/news/index.html","id":"new-features-0-5-2","dir":"Changelog","previous_headings":"","what":"New features","title":"ale 0.5.2","text":"Customize ALEPlots appending ggplot layers customize() function. Function invert_probs() inverts probabilities (subtracts 1) ALE ALEpDist objects.","code":""},{"path":"https://tripartio.github.io/ale/news/index.html","id":"bug-fixes-0-5-2","dir":"Changelog","previous_headings":"","what":"Bug fixes","title":"ale 0.5.2","text":"ALEPlot package delisted CRAN, remove references . Accordingly, former vignette article comparing {ale} {ALEPlot} packages removed. Allow numeric binary predictions. Formerly, binary predictions errored, even numeric. Larger datasets now properly sample. datasets > 500 lines, code mismatch size original dataset sampled dataset.","code":""},{"path":"https://tripartio.github.io/ale/news/index.html","id":"documentation-0-5-2","dir":"Changelog","previous_headings":"","what":"Documentation","title":"ale 0.5.2","text":"Serialize slow-generating objects vignettes, examples, documentation can quickly run users. now downloaded directly GitHub. significantly speeds package checking building (though speedup invisible users).","code":""},{"path":"https://tripartio.github.io/ale/news/index.html","id":"ale-050","dir":"Changelog","previous_headings":"","what":"ale 0.5.0","title":"ale 0.5.0","text":"CRAN release: 2025-04-09 deeply rethought vision package completely rewritten entire package support existing, new, future planned functionality. changes radical continuity previous version 0.3.1. Thus, ’ve skipped version number now version 0.5.0. Honestly, can’t keep track changes; experienced users advised rerun vignettes get speed new version. apologize discontinuity trust latest version easier use much functional. follows list notable changes ’ve kept track .","code":""},{"path":"https://tripartio.github.io/ale/news/index.html","id":"breaking-changes-0-5-0","dir":"Changelog","previous_headings":"","what":"Breaking changes","title":"ale 0.5.0","text":"underlying algorithm calculating ALE completely rewritten scalable. addition rewriting code hood, structure ale package objects completely rewritten. latest objects compatible earlier versions. However, new structure supports roadmap future functionality, hope minimal changes future interrupt backward compatibility. ALE: core ale package object holds ALE data model (replaces former ale() ale_ixn() functions). ModelBoot: results full-model bootstrapping (replaces former model_bootstrap() function). ALEPlots: store ALE plots generated either ALE ModelBoot convenient print() plot() methods. ALEpDist: p-value distribution information (replaces former create_p_dist() function). extensive rewrite, longer depend {ALEPlot} package code now claim full authorship code. One significant implications decided change package license GPL 2 MIT, permits maximum dissemination algorithms. ale_ixn() eliminated now 1D 2D ALE calculated ALE() constructor. ALE object constructor longer produces plots directly. ALE plots now created ALEPlots objects using newly added plot() methods create possible plots ALE data ALE ModelBoot objects. Thus, serializing ALE objects now avoids previous problems environment bloat included ggplot objects. Renamed rug_sample_size argument ALE constructor sample_size. Now reflects size data sampled ale object, can used rug plots purposes.","code":""},{"path":"https://tripartio.github.io/ale/news/index.html","id":"new-features-0-5-0","dir":"Changelog","previous_headings":"","what":"New features","title":"ale 0.5.0","text":"x_cols argument ALE() now supports complex syntax specifying specific columns 1D ALE pairs columns 2D interactions desired. also supports specification using standard R formula syntax. New get() methods now provide convenient access ALE, ModelBoot, ALEPlots objects. Confidence regions 1D ALE now reported compactly. creation plot() methods, eliminated compact_plots ale(). print() plot() methods added ale_plots object. print() method added ALE object. Interactions now supported pairs categorical variables. (, numerical pairs pairs one numerical one categorical supported.) Bootstrapping now supported ALE interactions. 2D ALE plots completely rewritten. still implemented tiled heatmaps now faceted bootstrap quantile ALE bootstrapped. ALE statistics now supported interactions, including confidence regions. Categorical y outcomes now supported. categorical y outcomes, plots created one category time also categories combined. 1D ALE, separate plots available categories overlaid one plot categories faceted. 2D ALE, plots faceted category available. ‘boot_data’ now output option ale(). outputs ALE values bootstrap iteration. model_bootstrap() added various model performance measures validated using bootstrap validation .632 correction. structure p_funs completely changed; now converted object named ale_p functions separated object internal functions. function create_p_funs() renamed create_p_dist(). ALEpDist() now produces three types p-values: “exact” (slow) least 1000 random iterations original model; “approx” 100 999 iterations original model; “surrogate” much faster less reliable p-values based surrogate linear model. See ALEpDist() details. Character input data now accepted categorical datatype. handled unordered factors. Plots display categorical outcomes one plot yet implemented. now, class category must plotted time. Although standard {ALE} class supports 2D ALE interactions ALE bootstrapping, {ModelBoot} yet support full-model bootstrapping 2D ALE interactions.","code":""},{"path":"https://tripartio.github.io/ale/news/index.html","id":"bug-fixes-0-5-0","dir":"Changelog","previous_headings":"","what":"Bug fixes","title":"ale 0.5.0","text":"dealt innumerable bugs development journey , fortunately, publicly signalled bugs. fixes publicly reported bugs indicated . Gracefully fails instead crashing input data missing values.","code":""},{"path":"https://tripartio.github.io/ale/news/index.html","id":"under-the-hood-0-5-0","dir":"Changelog","previous_headings":"","what":"Under the hood","title":"ale 0.5.0","text":"One fundamental changes directly visible affects ALE values calculated. certain specific cases, ALE values now slightly different reference {ALEPlot} package. non-numerical variables prediction types predictions scaled response variable. (E.g., binary categorical variable logarithmic prediction scaled scale response variable.) made change two reasons: can understand implementation interpretation edge cases much better reference {ALEPlot} implementation. cases covered base ALE scientific article poorly documented {ALEPlot} code. help users interpret results understand . implementation lets us write code scales smoothly interactions arbitrary depth. contrast, {ALEPlot} reference implementation scalable: custom code must written type degree interaction. edge cases, implementation continues give identical results reference {ALEPlot} package. notable changes might readily visible users: Update required R version >= 4.2.0 uses |> pipe placeholder. Move performance metrics new dedicated package, staccuracy. Reduce dependencies rlang cli packages. Reduced imported functions minimum. Package messages, warnings, errors now use cli. Replace {assertthat} custom validation functions adapt {assertthat} code. Use helper.R test files testing objects available loaded package. Configure future parallelization code restore original values exit. Configure code uses random seed restore original system seed exit. Improve memory efficiency ale_p objects. Update plotting code compatibility ggplot2 3.5. Add testing code coverage covr.","code":""},{"path":"https://tripartio.github.io/ale/news/index.html","id":"known-issues-to-be-addressed-in-a-future-version-0-5-0","dir":"Changelog","previous_headings":"","what":"Known issues to be addressed in a future version","title":"ale 0.5.0","text":"Effects plots interactions yet implemented.","code":""},{"path":"https://tripartio.github.io/ale/news/index.html","id":"ale-030","dir":"Changelog","previous_headings":"","what":"ale 0.3.0","title":"ale 0.3.0","text":"CRAN release: 2024-02-13 significant updates addition p-values ALE statistics, launching pkgdown website henceforth host development version package, parallelization core functions resulting performance boost.","code":""},{"path":"https://tripartio.github.io/ale/news/index.html","id":"breaking-changes-0-3-0","dir":"Changelog","previous_headings":"","what":"Breaking changes","title":"ale 0.3.0","text":"One key goals ale package truly model-agnostic: support R object can considered model, model defined object makes prediction input row data provided. Towards goal, adjust custom predict function make flexible various kinds model objects. happy changes now enable support tidymodels objects various survival models (now, return single-vector predictions). , addition taking required object newdata arguments, custom predict function pred_fun ale() function now also requires argument type specify prediction type, whether used . change breaks previous code used custom predict functions, allows ale analyze many new model types . Code require custom predict functions affected change. See updated documentation ale() function details. Another change breaks former code arguments model_bootstrap() modified. Instead cumbersome model_call_string, model_bootstrap() now uses insight package automatically detect many R models directly manipulate model object needed. , second argument now model object. However, non-standard models insight automatically parse, modified model_call_string still available assure model-agnostic functionality. Although change breaks former code ran model_bootstrap(), believe new function interface much user-friendly. slight change might break existing code conf_regions output associated ALE statistics restructured. new structure provides useful information. See help(ale) details.","code":""},{"path":"https://tripartio.github.io/ale/news/index.html","id":"other-user-visible-changes-0-3-0","dir":"Changelog","previous_headings":"","what":"Other user-visible changes","title":"ale 0.3.0","text":"package now uses pkgdown website located https://tripartio.github.io/ale/. recent development features documented. P-values now provided ALE statistics. However, calculation slow, disabled default; must explicitly requested. requested, automatically calculated possible (standard R model types); , additional steps must taken calculation. See new create_p_funs() function details example. normalization formula ALE statistics changed minor differences median normalized zero. adjustment, former normalization formula give tiny differences apparently large normalized effects. See updated documentation vignette('ale-statistics') details. vignette expanded details properly interpret normalized ALE statistics. Normalized ALE range (NALER) now expressed percentile points relative median (ranging -50% +50%) rather original formulation absolute percentiles (ranging 0 100%). See updated documentation vignette('ale-statistics') details. Performance dramatically improved addition parallelization default. use furrr library. tests, practically, typically found speed-ups n – 2 n number physical cores (machine learning generally unable use logical cores). example, computer 4 physical cores see least ×2 speed-computer 6 physical cores see least ×4 speed-. However, parallelization tricky model-agnostic design. users work models follow standard R conventions, ale package able automatically configure system parallelization. non-standard models users may explicitly list model’s packages new model_packages argument parallel thread can find necessary functions. concern get weird errors. See help(ale) details. Fully documented output ale() function. See help(ale) details. median_band_pct argument ale() now takes vector two numbers, one inner band one outer. Switched recommendation calculating ALE data test data instead calculate full dataset final deployment model. Replaced {gridExtra} patchwork examples vignettes printing plots. Separated ale() function documentation ale-package documentation. p-values provided, ALE effects plot now shows NALED band instead median band. alt tags describe plots accessibility. accurate rug plots ALE interaction plots. Various minor tweaks plots.","code":""},{"path":"https://tripartio.github.io/ale/news/index.html","id":"under-the-hood-0-3-0","dir":"Changelog","previous_headings":"","what":"Under the hood","title":"ale 0.3.0","text":"Uses insight package automatically detect y_col model call objects possible; increases range automatic model detection ale package general. switched using progressr package progress bars. cli progression handler, enables accurate estimated times arrival (ETA) long procedures, even parallel computing. message displayed per session informing users customize progress bars. details, see help(ale), particularly documentation progress bars silent argument. Moved ggplot2 dependency import. , longer automatically loaded package. detailed information internal var_summary() function. particular, encodes whether user using p-values (ALER band) (median band). Separated validation functions reused across functions internal validation.R file. Added argument compact_plots plotting functions strip plot environments reduce size returned objects. See help(ale) details. Created package_scope environment. Many minor bug fixes improvements. Improved validation problematic inputs informative error messages. Various minor performance boosts profiling refactoring code.","code":""},{"path":"https://tripartio.github.io/ale/news/index.html","id":"known-issues-to-be-addressed-in-a-future-version-0-3-0","dir":"Changelog","previous_headings":"","what":"Known issues to be addressed in a future version","title":"ale 0.3.0","text":"Bootstrapping yet supported ALE interactions (ale_ixn()). ALE statistics yet supported ALE interactions (ale_ixn()). ale() yet support multi-output model prediction types (e.g., multi-class classification multi-time survival probabilities).","code":""},{"path":"https://tripartio.github.io/ale/news/index.html","id":"ale-020","dir":"Changelog","previous_headings":"","what":"ale 0.2.0","title":"ale 0.2.0","text":"CRAN release: 2023-10-19 version introduces various ALE-based statistics let ALE used statistical inference, just interpretable machine learning. dedicated vignette introduces functionality (see “ALE-based statistics statistical inference effect sizes” vignettes link main CRAN page https://CRAN.R-project.org/package=ale). introduce statistics detail working paper: Okoli, Chitu. 2023. “Statistical Inference Using Machine Learning Classical Techniques Based Accumulated Local Effects (ALE).” arXiv. https://doi.org/10.48550/arXiv.2310.09877. Please note might refined peer review.","code":""},{"path":"https://tripartio.github.io/ale/news/index.html","id":"breaking-changes-0-2-0","dir":"Changelog","previous_headings":"","what":"Breaking changes","title":"ale 0.2.0","text":"changed output data structure ALE data plots. necessary add ALE statistics. Unfortunately, change breaks code refers objects created initial 0.1.0 version, especially code printing plots. However, felt necessary new structure makes coding workflows much easier. See vignettes examples code examples print plots using new structure.","code":""},{"path":"https://tripartio.github.io/ale/news/index.html","id":"other-user-visible-changes-0-2-0","dir":"Changelog","previous_headings":"","what":"Other user-visible changes","title":"ale 0.2.0","text":"added new ALE-based statistics: ALED ALER normalized versions NALED NALER. ale() model_bootstrap() now output statistics. (ale_ixn() come later.) added rug plots numeric values percentage frequencies plots categories. indicators give quick visual indication distribution plotted data. added vignette introduces ALE-based statistics, especially effect size measures, demonstrates use statistical inference: “ALE-based statistics statistical inference effect sizes” (available vignettes link main CRAN page https://CRAN.R-project.org/package=ale). added vignette compares ale package reference {ALEPlot} package: “Comparison {ALEPlot} ale packages” (available vignettes link main CRAN page https://CRAN.R-project.org/package=ale). var_cars modified version mtcars features many different types variables. census polished version adult income dataset used vignette {ALEPlot} package. Progress bars show progression analysis. can disabled passing silent = TRUE ale(), ale_ixn(), model_bootstrap(). user can specify random seed passing seed argument ale(), ale_ixn(), model_bootstrap().","code":""},{"path":"https://tripartio.github.io/ale/news/index.html","id":"under-the-hood-0-2-0","dir":"Changelog","previous_headings":"","what":"Under the hood","title":"ale 0.2.0","text":"far extensive changes assure accuracy stability package software engineering perspective. Even though visible users, make package robust hopefully fewer bugs. Indeed, extensive data validation may help users debug errors. Added data validation exported functions. hood, user-facing function carefully validates user entered valid data using {assertthat} package; , function fails quickly appropriate error message. Created unit tests exported functions. hood, testthat package now used testing outputs user-facing function. help code base robust going forward future developments. importantly, created tests compare results original reference {ALEPlot} package. tests ensure future code breaks accuracy ALE calculations caught quickly. Bootstrapped ALE values now centred mean default, instead median. Mean averaging generally stable, especially smaller datasets. code base extensively reorganized efficient development moving forward. Numerous bugs fixed following internal usage testing.","code":""},{"path":"https://tripartio.github.io/ale/news/index.html","id":"known-issues-to-be-addressed-in-a-future-version-0-2-0","dir":"Changelog","previous_headings":"","what":"Known issues to be addressed in a future version","title":"ale 0.2.0","text":"Bootstrapping yet supported ALE interactions (ale_ixn()). ALE statistics yet supported ALE interactions (ale_ixn()).","code":""},{"path":"https://tripartio.github.io/ale/news/index.html","id":"ale-010","dir":"Changelog","previous_headings":"","what":"ale 0.1.0","title":"ale 0.1.0","text":"CRAN release: 2023-08-29 first CRAN release ale package. official description initial release: Accumulated Local Effects (ALE) initially developed model-agnostic approach global explanations results black-box machine learning algorithms. (Apley, Daniel W., Jingyu Zhu. “Visualizing effects predictor variables black box supervised learning models.” Journal Royal Statistical Society Series B: Statistical Methodology 82.4 (2020): 1059-1086 doi:10.1111/rssb.12377.) ALE two primary advantages approaches like partial dependency plots (PDP) SHapley Additive exPlanations (SHAP): values affected presence interactions among variables model computation relatively rapid. package rewrites original code ‘ALEPlot’ package calculating ALE data completely reimplements plotting ALE values. (package uses GPL-2 license {ALEPlot} package.) initial release replicates full functionality {ALEPlot} package lot . currently presents three functions: ale(): create data plot one-way ALE (single variables). ALE values may bootstrapped. ale_ixn(): create data plot two-way ALE interactions. Bootstrapping interaction ALE values yet implemented. model_bootstrap(): bootstrap entire model, just ALE values. function returns bootstrapped model statistics coefficients well bootstrapped ALE values. appropriate approach small samples. release provides details following vignettes (available vignettes link main CRAN page https://CRAN.R-project.org/package=ale): Introduction ale package Analyzing small datasets (fewer 2000 rows) ALE ale() function handling various datatypes x","code":""}]
