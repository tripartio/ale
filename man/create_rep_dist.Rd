% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/rep.R
\name{create_rep_dist}
\alias{create_rep_dist}
\title{Create an object of the ALE statistics of a random variable that can be used to generate random effect probabilities (REPs)}
\usage{
create_rep_dist(
  data,
  model,
  rep_speed = "approx fast",
  ...,
  parallel = future::availableCores(logical = FALSE, omit = 1),
  model_packages = NULL,
  random_model_call_string = NULL,
  random_model_call_string_vars = character(),
  y_col = NULL,
  binary_true_value = TRUE,
  pred_fun = function(object, newdata, type = pred_type) {
     stats::predict(object =
    object, newdata = newdata, type = type)
 },
  pred_type = "response",
  output = NULL,
  rand_it = 1000,
  seed = 0,
  silent = FALSE,
  .testing_mode = FALSE
)
}
\arguments{
\item{data}{See documentation for \code{\link[=ale]{ale()}}}

\item{model}{See documentation for \code{\link[=ale]{ale()}}}

\item{rep_speed}{character(1). Either 'approx fast' (default) or 'precise slow'. See details.}

\item{...}{not used. Inserted to require explicit naming of subsequent arguments.}

\item{parallel}{See documentation for \code{\link[=ale]{ale()}}}

\item{model_packages}{See documentation for \code{\link[=ale]{ale()}}}

\item{random_model_call_string}{character string. If NULL, \code{create_rep_dist()} tries to
automatically detect and construct the call for random effect probabilities (REPs). If it cannot, the function will fail early. In that case, a character string of the full call for the model must be provided that includes the random variable. See details.}

\item{random_model_call_string_vars}{See documentation for \code{model_call_string_vars}
in \code{\link[=model_bootstrap]{model_bootstrap()}}; their operation is very similar.}

\item{y_col}{See documentation for \code{\link[=ale]{ale()}}}

\item{binary_true_value}{See documentation for \code{\link[=model_bootstrap]{model_bootstrap()}}}

\item{pred_fun, pred_type}{See documentation for \code{\link[=ale]{ale()}}.}

\item{output}{character string. If 'residuals', returns the residuals in addition to the raw data of the generated random statistics (which are always returned). If NULL (default), does not return the residuals.}

\item{rand_it}{non-negative integer length 1. Number of times that the model
should be retrained with a new random variable. The default of 1000 should
give reasonably stable random effect probabilities (REPs) It can be reduced as low as 100 for faster
test runs.}

\item{seed}{See documentation for \code{\link[=ale]{ale()}}}

\item{silent}{See documentation for \code{\link[=ale]{ale()}}}

\item{.testing_mode}{logical(1). Internal use only. Disables some data validation checks to allow for debugging.}
}
\value{
The return value is a list of class \code{ale_rep}. See examples for an illustration of how to inspect this list. Its elements are:
\itemize{
\item \code{value_to_p}: a list of functions named for each each available ALE statistic.
Each function signature is \verb{function(x)} where x is a numeric. The function returns
the random effect probability (REP) (minimum 0; maximum 1) for the respective statistic based on the random variable analysis.
For an input x that returns p, its interpretation is that p\% of random variables
obtained the same or higher statistic value. For example, to get the REP
of a NALED of 4.2, enter \code{rep_dist$value_to_p(4.2)}. A return value of 0.03 means
that only 3\% of random variables obtained a NALED greater than or equal to 4.2.
\item \code{p_to_random_value}: a list of functions named for each each available ALE statistic.
These are the inverse functions of \code{value_to_p}. The signature is \verb{function(p)}
where p is a numeric from 0 to 1. The function returns the numeric value of the
random variable statistic that would yield the provided REP.
For an input p that returns x, its interpretation is that p\% of random variables
obtained the same or higher statistic value. For example, to get the random
variable ALED for the 0.05 REP, enter \code{rep_dist$p_to_random_value(0.05)}.
A return value of 102 means that only 5\% of random variables obtained an ALED
greater than or equal to 102.
\item \code{rand_stats}: a tibble whose rows are each of the \code{rand_it} iterations of the random variable analysis and whose columns are the ALE statistics obtained for each random variable.
\item \code{residuals}: If \code{output = 'residuals'}, returns the actual \code{y_col} values from \code{data} minus the predicted values from the \code{model} (without random variables) on the \code{data}. If \code{output = NULL}, (default), does not return these residuals.
\code{residual_distribution}: the closest estimated distribution for the \code{residuals}
as determined by \code{\link[univariateML:MaximumLikelihoodDistribution]{univariateML::rml()}}. This is the distribution used to generate
all the random variables.
}
}
\description{
ALE statistics are accompanied with two indicators of the confidence of their values, serving purposes analogous (but not identical to) p-values. First, bootstrapping creates confidence intervals for ALE measures and ALE statistics to give a range of the possible likely values.

Second, we calculate random effect probabilities (REPs), an indicator of the probability that a given ALE statistic is random. Calculating REPs is not trivial for ALE statistics because ALE is non-parametric and model-agnostic. Because ALE is non-parametric (that is, it does not assume any particular distribution of data), the \code{ale} package generates REPs by calculating ALE for many random variables; this makes the
procedure somewhat slow. For this reason, they are not calculated by default;
they must be explicitly requested. Because the \code{ale} package is model-agnostic (that is, it
works with any kind of R model), the \code{\link[=ale]{ale()}} function cannot always automatically
manipulate the model object to create the REPs. It can only do so for
models that follow the standard R statistical modelling conventions, which
includes almost all built-in R algorithms (like \code{\link[stats:lm]{stats::lm()}} and \code{\link[stats:glm]{stats::glm()}}) and many widely
used statistics packages (like \code{mgcv} and \code{survival}), but which excludes most
machine learning algorithms (like \code{tidymodels} and \code{caret}). For non-standard
algorithms, the user needs to do a little work to help the ale function
correctly manipulate its model object:
\itemize{
\item The full model call must be passed as a character string in the argument
'random_model_call_string', with two slight modifications as follows.
\item In the formula that specifies the model, you must add a variable named
'random_variable'. This corresponds to the random variables that \code{\link[=create_rep_dist]{create_rep_dist()}}
will use to estimate REPs.
\item The dataset on which the model is trained must be named 'rand_data'. This
corresponds to the modified datasets that will be used to train the random
variables.
}

See the example below for how this is implemented.
}
\section{Approach to calculating random effect probabilities (REPs)}{

The \code{ale} package takes a literal frequentist approach to the calculation of
REPs. That is, it literally retrains the model 1000 times, each time
modifying it by adding a distinct random variable to the model.
(The number of iterations is customizable
with the \code{rand_it} argument.) The ALEs and ALE statistics are calculated for
each random variable. The percentiles of the distribution of these
random-variable ALEs are then used to determine REPs for non-random variables.
Thus, REPs are interpreted as the frequency of random variable ALE statistics
that exceed the value of ALE statistic of the actual variable in question.
The specific steps are as follows:
\itemize{
\item The residuals of the original model trained on the training data are calculated
(residuals are the actual y target value minus the predicted values).
\item The closest distribution of the residuals is detected with
\code{univariateML::model_select()}.
\item 1000 new models are trained by generating a random variable each time with
\code{univariateML::rml()} and then training a new model with that random variable
added.
\item The ALEs and ALE statistics are calculated for each random variable.
\item For each ALE statistic, the empirical cumulative distribution function
(from \code{stats::ecdf()}) is used to create a function to determine REPs
according to the distribution of the random variables' ALE statistics.
}

What we have just described is the precise approach to calculating REPs with the argument \code{rep_speed = 'precise slow'}. Because it is so slow, by default, create_rep_dist() implements an approximate algorithm by default (\code{rep_speed = 'approx fast'}) which trains only a few random variables up to the number of physical parallel processing threads available, with a minimum of four. To increase speed, the random variable uses only 10 ALE x intervals instead of the default 100. Although approximate REPs are much faster than precise ones, they are still somewhat slow: at the very quickest, they take at least the amount of time that it would take to train the original model  two or three times. See the "Parallel processing" section below for more details on the speed of computation.
}

\section{Parallel processing}{

Parallel processing using the \code{{furrr}} framework is enabled by default. By default, it will use all the available physical CPU cores (minus the core being used for the current R session) with the setting \code{parallel = future::availableCores(logical = FALSE, omit = 1)}. Note that only physical cores are used (not logical cores or "hyperthreading") because machine learning can only take advantage of the floating point processors on physical cores, which are absent from logical cores. Trying to use logical cores will not speed up processing and might actually slow it down with useless data transfer.

For exact REPs, by default 1000 random variables are trained. So, even with
parallel processing, the procedure is very slow. However, a rep_dist object
trained with a specific model on a specific dataset can be reused as often as
needed for the identical model-dataset pair.

For approximate REPs (the default), at least four random variables are trained to give
some minimal variation. With parallel processing, more random variables can
be trained to increase the accuracy of the REP estimates up to the maximum
number of physical cores.
}

\examples{
\donttest{
# Sample 1000 rows from the ggplot2::diamonds dataset (for a simple example)
set.seed(0)
diamonds_sample <- ggplot2::diamonds[sample(nrow(ggplot2::diamonds), 1000), ]

# Create a GAM model with flexible curves to predict diamond price
# Smooth all numeric variables and include all other variables
gam_diamonds <- mgcv::gam(
  price ~ s(carat) + s(depth) + s(table) + s(x) + s(y) + s(z) +
    cut + color + clarity,
  data = diamonds_sample
)
summary(gam_diamonds)

# Create REP distribution
rd_diamonds <- create_rep_dist(
  diamonds_sample,
  gam_diamonds,
  # only 100 iterations for a quick demo; but usually should remain at 1000
  rand_it = 100,
)

# Examine the structure of the returned object
str(rd_diamonds)
# In RStudio: View(rd_diamonds)

# Calculate ALEs with REPs
ale_gam_diamonds <- ale(
  diamonds_sample,
  gam_diamonds,
  rep = rd_diamonds
)

# Plot the ALE data. The horizontal bands in the plots use the REPs.
ale_gam_diamonds$plots |>
  patchwork::wrap_plots()


# For non-standard models that give errors with the default settings,
# you can use 'random_model_call_string' to specify a model for the estimation
# of REPs from random variables as in this example.
# See details above for an explanation.
rd_diamonds <- create_rep_dist(
  diamonds_sample,
  gam_diamonds,
  random_model_call_string = 'mgcv::gam(
    price ~ s(carat) + s(depth) + s(table) + s(x) + s(y) + s(z) +
        cut + color + clarity + random_variable,
    data = rand_data
  )',
  # only 100 iterations for a quick demo; but usually should remain at 1000
  rand_it = 100,
)

}


}
\references{
Okoli, Chitu. 2023.
“Statistical Inference Using Machine Learning and Classical Techniques Based
on Accumulated Local Effects (ALE).” arXiv. \url{https://arxiv.org/abs/2310.09877}.
}
